{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1b4ccd3092164890aca06e0bdc4b8da8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ce7ca0cedd4443282d31bf2f40be665","IPY_MODEL_b0b14f1dc4f442c783fccaecfd82840f","IPY_MODEL_2e0d8e34e7a54f0a8bea5646d5cf2b4e"],"layout":"IPY_MODEL_1942407dc08c45139581675c9092bf0a"}},"0ce7ca0cedd4443282d31bf2f40be665":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ca5e5e6fcea490e919643bd857d8844","placeholder":"​","style":"IPY_MODEL_644598da1c4e48feb3fff22cd84b1982","value":"Sanity Checking DataLoader 0: 100%"}},"b0b14f1dc4f442c783fccaecfd82840f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d70c17526f5d42949b8f0299ad9d4a66","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69f07122e5ae411394775b2a86bb1f35","value":2}},"2e0d8e34e7a54f0a8bea5646d5cf2b4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a0ab738ef9a4b78a908898979c2d1c2","placeholder":"​","style":"IPY_MODEL_97576b9cceef4a12b77d3ab2fdb43772","value":" 2/2 [00:00&lt;00:00,  7.79it/s]"}},"1942407dc08c45139581675c9092bf0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"4ca5e5e6fcea490e919643bd857d8844":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"644598da1c4e48feb3fff22cd84b1982":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d70c17526f5d42949b8f0299ad9d4a66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69f07122e5ae411394775b2a86bb1f35":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a0ab738ef9a4b78a908898979c2d1c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97576b9cceef4a12b77d3ab2fdb43772":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b0e5ceb6e3b4be586e781baa31ea25b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ad97ac666fb4658b28c455e0009c6da","IPY_MODEL_8d950b225a594e2fa12d781db2e72501","IPY_MODEL_3306aa5561d34ee8901ce007b4e2470e"],"layout":"IPY_MODEL_041f70d6bad4490aa3de47065d71b3e1"}},"3ad97ac666fb4658b28c455e0009c6da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2bc967ff20044269f4f7ac0efa291d2","placeholder":"​","style":"IPY_MODEL_7b0276b4875f44bd98c96c4510cf151d","value":"Epoch 64:   0%"}},"8d950b225a594e2fa12d781db2e72501":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e11dd04a3014fb689b2192713c02478","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18367889aaba4ceaab3eb647f2db1461","value":0}},"3306aa5561d34ee8901ce007b4e2470e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f973d503a9984fbabef849b8ab2a302e","placeholder":"​","style":"IPY_MODEL_6a9929dfecd14e26953a939d0107fe1d","value":" 0/7 [00:00&lt;?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.984, valid_loss=1.340]"}},"041f70d6bad4490aa3de47065d71b3e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"c2bc967ff20044269f4f7ac0efa291d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b0276b4875f44bd98c96c4510cf151d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e11dd04a3014fb689b2192713c02478":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18367889aaba4ceaab3eb647f2db1461":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f973d503a9984fbabef849b8ab2a302e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a9929dfecd14e26953a939d0107fe1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82fe3f59990b48e2bdacb3f2b74ed6d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_915fb0aefacf406abb9d5dfbd0d1ce0e","IPY_MODEL_5e3d388e2bd3423daeb1c679c85a5e3f","IPY_MODEL_b0ae6a58db1144c980feb6a4d0d3f693"],"layout":"IPY_MODEL_0090dcffbe494a4f82735d95d2e2b43e"}},"915fb0aefacf406abb9d5dfbd0d1ce0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_392edeb3de4a4c01af7bed6417873886","placeholder":"​","style":"IPY_MODEL_bbbed57991e448c499e3ffa0cac8e884","value":"Validation DataLoader 0: 100%"}},"5e3d388e2bd3423daeb1c679c85a5e3f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbd2a84479a84477af43b8f3e4eb74c9","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69525b64bd3d44258334a47cf6e93ed8","value":7}},"b0ae6a58db1144c980feb6a4d0d3f693":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4fc5a1dffc54c64a621b47374191e76","placeholder":"​","style":"IPY_MODEL_566f641b434a40a0b641062ef1dc7a7f","value":" 7/7 [00:00&lt;00:00, 126.80it/s]"}},"0090dcffbe494a4f82735d95d2e2b43e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"392edeb3de4a4c01af7bed6417873886":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbbed57991e448c499e3ffa0cac8e884":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbd2a84479a84477af43b8f3e4eb74c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69525b64bd3d44258334a47cf6e93ed8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4fc5a1dffc54c64a621b47374191e76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"566f641b434a40a0b641062ef1dc7a7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ae2c87f2e39452085f7b8550d0507be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8f6c33dd87a4ebfa498e64070c1df6c","IPY_MODEL_9dabcd52834b4f1a8fb270a206984e8e","IPY_MODEL_152facc1227a482eab717c61b957710c"],"layout":"IPY_MODEL_900bffd6b8c34dd0b5c6ef1163cc2533"}},"c8f6c33dd87a4ebfa498e64070c1df6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c4ac30934f4407492608c273af12df3","placeholder":"​","style":"IPY_MODEL_9f2f59e65446495eb62fe51bbbfe48e2","value":"Validation DataLoader 0: 100%"}},"9dabcd52834b4f1a8fb270a206984e8e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e77f9f9cb9e34ced85b5ec97dbdfdfdd","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9ad6077d4d9b4c3ca8ac61f1c57050b0","value":7}},"152facc1227a482eab717c61b957710c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a64c81112cf843ef815561864beafea3","placeholder":"​","style":"IPY_MODEL_71c80d73e33542d597af16361269f7c4","value":" 7/7 [00:00&lt;00:00, 119.36it/s]"}},"900bffd6b8c34dd0b5c6ef1163cc2533":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"2c4ac30934f4407492608c273af12df3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f2f59e65446495eb62fe51bbbfe48e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e77f9f9cb9e34ced85b5ec97dbdfdfdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ad6077d4d9b4c3ca8ac61f1c57050b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a64c81112cf843ef815561864beafea3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71c80d73e33542d597af16361269f7c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28d63001996b4cec82ffcadb2e6e7599":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a39503c6824549ee86eebfc5a73cdf78","IPY_MODEL_f8943d0a482a415fb8fa06c6a73a6d8d","IPY_MODEL_f1307b7a206440ba8ec915f92c4ed0f0"],"layout":"IPY_MODEL_58ae48ca5dc84146905938d902ba921b"}},"a39503c6824549ee86eebfc5a73cdf78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a13bce18b8d43dda585632ade81eece","placeholder":"​","style":"IPY_MODEL_eacd6c7ae6d144e0902deab2ce01f5bd","value":"Validation DataLoader 0: 100%"}},"f8943d0a482a415fb8fa06c6a73a6d8d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2170c349582e4a24a6b79e2f8ef2dc4a","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4e22946844e410abee57f020d0b9f2a","value":7}},"f1307b7a206440ba8ec915f92c4ed0f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d45dce67d8a84ec596d6a047dda5b2f5","placeholder":"​","style":"IPY_MODEL_de4eabb4560841b28a5f7287ea8a42fe","value":" 7/7 [00:00&lt;00:00, 129.68it/s]"}},"58ae48ca5dc84146905938d902ba921b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"9a13bce18b8d43dda585632ade81eece":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eacd6c7ae6d144e0902deab2ce01f5bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2170c349582e4a24a6b79e2f8ef2dc4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4e22946844e410abee57f020d0b9f2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d45dce67d8a84ec596d6a047dda5b2f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de4eabb4560841b28a5f7287ea8a42fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"186dbd8b81ee4be2b8db892502ae2db9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e6f03bb1315142a59b781270e8ba0603","IPY_MODEL_3949e7c329f842d087845a0a67fe2940","IPY_MODEL_dd46adde19d9469ca7bbe6ad579a79cb"],"layout":"IPY_MODEL_7ff8ec1019484d9183cdb39b7f110119"}},"e6f03bb1315142a59b781270e8ba0603":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_969ffd73e193405b83995d33bc99bbcd","placeholder":"​","style":"IPY_MODEL_25ae2c1d3c0c4a319cc4fe7d1169ddb1","value":"Validation DataLoader 0: 100%"}},"3949e7c329f842d087845a0a67fe2940":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c04a1004d8934a7c861ab5b42008e4a3","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d4ffdefd2d547128ceca8dfff1032d3","value":7}},"dd46adde19d9469ca7bbe6ad579a79cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69dc7141979d4491ab163e87441e810b","placeholder":"​","style":"IPY_MODEL_f169c22034254181a7592957357447e5","value":" 7/7 [00:00&lt;00:00, 124.63it/s]"}},"7ff8ec1019484d9183cdb39b7f110119":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"969ffd73e193405b83995d33bc99bbcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25ae2c1d3c0c4a319cc4fe7d1169ddb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c04a1004d8934a7c861ab5b42008e4a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d4ffdefd2d547128ceca8dfff1032d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69dc7141979d4491ab163e87441e810b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f169c22034254181a7592957357447e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61e177c2c79245a8b7724da265589845":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e7ef46cc6424bd389de92009b694984","IPY_MODEL_5b4a768695e0454cb3237a070abf057a","IPY_MODEL_221def5e646c43f7a7d8c917698c0efd"],"layout":"IPY_MODEL_994291390400428e97421af834b1ed25"}},"4e7ef46cc6424bd389de92009b694984":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1a06844f52a4eb39f636c3534165018","placeholder":"​","style":"IPY_MODEL_aa05a592a3a34bf0890103f203a128d5","value":"Validation DataLoader 0: 100%"}},"5b4a768695e0454cb3237a070abf057a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_25ed90c741fc4f65ac555edac98174db","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17bf77f757c6453680001f7d06a1b90a","value":7}},"221def5e646c43f7a7d8c917698c0efd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6e449b0f3aa451fa9db8cc9d8aa0e22","placeholder":"​","style":"IPY_MODEL_713e4b98a839446cbd925284248a5aec","value":" 7/7 [00:00&lt;00:00, 118.30it/s]"}},"994291390400428e97421af834b1ed25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"e1a06844f52a4eb39f636c3534165018":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa05a592a3a34bf0890103f203a128d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25ed90c741fc4f65ac555edac98174db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17bf77f757c6453680001f7d06a1b90a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6e449b0f3aa451fa9db8cc9d8aa0e22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"713e4b98a839446cbd925284248a5aec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c6a24ac73be47a480e84e82a8073a79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18d0cdcc51b64f5381dc00b761056719","IPY_MODEL_8a009da9ebfa4ba1aef3e1ead6470531","IPY_MODEL_f4f080b94f464bc386a2219faa783d2a"],"layout":"IPY_MODEL_2ad9c0814da042828d558fd411b1a7c7"}},"18d0cdcc51b64f5381dc00b761056719":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f07281f1aff41a684fe93ab7192de66","placeholder":"​","style":"IPY_MODEL_2467892450d64b9f85a3b8aad6cb7d0d","value":"Validation DataLoader 0: 100%"}},"8a009da9ebfa4ba1aef3e1ead6470531":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b8fede78cd947de824765646ca22e23","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_934a171e1895461cbf5b31c5b7ada2c3","value":7}},"f4f080b94f464bc386a2219faa783d2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_808627c439604fb4a53a166bb12095b3","placeholder":"​","style":"IPY_MODEL_4971d6fb7e7044da871275b2eb191ec0","value":" 7/7 [00:00&lt;00:00, 113.07it/s]"}},"2ad9c0814da042828d558fd411b1a7c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"6f07281f1aff41a684fe93ab7192de66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2467892450d64b9f85a3b8aad6cb7d0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b8fede78cd947de824765646ca22e23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"934a171e1895461cbf5b31c5b7ada2c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"808627c439604fb4a53a166bb12095b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4971d6fb7e7044da871275b2eb191ec0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c692353c7b2d4728ae1a572ecefbfe7e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_701e64cf28ab48618fca3b3bf7851e3e","IPY_MODEL_0d5eb0baf11a476f9fd901b2ab35a4d4","IPY_MODEL_3b14e5d4a9174b90aab91a33e4692a06"],"layout":"IPY_MODEL_56f39a43f6d6468a9db0555f92608296"}},"701e64cf28ab48618fca3b3bf7851e3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a0684b932934012a474e5904313e648","placeholder":"​","style":"IPY_MODEL_bb366752743541d590e8945e4b8e1c47","value":"Validation DataLoader 0: 100%"}},"0d5eb0baf11a476f9fd901b2ab35a4d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_13317ca5c89b44cbbc824f0b28e086c9","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_920a870c778d4ca5b630fa35067643c5","value":7}},"3b14e5d4a9174b90aab91a33e4692a06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1c788935a074c48b82e1ca86edc79df","placeholder":"​","style":"IPY_MODEL_f79e5a7bfe6d44b3bb227e6a8cb66970","value":" 7/7 [00:00&lt;00:00, 91.54it/s]"}},"56f39a43f6d6468a9db0555f92608296":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"7a0684b932934012a474e5904313e648":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb366752743541d590e8945e4b8e1c47":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13317ca5c89b44cbbc824f0b28e086c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"920a870c778d4ca5b630fa35067643c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a1c788935a074c48b82e1ca86edc79df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f79e5a7bfe6d44b3bb227e6a8cb66970":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d74790f1150415ba4bc0fcb37391245":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50b65e59b8594745975232912a0bc7d9","IPY_MODEL_0e2fa0f474d04bd19d26f91ca639ef35","IPY_MODEL_8f189c23100943b795805c575d1af00a"],"layout":"IPY_MODEL_6651e6babc3b4faebcfc2c8b4ecce8d5"}},"50b65e59b8594745975232912a0bc7d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2ccdf5a20dd44cbbb8cb8f5bc4dd96f","placeholder":"​","style":"IPY_MODEL_0e13fe7df6e24ddda651aa69a75cf643","value":"Validation DataLoader 0: 100%"}},"0e2fa0f474d04bd19d26f91ca639ef35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e68bedaacabe4c5aae179a8a940d0129","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63df3e55c8a14b06b60bebf4538eb179","value":7}},"8f189c23100943b795805c575d1af00a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a53d32f14a5b4c7bb30134a13556db50","placeholder":"​","style":"IPY_MODEL_03c497180ecd462181e8a0b31c6b238f","value":" 7/7 [00:00&lt;00:00, 117.79it/s]"}},"6651e6babc3b4faebcfc2c8b4ecce8d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"f2ccdf5a20dd44cbbb8cb8f5bc4dd96f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e13fe7df6e24ddda651aa69a75cf643":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e68bedaacabe4c5aae179a8a940d0129":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63df3e55c8a14b06b60bebf4538eb179":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a53d32f14a5b4c7bb30134a13556db50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03c497180ecd462181e8a0b31c6b238f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d5e85bd67114980b9f020611f22ef8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_212f7cff24c84b34ba1ad9f8e3ea8ab4","IPY_MODEL_bcf8d41a4ea14427b40d9e3ff9bbff06","IPY_MODEL_14f99bca1bbb49d785381792a92b7a55"],"layout":"IPY_MODEL_acf3836f445e43f88bb8279e22d55e6c"}},"212f7cff24c84b34ba1ad9f8e3ea8ab4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_135173037fcd4b6dbb17d9a5ec8c7696","placeholder":"​","style":"IPY_MODEL_b0efbfb2c8c3452d9b26990253c86e02","value":"Validation DataLoader 0: 100%"}},"bcf8d41a4ea14427b40d9e3ff9bbff06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d756c8e3cb0c49528471bee100da5749","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff970955a4684004be9e9357c090a8c0","value":7}},"14f99bca1bbb49d785381792a92b7a55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c696165ddb09441e9baf5b16a3199b4e","placeholder":"​","style":"IPY_MODEL_bad2083a568345f39ff11865c784ba3e","value":" 7/7 [00:00&lt;00:00, 132.22it/s]"}},"acf3836f445e43f88bb8279e22d55e6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"135173037fcd4b6dbb17d9a5ec8c7696":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0efbfb2c8c3452d9b26990253c86e02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d756c8e3cb0c49528471bee100da5749":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff970955a4684004be9e9357c090a8c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c696165ddb09441e9baf5b16a3199b4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bad2083a568345f39ff11865c784ba3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b5ae7ecf7ff4d4f9240a6b3cfa63638":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c8fd7f87bec4525b290ac394aa57bbe","IPY_MODEL_229997fcc26d4a468980c35d1a58148b","IPY_MODEL_ee5b6c18ca3d4034b40d645c9fb8eb6b"],"layout":"IPY_MODEL_7e256554e039469d9e4421677ffbb3fe"}},"2c8fd7f87bec4525b290ac394aa57bbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19cdaacab3f94dfdbad4805477d5ffe1","placeholder":"​","style":"IPY_MODEL_7e1c4d6b2dcf47ada9ec7d816490eb73","value":"Sanity Checking DataLoader 0: 100%"}},"229997fcc26d4a468980c35d1a58148b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e862d29379b54ddb8bd6a1258839383e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb084adf02d748b4956344b4f8bef56b","value":2}},"ee5b6c18ca3d4034b40d645c9fb8eb6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da953794bb7e4ab49960190818828f15","placeholder":"​","style":"IPY_MODEL_e90bc971232b476d94c14f8ae33c75af","value":" 2/2 [00:00&lt;00:00, 23.92it/s]"}},"7e256554e039469d9e4421677ffbb3fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"19cdaacab3f94dfdbad4805477d5ffe1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e1c4d6b2dcf47ada9ec7d816490eb73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e862d29379b54ddb8bd6a1258839383e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb084adf02d748b4956344b4f8bef56b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da953794bb7e4ab49960190818828f15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e90bc971232b476d94c14f8ae33c75af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e21582e0be024404a227404224e7369c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b2b97de05654bc69deba02128326413","IPY_MODEL_f970fcc91eee43d7a760e969efdcaef0","IPY_MODEL_7d82d9dfe59c4c70bef7d341ce51824d"],"layout":"IPY_MODEL_7534cb4d74084e3babf88f14f0bbdc71"}},"9b2b97de05654bc69deba02128326413":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a438e45891b6493ba682f434c6b6e3ef","placeholder":"​","style":"IPY_MODEL_1531fa8e13834270a048e2f868a7b737","value":"Epoch 78:   0%"}},"f970fcc91eee43d7a760e969efdcaef0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7ed4889788549fea73ca09f08aecdf4","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b52623c2d97844cbbdff18b83f173ecf","value":0}},"7d82d9dfe59c4c70bef7d341ce51824d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0a72500544e4f66b794d5ffb3cc8971","placeholder":"​","style":"IPY_MODEL_5b48b463732248b992e42e059baae0eb","value":" 0/7 [00:00&lt;?, ?it/s, v_num=1, train_loss_step=1.190, train_loss_epoch=1.240, valid_loss=1.310]"}},"7534cb4d74084e3babf88f14f0bbdc71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"a438e45891b6493ba682f434c6b6e3ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1531fa8e13834270a048e2f868a7b737":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7ed4889788549fea73ca09f08aecdf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b52623c2d97844cbbdff18b83f173ecf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e0a72500544e4f66b794d5ffb3cc8971":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b48b463732248b992e42e059baae0eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c91a2ac5bb574ce59f3a9a7d4cb56306":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e4d8ab71f5846a2b8051e9c8bf183b5","IPY_MODEL_338a1152c5b94be9ac3fc14b32fee6fc","IPY_MODEL_8082637de89946da92ba9a4ee429c9c6"],"layout":"IPY_MODEL_443ce21feb184726aa03bff2787dc799"}},"9e4d8ab71f5846a2b8051e9c8bf183b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c7ae0ea1c8a4a13babdad9d897bd821","placeholder":"​","style":"IPY_MODEL_ed6fa731ad8641378ec4b61815664c2c","value":"Validation DataLoader 0: 100%"}},"338a1152c5b94be9ac3fc14b32fee6fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_faea6389e60a4516b12624bb103aa135","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2af7655a30954d99a09bc5315ac5588e","value":7}},"8082637de89946da92ba9a4ee429c9c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fdb2711e0ab488bae0d1df8b7caf731","placeholder":"​","style":"IPY_MODEL_b10c15801ebb4148a0d4d0e9fa74c24c","value":" 7/7 [00:00&lt;00:00, 113.36it/s]"}},"443ce21feb184726aa03bff2787dc799":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"4c7ae0ea1c8a4a13babdad9d897bd821":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed6fa731ad8641378ec4b61815664c2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"faea6389e60a4516b12624bb103aa135":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2af7655a30954d99a09bc5315ac5588e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fdb2711e0ab488bae0d1df8b7caf731":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b10c15801ebb4148a0d4d0e9fa74c24c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"086c137f5ed04b7eb9849ca543a4bfc3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f894f06ae92f43a1b36976ae981b25cb","IPY_MODEL_85903073305549a286c5d0af955600ec","IPY_MODEL_85b77526e425425e980a51bacc742405"],"layout":"IPY_MODEL_811175bd0e42414280621e9997451aa2"}},"f894f06ae92f43a1b36976ae981b25cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_614c57e8818a4ae69d4fcef057478377","placeholder":"​","style":"IPY_MODEL_d12b10058d6d4fec9bc18e4cae443d9c","value":"Validation DataLoader 0: 100%"}},"85903073305549a286c5d0af955600ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9c0a876afa24e67873446982cb14d14","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8e60e10440d4b2ba29432152e695c6e","value":7}},"85b77526e425425e980a51bacc742405":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd04e8ab805a4bf9b1390691134c9b7d","placeholder":"​","style":"IPY_MODEL_41cf0ac4c4c4446ca33a8c1a78133e5f","value":" 7/7 [00:00&lt;00:00, 122.59it/s]"}},"811175bd0e42414280621e9997451aa2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"614c57e8818a4ae69d4fcef057478377":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d12b10058d6d4fec9bc18e4cae443d9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9c0a876afa24e67873446982cb14d14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8e60e10440d4b2ba29432152e695c6e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd04e8ab805a4bf9b1390691134c9b7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41cf0ac4c4c4446ca33a8c1a78133e5f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68e0e27a676f479f9a335e6d51dd8f78":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5bcbec1391ee4e09ac832d97e9b5b7b6","IPY_MODEL_f06f1ce55e5e4627aef40866602d9ec0","IPY_MODEL_6de86be3c746490b89ba5ec1d91aad10"],"layout":"IPY_MODEL_d65832d3e3d54470a2734052f291c1c5"}},"5bcbec1391ee4e09ac832d97e9b5b7b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d4d244d162040b3a75d46c9f3aa9f68","placeholder":"​","style":"IPY_MODEL_412aebd198db4959b246b315484e48fe","value":"Validation DataLoader 0: 100%"}},"f06f1ce55e5e4627aef40866602d9ec0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_189b636368ff4429a86b48dcc58da171","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f636ce128d043e6b7223d2847a72d89","value":7}},"6de86be3c746490b89ba5ec1d91aad10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77c122fc7766415dbc6ae9698852b08c","placeholder":"​","style":"IPY_MODEL_d4a929224e6d4f6ab9cca1d47b8d830b","value":" 7/7 [00:00&lt;00:00, 93.45it/s]"}},"d65832d3e3d54470a2734052f291c1c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"9d4d244d162040b3a75d46c9f3aa9f68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"412aebd198db4959b246b315484e48fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"189b636368ff4429a86b48dcc58da171":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f636ce128d043e6b7223d2847a72d89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"77c122fc7766415dbc6ae9698852b08c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4a929224e6d4f6ab9cca1d47b8d830b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a1b20f837e64420a06c58544d8ccd23":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02ebffeead6f405abdccef8119b307a7","IPY_MODEL_ad84c946620c48d0988bdcc98fa86b64","IPY_MODEL_46644cc454344264b1d6b1716717b411"],"layout":"IPY_MODEL_bda41dfc05414aeebd5b464bcacdf38d"}},"02ebffeead6f405abdccef8119b307a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c97be772c719491895037f89af3e43f9","placeholder":"​","style":"IPY_MODEL_3baf55c1a91a481db9eea0f3c9736363","value":"Validation DataLoader 0: 100%"}},"ad84c946620c48d0988bdcc98fa86b64":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4ce2a76cbf747ea824b295034e70f59","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0c926fb9ee241619a2b7b943263631f","value":7}},"46644cc454344264b1d6b1716717b411":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51b23c5ba4d04218a3d3b68107a4ea4f","placeholder":"​","style":"IPY_MODEL_a98f970368204ca58af0369f7f0cc475","value":" 7/7 [00:00&lt;00:00, 136.86it/s]"}},"bda41dfc05414aeebd5b464bcacdf38d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"c97be772c719491895037f89af3e43f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3baf55c1a91a481db9eea0f3c9736363":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4ce2a76cbf747ea824b295034e70f59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c926fb9ee241619a2b7b943263631f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"51b23c5ba4d04218a3d3b68107a4ea4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a98f970368204ca58af0369f7f0cc475":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8a16f0d6eb84c1b8de64a9462771733":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_11900808c8d047618b269ccf3da309f9","IPY_MODEL_b354a2991f984ffbaed374a50df6dad2","IPY_MODEL_979734a842084d6caf71a542c38b9d26"],"layout":"IPY_MODEL_ef1b7e43a5f547f2ba26a4f9364656f7"}},"11900808c8d047618b269ccf3da309f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f603f3708e1d4e4caa591c0047370ada","placeholder":"​","style":"IPY_MODEL_db64a8378f1d45c392f67a34de09b7e1","value":"Validation DataLoader 0: 100%"}},"b354a2991f984ffbaed374a50df6dad2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_05f88d4a736b4990a80eead15d0581e5","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2511cb4458e4961a7df3c8ce570ae71","value":7}},"979734a842084d6caf71a542c38b9d26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dc66ddf49a84473a7d96a777618520a","placeholder":"​","style":"IPY_MODEL_6ece75e5792b42698c1e36521def9754","value":" 7/7 [00:00&lt;00:00, 142.90it/s]"}},"ef1b7e43a5f547f2ba26a4f9364656f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"f603f3708e1d4e4caa591c0047370ada":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db64a8378f1d45c392f67a34de09b7e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05f88d4a736b4990a80eead15d0581e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2511cb4458e4961a7df3c8ce570ae71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7dc66ddf49a84473a7d96a777618520a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ece75e5792b42698c1e36521def9754":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9d8f43e5eb949529a67a4ef0d0bd456":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c44b28ceaee14af284c6d4e564ae939a","IPY_MODEL_7623d6943fb54f58a963c183bef651be","IPY_MODEL_f47dd97279e346df9f4558d8c688c9ba"],"layout":"IPY_MODEL_a5bc801f087d444e958cc647f6f1ef9a"}},"c44b28ceaee14af284c6d4e564ae939a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ede3239a3924465586b64dcdecb7ca7e","placeholder":"​","style":"IPY_MODEL_3a92e126d9014c7a870661efba4455a9","value":"Validation DataLoader 0: 100%"}},"7623d6943fb54f58a963c183bef651be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_599c537a26f04bff956fda0a12934aae","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a6aad0c508d4ff1ae67f697867d9512","value":7}},"f47dd97279e346df9f4558d8c688c9ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ff188065a2042eab7193267a423300e","placeholder":"​","style":"IPY_MODEL_f8dde9d3af194ba28c37cfe04c96bbae","value":" 7/7 [00:00&lt;00:00, 136.80it/s]"}},"a5bc801f087d444e958cc647f6f1ef9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"ede3239a3924465586b64dcdecb7ca7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a92e126d9014c7a870661efba4455a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"599c537a26f04bff956fda0a12934aae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a6aad0c508d4ff1ae67f697867d9512":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ff188065a2042eab7193267a423300e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8dde9d3af194ba28c37cfe04c96bbae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6cfcb5eb068444a98b093f94c2f3167":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4dd50c2cc3f4bb888a9fce62052b711","IPY_MODEL_161351c188a1476fb5eec10baca12eeb","IPY_MODEL_2e800e5ad2aa417fa6bc176b57f0b14b"],"layout":"IPY_MODEL_7f75122b2afa4058b6ef34ea67d748fd"}},"b4dd50c2cc3f4bb888a9fce62052b711":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a54a3f9aab5449baa7cc75cd5bf17ad6","placeholder":"​","style":"IPY_MODEL_66911624d0ae4b25a6dc1e4528e306b7","value":"Validation DataLoader 0: 100%"}},"161351c188a1476fb5eec10baca12eeb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c23b5928b604ff2a235a10b0543a6ca","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f1866df06e55482981ad02f3916e973a","value":7}},"2e800e5ad2aa417fa6bc176b57f0b14b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b900d8432d44b3b8c78fef508466188","placeholder":"​","style":"IPY_MODEL_e08f352ccca24695b9b164f52606b1f3","value":" 7/7 [00:00&lt;00:00, 141.82it/s]"}},"7f75122b2afa4058b6ef34ea67d748fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"a54a3f9aab5449baa7cc75cd5bf17ad6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66911624d0ae4b25a6dc1e4528e306b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c23b5928b604ff2a235a10b0543a6ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1866df06e55482981ad02f3916e973a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b900d8432d44b3b8c78fef508466188":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e08f352ccca24695b9b164f52606b1f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c052c85e1224d7bbb2f6b9e4f3c60c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfdd0a8c83444280a306d56ba7f14871","IPY_MODEL_8760ec82616a49669c9d5c6d0a258498","IPY_MODEL_14a2028d0c2b450ca2e1f2a22a0b3846"],"layout":"IPY_MODEL_19cf81201f904defa13b6c09e5dc392b"}},"bfdd0a8c83444280a306d56ba7f14871":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ad51cd502a346c884885357c63a5aa2","placeholder":"​","style":"IPY_MODEL_07902ee6c11e4ff78795677779814997","value":"Validation DataLoader 0: 100%"}},"8760ec82616a49669c9d5c6d0a258498":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bd3c88b5e7a4bf99eb01d7ebfaca511","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_905a7c981be44f58b67ab017dd98d728","value":7}},"14a2028d0c2b450ca2e1f2a22a0b3846":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c55f25410e1b43979cd160a9697c2852","placeholder":"​","style":"IPY_MODEL_7198591bd8554deaaeca5ad789c1a0a9","value":" 7/7 [00:00&lt;00:00, 134.93it/s]"}},"19cf81201f904defa13b6c09e5dc392b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"6ad51cd502a346c884885357c63a5aa2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07902ee6c11e4ff78795677779814997":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bd3c88b5e7a4bf99eb01d7ebfaca511":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"905a7c981be44f58b67ab017dd98d728":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c55f25410e1b43979cd160a9697c2852":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7198591bd8554deaaeca5ad789c1a0a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"826015724d314995a7403ab959033670":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53838c2992814d55aa73ecb16233ea18","IPY_MODEL_dbd27adf5fe2420caef4a629f2346f63","IPY_MODEL_617f09d177e94b5e8ae858cd0d626e0a"],"layout":"IPY_MODEL_f78ec9781d274716a6c142fefba8eecf"}},"53838c2992814d55aa73ecb16233ea18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9e17f316ea04f239c85b35032796550","placeholder":"​","style":"IPY_MODEL_7c6ff1f800a4432bb77fd3e67cf986c0","value":"Validation DataLoader 0: 100%"}},"dbd27adf5fe2420caef4a629f2346f63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e173ddff2ab46a0a51123774674203b","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd0f6165a78a4958b7e518f5fe164f2b","value":7}},"617f09d177e94b5e8ae858cd0d626e0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04ddee2aa9754aa2b71e87424ca7fcf2","placeholder":"​","style":"IPY_MODEL_10143be6c3ed4d09b38ccedb49c4914e","value":" 7/7 [00:00&lt;00:00, 111.82it/s]"}},"f78ec9781d274716a6c142fefba8eecf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"d9e17f316ea04f239c85b35032796550":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c6ff1f800a4432bb77fd3e67cf986c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e173ddff2ab46a0a51123774674203b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd0f6165a78a4958b7e518f5fe164f2b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04ddee2aa9754aa2b71e87424ca7fcf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10143be6c3ed4d09b38ccedb49c4914e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e58fea50b9f436c8a672b9c32dff8ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_55c87e6b724f407886a9508599c4e003","IPY_MODEL_488f9a6c4feb4319a5a80d3518a466d4","IPY_MODEL_86355a0b1c0d4f70a18e29b22df3e140"],"layout":"IPY_MODEL_bb23762ecdac457cb80767f474672a51"}},"55c87e6b724f407886a9508599c4e003":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffd1e5d3a8db4cf9a39956b3b0559551","placeholder":"​","style":"IPY_MODEL_7dfe6646658145c9a45d9ab680865c6f","value":"Validation DataLoader 0: 100%"}},"488f9a6c4feb4319a5a80d3518a466d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7b407abd4b14d008682b5014d9f981e","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8d25a0e3abb414dbdc80c33adb625e7","value":7}},"86355a0b1c0d4f70a18e29b22df3e140":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6725426642b84d138ce6c23d4b1895bf","placeholder":"​","style":"IPY_MODEL_544c7886a8b84580813dd4d77226ed88","value":" 7/7 [00:00&lt;00:00, 148.72it/s]"}},"bb23762ecdac457cb80767f474672a51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"ffd1e5d3a8db4cf9a39956b3b0559551":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dfe6646658145c9a45d9ab680865c6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7b407abd4b14d008682b5014d9f981e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8d25a0e3abb414dbdc80c33adb625e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6725426642b84d138ce6c23d4b1895bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"544c7886a8b84580813dd4d77226ed88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9d837b626bb491a94a881ee05280ed8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22cba3e451bf4d7cadf291d8a7cf660e","IPY_MODEL_e5321a75b1b54ae39989febfa7e22ca9","IPY_MODEL_416a48a575fa44e9b8df78e7aa4c751f"],"layout":"IPY_MODEL_75c201ace32845a8886adac6c5a0e338"}},"22cba3e451bf4d7cadf291d8a7cf660e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_916fcac99ba34221b204bdf4d4e3f7f9","placeholder":"​","style":"IPY_MODEL_37322713f89a42acb03c5ee5373dc3ab","value":"Validation DataLoader 0: 100%"}},"e5321a75b1b54ae39989febfa7e22ca9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a188288e4b324e4b8128a8f81063c468","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b388591ab4c41418bf48c358fba9b85","value":7}},"416a48a575fa44e9b8df78e7aa4c751f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de81021d497747a6a5cb988387b00d52","placeholder":"​","style":"IPY_MODEL_e986fbc355d7444b83cd16b843d2f695","value":" 7/7 [00:00&lt;00:00, 150.06it/s]"}},"75c201ace32845a8886adac6c5a0e338":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"916fcac99ba34221b204bdf4d4e3f7f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37322713f89a42acb03c5ee5373dc3ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a188288e4b324e4b8128a8f81063c468":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b388591ab4c41418bf48c358fba9b85":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de81021d497747a6a5cb988387b00d52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e986fbc355d7444b83cd16b843d2f695":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ddf00daf9be4fc1b8fb452ca74e8c6e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8121b8b907554fa9a743106b7f8b9297","IPY_MODEL_c847fd7ba10846c4b38b64ff75fdc041","IPY_MODEL_3167240a7e71450f9bf0168c03ebab64"],"layout":"IPY_MODEL_63ab9526dbed41569293c18458805acb"}},"8121b8b907554fa9a743106b7f8b9297":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6267be6a782d431d84b57f7d63b44248","placeholder":"​","style":"IPY_MODEL_273ec0404add4daaa4bc26d2d865fbab","value":"Predicting DataLoader 0: 100%"}},"c847fd7ba10846c4b38b64ff75fdc041":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2acb3b27088440bc881ed132c97685b3","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66322c8b32d042829a8524e6bb8cf7c8","value":7}},"3167240a7e71450f9bf0168c03ebab64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_065e88082eb84efcbb8b6c2ef1b2591b","placeholder":"​","style":"IPY_MODEL_d5a2ae780ee3466fb8ad04da20309907","value":" 7/7 [00:00&lt;00:00, 134.09it/s]"}},"63ab9526dbed41569293c18458805acb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"6267be6a782d431d84b57f7d63b44248":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"273ec0404add4daaa4bc26d2d865fbab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2acb3b27088440bc881ed132c97685b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66322c8b32d042829a8524e6bb8cf7c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"065e88082eb84efcbb8b6c2ef1b2591b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5a2ae780ee3466fb8ad04da20309907":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57e2ab30cac24e45b5caaf72111c7899":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ddcbb3361dc84b0eadb4ddd3e8a74987","IPY_MODEL_cd54f1fbf62640f090f825f9a1b8f70e","IPY_MODEL_3103cdc549ef436f823aec4a6d98c235"],"layout":"IPY_MODEL_98f32d9b609a4ccc915f4b0425fb4e43"}},"ddcbb3361dc84b0eadb4ddd3e8a74987":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a0819053cb34fefb228a3132eee5263","placeholder":"​","style":"IPY_MODEL_b6517488583e44f7bd5b802337c3a89b","value":"Predicting DataLoader 0: 100%"}},"cd54f1fbf62640f090f825f9a1b8f70e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51070bd257904194b326bc4782ed8761","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57c4a083be4f4d6bbe7acdf4c112ef3c","value":7}},"3103cdc549ef436f823aec4a6d98c235":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c889cd639d62452ba0c483e702ac9eb0","placeholder":"​","style":"IPY_MODEL_f9a525bec3bc497cb2acbd8d78d56573","value":" 7/7 [00:00&lt;00:00, 145.19it/s]"}},"98f32d9b609a4ccc915f4b0425fb4e43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"4a0819053cb34fefb228a3132eee5263":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6517488583e44f7bd5b802337c3a89b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51070bd257904194b326bc4782ed8761":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57c4a083be4f4d6bbe7acdf4c112ef3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c889cd639d62452ba0c483e702ac9eb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9a525bec3bc497cb2acbd8d78d56573":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9070f3e2bb35405db17d4ad239f0f157":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec3e5eaea8ca4337856b4f0729a1b34e","IPY_MODEL_95e23a20c821441c8b73bb96a7be37c9","IPY_MODEL_9c4e05b0f46b4d6790d66b5323b29594"],"layout":"IPY_MODEL_e27f7ec405e74ce5bd3c801dd334041d"}},"ec3e5eaea8ca4337856b4f0729a1b34e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73eba21eec8a4dabad72afd0ff102f1d","placeholder":"​","style":"IPY_MODEL_b7faae5fce1b4711be82a2483cbf9b19","value":"Sanity Checking DataLoader 0: 100%"}},"95e23a20c821441c8b73bb96a7be37c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_184be2e83bb849cfaf78443b37b95ef5","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_602c3a3fcf544712b0c008eb3ef73f92","value":2}},"9c4e05b0f46b4d6790d66b5323b29594":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a0afc555b5d406a8fa4bef3ca181444","placeholder":"​","style":"IPY_MODEL_92e7beb37bd04a219eec770e0acd1df1","value":" 2/2 [00:00&lt;00:00, 76.58it/s]"}},"e27f7ec405e74ce5bd3c801dd334041d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"73eba21eec8a4dabad72afd0ff102f1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7faae5fce1b4711be82a2483cbf9b19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"184be2e83bb849cfaf78443b37b95ef5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"602c3a3fcf544712b0c008eb3ef73f92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a0afc555b5d406a8fa4bef3ca181444":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92e7beb37bd04a219eec770e0acd1df1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab653e2090784bd08aadcd1643125b69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_20a25d45ba0547f1aec605d330718a0f","IPY_MODEL_e83b22ca655649fbad253742bc73e1ad","IPY_MODEL_51bbf34dcb374025a279030bc260540f"],"layout":"IPY_MODEL_10e5bbb763d34a8881f39329dc84a89a"}},"20a25d45ba0547f1aec605d330718a0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fcba674633a445eb9eeb6988dafe5f2","placeholder":"​","style":"IPY_MODEL_6c298ed584ae4d338b02ba25b35aa1ce","value":"Epoch 64:   0%"}},"e83b22ca655649fbad253742bc73e1ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_42c06b741d4449e596d0cd3d2fa94e09","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1ac9fb03d21448c9ddf6bcb08fc3ba1","value":0}},"51bbf34dcb374025a279030bc260540f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_485e45b552fa4f1b89fe48231612f859","placeholder":"​","style":"IPY_MODEL_e2b957fcd3fc4032be72501bd6fdd44d","value":" 0/7 [00:00&lt;?, ?it/s, v_num=4, train_loss_step=1.090, train_loss_epoch=1.040, valid_loss=1.010]"}},"10e5bbb763d34a8881f39329dc84a89a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"9fcba674633a445eb9eeb6988dafe5f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c298ed584ae4d338b02ba25b35aa1ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42c06b741d4449e596d0cd3d2fa94e09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1ac9fb03d21448c9ddf6bcb08fc3ba1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"485e45b552fa4f1b89fe48231612f859":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2b957fcd3fc4032be72501bd6fdd44d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0168e8f930ab4283be0ea80a7c4649a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_351a2cdd427a4463a18e5d77d33e3c47","IPY_MODEL_baa4ea06e35f4cb6b5c5fb530c70ed5c","IPY_MODEL_ac6a3bfc88f54644bc373e896d8e38b1"],"layout":"IPY_MODEL_75c307c1935e442c8deb6b188ff2b918"}},"351a2cdd427a4463a18e5d77d33e3c47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb35a1880fa44832b328b3ca8f234b0f","placeholder":"​","style":"IPY_MODEL_2d9c6f86a16c47a2be9404a5f8c1c8ca","value":"Validation DataLoader 0: 100%"}},"baa4ea06e35f4cb6b5c5fb530c70ed5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f454957b8dc34966999cd075ce5ea407","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c837d20e19a14f28b9a95e2aad156ad2","value":7}},"ac6a3bfc88f54644bc373e896d8e38b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f8c0768db2542209bfd5525b085af6a","placeholder":"​","style":"IPY_MODEL_bc3433f738cf40df8ab55e37580e4725","value":" 7/7 [00:00&lt;00:00, 84.58it/s]"}},"75c307c1935e442c8deb6b188ff2b918":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"eb35a1880fa44832b328b3ca8f234b0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d9c6f86a16c47a2be9404a5f8c1c8ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f454957b8dc34966999cd075ce5ea407":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c837d20e19a14f28b9a95e2aad156ad2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f8c0768db2542209bfd5525b085af6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc3433f738cf40df8ab55e37580e4725":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0628a4d4837464dae68515c6520b5a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0140f0fcb51145e9998fb009c74823aa","IPY_MODEL_0b3bfe3a407d4c878fab938b4618b5b8","IPY_MODEL_d9ef017410c34d899b06b3e7f8123de6"],"layout":"IPY_MODEL_12cacbfa26aa4c14acdaf72b09e8c189"}},"0140f0fcb51145e9998fb009c74823aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bab729defc1406c9647e832f7b40c86","placeholder":"​","style":"IPY_MODEL_c87763104ffc4adbaa593a7882c3b246","value":"Validation DataLoader 0: 100%"}},"0b3bfe3a407d4c878fab938b4618b5b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d8d595f59ec47c18a9c849c45ed4441","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e62a4fcb1df04f4b97a17483c0d822b6","value":7}},"d9ef017410c34d899b06b3e7f8123de6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51f55f959f42499b9ca8dc10d0da9a0c","placeholder":"​","style":"IPY_MODEL_45df5fac704c40ddb803774f10dc91c3","value":" 7/7 [00:00&lt;00:00, 94.01it/s]"}},"12cacbfa26aa4c14acdaf72b09e8c189":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"9bab729defc1406c9647e832f7b40c86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c87763104ffc4adbaa593a7882c3b246":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d8d595f59ec47c18a9c849c45ed4441":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e62a4fcb1df04f4b97a17483c0d822b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"51f55f959f42499b9ca8dc10d0da9a0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45df5fac704c40ddb803774f10dc91c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89888f516ea0447d9934b623b3e3a8fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05a2190005544464823862097e666b30","IPY_MODEL_c3684c83ac3442c2ac2aa1630970cfef","IPY_MODEL_206bce365a30408a8d36914a5ca6b651"],"layout":"IPY_MODEL_b7ae60f48c4045abba21ee53f6ae25e9"}},"05a2190005544464823862097e666b30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54feb72462494b169e52d4c7fa76d9ce","placeholder":"​","style":"IPY_MODEL_3da04144c79d439cb47c1a6f55fec249","value":"Validation DataLoader 0: 100%"}},"c3684c83ac3442c2ac2aa1630970cfef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_121c5c30b9614903aceee5ce9267d521","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6cf8f71d95544dd0b0ca332aa637178d","value":7}},"206bce365a30408a8d36914a5ca6b651":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9af484211a5f483c95bf87553c449aa2","placeholder":"​","style":"IPY_MODEL_fafdcac4b9c54bf3b20297964252b413","value":" 7/7 [00:00&lt;00:00, 119.24it/s]"}},"b7ae60f48c4045abba21ee53f6ae25e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"54feb72462494b169e52d4c7fa76d9ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3da04144c79d439cb47c1a6f55fec249":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"121c5c30b9614903aceee5ce9267d521":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cf8f71d95544dd0b0ca332aa637178d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9af484211a5f483c95bf87553c449aa2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fafdcac4b9c54bf3b20297964252b413":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1b3aaa201614d31af882e5f70a0ef36":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da38df7dbd7a4d93a9d4d32f29df8df2","IPY_MODEL_84a0685284b44ae497c3f3b39e4032df","IPY_MODEL_ec6c86d5b8fa4241a413da7089618b04"],"layout":"IPY_MODEL_510e425ac3c74c4d9aff3a59cd6ffd1a"}},"da38df7dbd7a4d93a9d4d32f29df8df2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_927259a7f4d540b19a58873d411e3732","placeholder":"​","style":"IPY_MODEL_c9e9c0006f51403eb2f423c49d843261","value":"Validation DataLoader 0: 100%"}},"84a0685284b44ae497c3f3b39e4032df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a9a23022deb4313835f981e28b8c4a6","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6826609626624e9fbd32897316885c6e","value":7}},"ec6c86d5b8fa4241a413da7089618b04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f34b146efb4b40a198ba1ae2bc3cae5f","placeholder":"​","style":"IPY_MODEL_acfdf8dbfc814c8eb2b474535e95251a","value":" 7/7 [00:00&lt;00:00, 97.11it/s]"}},"510e425ac3c74c4d9aff3a59cd6ffd1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"927259a7f4d540b19a58873d411e3732":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9e9c0006f51403eb2f423c49d843261":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a9a23022deb4313835f981e28b8c4a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6826609626624e9fbd32897316885c6e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f34b146efb4b40a198ba1ae2bc3cae5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acfdf8dbfc814c8eb2b474535e95251a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd8fba7745ac48f7afc4a0b23377b0d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2641b22ea7b441bd8848b027c4066050","IPY_MODEL_691bf393bf2a462bbc69db9d48ba31a9","IPY_MODEL_91d2477fbd6d4e83bfd5b21b7237a13e"],"layout":"IPY_MODEL_aa396bc8f10d4067ab9e1d406d223410"}},"2641b22ea7b441bd8848b027c4066050":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f43c012513824c8d9460ffa2f0e65ddf","placeholder":"​","style":"IPY_MODEL_a2059be4644649bb9bc6909936067c06","value":"Validation DataLoader 0: 100%"}},"691bf393bf2a462bbc69db9d48ba31a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_24afc46bd13241f3aea13fbd8e1e3029","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e31eb08aaeb4deabe91c9a33c8f8c40","value":7}},"91d2477fbd6d4e83bfd5b21b7237a13e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16a8e3acc7f64ac5b6394bd2dbce9410","placeholder":"​","style":"IPY_MODEL_3ad0181ac01e43cabf3fffd8c5ed7061","value":" 7/7 [00:00&lt;00:00, 120.17it/s]"}},"aa396bc8f10d4067ab9e1d406d223410":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"f43c012513824c8d9460ffa2f0e65ddf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2059be4644649bb9bc6909936067c06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24afc46bd13241f3aea13fbd8e1e3029":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e31eb08aaeb4deabe91c9a33c8f8c40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16a8e3acc7f64ac5b6394bd2dbce9410":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ad0181ac01e43cabf3fffd8c5ed7061":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35e24355d05347a2bbd2db21b23eb54c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a9c01a291a44d6bb5c53e759c550651","IPY_MODEL_3595807ddfc242d197f564e655c6037d","IPY_MODEL_1d7ec36a34fd4cc5b7563d9fd1b458e5"],"layout":"IPY_MODEL_c8af2d4fb81d43a984d8973b245187ac"}},"6a9c01a291a44d6bb5c53e759c550651":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75d13251e6b44a8eaf7236307d7e06c0","placeholder":"​","style":"IPY_MODEL_cb1ea16d3f124784b84ff5e594baf319","value":"Validation DataLoader 0: 100%"}},"3595807ddfc242d197f564e655c6037d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3528ff66184f413981ccaa19558a314b","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06ac04ce0c664a31a248d7b1a5260451","value":7}},"1d7ec36a34fd4cc5b7563d9fd1b458e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d478de58bc546d5b7bb739aa864fb48","placeholder":"​","style":"IPY_MODEL_58a7cc9b5eb644698456f4c3e8fc602b","value":" 7/7 [00:00&lt;00:00, 100.80it/s]"}},"c8af2d4fb81d43a984d8973b245187ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"75d13251e6b44a8eaf7236307d7e06c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb1ea16d3f124784b84ff5e594baf319":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3528ff66184f413981ccaa19558a314b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06ac04ce0c664a31a248d7b1a5260451":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d478de58bc546d5b7bb739aa864fb48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58a7cc9b5eb644698456f4c3e8fc602b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df15a760b3564853a4ec69ea35d3b762":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dcc8571867dc4cde9dae04a03c4af981","IPY_MODEL_fa2ef909e39246dca41f30f399430078","IPY_MODEL_d76cf8cf06c54f3faf27a0b179a62303"],"layout":"IPY_MODEL_76e665cf6d23452e9c14b6b7153b188a"}},"dcc8571867dc4cde9dae04a03c4af981":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d975d72b90de41f295db3c920e2e59a4","placeholder":"​","style":"IPY_MODEL_93fc07b1480b42f991177f6f68970d05","value":"Validation DataLoader 0: 100%"}},"fa2ef909e39246dca41f30f399430078":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e43dc314a0043ee9899b5d4e886aa31","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96a34c95ef8c4ce1b9fc58f7455663ef","value":7}},"d76cf8cf06c54f3faf27a0b179a62303":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9186895ae6545f39768c6757ada1fa3","placeholder":"​","style":"IPY_MODEL_3857faa149c94249b78112356e95f66a","value":" 7/7 [00:00&lt;00:00, 121.93it/s]"}},"76e665cf6d23452e9c14b6b7153b188a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"d975d72b90de41f295db3c920e2e59a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93fc07b1480b42f991177f6f68970d05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e43dc314a0043ee9899b5d4e886aa31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96a34c95ef8c4ce1b9fc58f7455663ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9186895ae6545f39768c6757ada1fa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3857faa149c94249b78112356e95f66a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e69a7c6eea384c4f9e8d622316064ef3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6087ffff11c841ee8c35552f67ed94d9","IPY_MODEL_9d411f384c624264ba8b1b02cd6bb121","IPY_MODEL_78f98a9249814578a728ceaf4498a558"],"layout":"IPY_MODEL_08e32e69767b4bcabb5864c6b58287ae"}},"6087ffff11c841ee8c35552f67ed94d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e59b45af2540499aa41f682b35a40fe6","placeholder":"​","style":"IPY_MODEL_0abd3e9365914371b19c43f47df090c7","value":"Validation DataLoader 0: 100%"}},"9d411f384c624264ba8b1b02cd6bb121":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_627bfb18264444e4883a21f4c4769e95","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dde0678a614f437a8beb300f6fd128e1","value":7}},"78f98a9249814578a728ceaf4498a558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bebe079618e64694b0328236e1e57381","placeholder":"​","style":"IPY_MODEL_ad32bab9eccf48e7ae2d82de89da9d43","value":" 7/7 [00:00&lt;00:00, 130.97it/s]"}},"08e32e69767b4bcabb5864c6b58287ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"e59b45af2540499aa41f682b35a40fe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0abd3e9365914371b19c43f47df090c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"627bfb18264444e4883a21f4c4769e95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dde0678a614f437a8beb300f6fd128e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bebe079618e64694b0328236e1e57381":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad32bab9eccf48e7ae2d82de89da9d43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db7f3c2467e64d769204b8be8569483f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7bfd54c125aa43f28cb018d87ad28307","IPY_MODEL_7265c85d59c5471891b4adddbc96a2e1","IPY_MODEL_515d48e6fa2b4718bbb57a2b5e1d1dd6"],"layout":"IPY_MODEL_b77b1b091878409e9b0f9ef4e7cb150a"}},"7bfd54c125aa43f28cb018d87ad28307":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfe11d9025f9471fbc0573fe8a64a1cf","placeholder":"​","style":"IPY_MODEL_63cc09fca880482eb993e5984a480431","value":"Validation DataLoader 0: 100%"}},"7265c85d59c5471891b4adddbc96a2e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce37a2c0f003405784d643e79ac7ee2c","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0436299a39914082a7a39ccb29c2fa24","value":7}},"515d48e6fa2b4718bbb57a2b5e1d1dd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41d1401be8fe4564bbf38a3ec49937cc","placeholder":"​","style":"IPY_MODEL_9fa310220fbc40018b44b3959b78d5fc","value":" 7/7 [00:00&lt;00:00, 132.64it/s]"}},"b77b1b091878409e9b0f9ef4e7cb150a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"bfe11d9025f9471fbc0573fe8a64a1cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63cc09fca880482eb993e5984a480431":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce37a2c0f003405784d643e79ac7ee2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0436299a39914082a7a39ccb29c2fa24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"41d1401be8fe4564bbf38a3ec49937cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fa310220fbc40018b44b3959b78d5fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d28b930d40044e77b470c56a6c321b51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbe89b07fc7740098781eba8ecb0b592","IPY_MODEL_5b2f17b3c1a54088a0380ea415b969d3","IPY_MODEL_0427a3764fe94533ad1fd287f9365b58"],"layout":"IPY_MODEL_ee8c492ba8744956b880572cf4183f6c"}},"fbe89b07fc7740098781eba8ecb0b592":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ac3556b8366491086c274e3e19ae516","placeholder":"​","style":"IPY_MODEL_05fee127d96f48a0bb81c73df2feb929","value":"Predicting DataLoader 0: 100%"}},"5b2f17b3c1a54088a0380ea415b969d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a0df1bc78f0417e8370bbed8e1abd5c","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5cee77b01f0c47c699bda9527946082c","value":7}},"0427a3764fe94533ad1fd287f9365b58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e6488ca1abf4fa8ab3668a3d0f87435","placeholder":"​","style":"IPY_MODEL_f7d71a18ec7249d6a4cea9087d94e999","value":" 7/7 [00:00&lt;00:00, 180.06it/s]"}},"ee8c492ba8744956b880572cf4183f6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"6ac3556b8366491086c274e3e19ae516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05fee127d96f48a0bb81c73df2feb929":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a0df1bc78f0417e8370bbed8e1abd5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cee77b01f0c47c699bda9527946082c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e6488ca1abf4fa8ab3668a3d0f87435":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7d71a18ec7249d6a4cea9087d94e999":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6efca17fb83447a591cdc611e6753eab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_15cc7e5cca874effb8729df5cfdb841a","IPY_MODEL_32c6cbc9f54440e0be95d418eda8c06a","IPY_MODEL_834c8041099b43eaaa19e4424d6210f4"],"layout":"IPY_MODEL_12328798990144fab29e287d80ad44de"}},"15cc7e5cca874effb8729df5cfdb841a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9075bf8a37da4d4da3065f76ff315c6f","placeholder":"​","style":"IPY_MODEL_88935f1ef51a4b148be24a95a7c5668a","value":"Sanity Checking DataLoader 0: 100%"}},"32c6cbc9f54440e0be95d418eda8c06a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f40cf9577e834098bf1137b82ef50e8c","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40c69e05d2064019a508742496edf8cd","value":2}},"834c8041099b43eaaa19e4424d6210f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aae5ffd23154146adb09cc20a442e2f","placeholder":"​","style":"IPY_MODEL_7242b694a5884dd486cfc4b55521d2cc","value":" 2/2 [00:00&lt;00:00, 119.55it/s]"}},"12328798990144fab29e287d80ad44de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"9075bf8a37da4d4da3065f76ff315c6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88935f1ef51a4b148be24a95a7c5668a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f40cf9577e834098bf1137b82ef50e8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40c69e05d2064019a508742496edf8cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1aae5ffd23154146adb09cc20a442e2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7242b694a5884dd486cfc4b55521d2cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2181d5886404a8eb26579e7c10c7d1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b453d4a142be4154bffa3b8d2acd000b","IPY_MODEL_d085dfa351354e73823eda7fbc20c3e3","IPY_MODEL_ecbf18929b77455bbceccf321e991a5b"],"layout":"IPY_MODEL_217f5a5f2dde457eba9c63a0b5a5a23c"}},"b453d4a142be4154bffa3b8d2acd000b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b08029de6a949afb6b0a51e74a2daa7","placeholder":"​","style":"IPY_MODEL_616c76edb7eb496e957efc77846e7116","value":"Epoch 142:   0%"}},"d085dfa351354e73823eda7fbc20c3e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_421388e54fa648f28665d378205b47aa","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ca68e11965d402590e4168419ee2337","value":0}},"ecbf18929b77455bbceccf321e991a5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c4c4b8d043a4379beda87d23fdfd3c2","placeholder":"​","style":"IPY_MODEL_453d9f37918348539c2d0a24a8c2f743","value":" 0/7 [00:00&lt;?, ?it/s, v_num=6, train_loss_step=1.310, train_loss_epoch=1.300, valid_loss=1.040]"}},"217f5a5f2dde457eba9c63a0b5a5a23c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"5b08029de6a949afb6b0a51e74a2daa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"616c76edb7eb496e957efc77846e7116":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"421388e54fa648f28665d378205b47aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ca68e11965d402590e4168419ee2337":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c4c4b8d043a4379beda87d23fdfd3c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"453d9f37918348539c2d0a24a8c2f743":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db681488593840d6ada54fc0c76617c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7655df7ee30412bba68c3c67d9f75e0","IPY_MODEL_779ea11f378b482abdba7474cdc08d84","IPY_MODEL_f417dfff84af4664adc81afa45b76f3d"],"layout":"IPY_MODEL_d758ce2ec201470194cfbd92d9af9128"}},"e7655df7ee30412bba68c3c67d9f75e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd0ca77ffda64078a3214094c6bda709","placeholder":"​","style":"IPY_MODEL_cf404db9b4be44c9968206342e96e250","value":"Validation DataLoader 0: 100%"}},"779ea11f378b482abdba7474cdc08d84":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_585c0b53be0f48ce9b231610bc0ea4ea","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ebb5625904449c1aa394941418279ce","value":7}},"f417dfff84af4664adc81afa45b76f3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ab427fcc3814bd18e69c3626b694c1c","placeholder":"​","style":"IPY_MODEL_00e62b139293425aa1d656a08a0939f8","value":" 7/7 [00:00&lt;00:00, 115.32it/s]"}},"d758ce2ec201470194cfbd92d9af9128":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"cd0ca77ffda64078a3214094c6bda709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf404db9b4be44c9968206342e96e250":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"585c0b53be0f48ce9b231610bc0ea4ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ebb5625904449c1aa394941418279ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ab427fcc3814bd18e69c3626b694c1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00e62b139293425aa1d656a08a0939f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54d5f56a12354d1c9c5de34449d2c9c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4db9ac09a39d4275af19230c1e1aa9f5","IPY_MODEL_1f73c26e98004549b27bdce5b6e2098c","IPY_MODEL_33c8d6cf74074b82847a8915d2716664"],"layout":"IPY_MODEL_6f04c64361e94f718250332b5042b632"}},"4db9ac09a39d4275af19230c1e1aa9f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a156f3536cc482f905a74d5931db6ed","placeholder":"​","style":"IPY_MODEL_71cb740fa3e94bb6a9925a4f02d2ffcb","value":"Validation DataLoader 0: 100%"}},"1f73c26e98004549b27bdce5b6e2098c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_38fc104a45a04382b254d62669f1a90c","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d8b25b92ec540be9243c63519a14fb1","value":7}},"33c8d6cf74074b82847a8915d2716664":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc738de280444fb29a6d490028878306","placeholder":"​","style":"IPY_MODEL_0e018d13b32741aeb83583a04ed90018","value":" 7/7 [00:00&lt;00:00, 119.87it/s]"}},"6f04c64361e94f718250332b5042b632":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"9a156f3536cc482f905a74d5931db6ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71cb740fa3e94bb6a9925a4f02d2ffcb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38fc104a45a04382b254d62669f1a90c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d8b25b92ec540be9243c63519a14fb1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc738de280444fb29a6d490028878306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e018d13b32741aeb83583a04ed90018":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71decdc5b01d4006ba082ac2479849d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c24d9b0cee740948815e9ed0fd68fb9","IPY_MODEL_366060b27401457e8ce7cebfae1aac2d","IPY_MODEL_2a2bf743ea494395883d14af637b895e"],"layout":"IPY_MODEL_17580c1156904f0db53fef2f25aa464b"}},"8c24d9b0cee740948815e9ed0fd68fb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb5486fdc3e8457287b4b28e76bd0f67","placeholder":"​","style":"IPY_MODEL_95e55018b5f24399bacb5e8389cf4061","value":"Validation DataLoader 0: 100%"}},"366060b27401457e8ce7cebfae1aac2d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_130892ca49ea4522a4f9b2931e5e5abe","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2025e0ee545840d4adc734970e8fa63b","value":7}},"2a2bf743ea494395883d14af637b895e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a2abce31e554c37995cbc701617fefc","placeholder":"​","style":"IPY_MODEL_0d2106fd3ed14a6398283005f11dc617","value":" 7/7 [00:00&lt;00:00, 129.07it/s]"}},"17580c1156904f0db53fef2f25aa464b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"bb5486fdc3e8457287b4b28e76bd0f67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95e55018b5f24399bacb5e8389cf4061":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"130892ca49ea4522a4f9b2931e5e5abe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2025e0ee545840d4adc734970e8fa63b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a2abce31e554c37995cbc701617fefc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d2106fd3ed14a6398283005f11dc617":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"056bdfbf47654a56bc2dd24e9e716f82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd3a7f9f7852420881a694eb8d9068fd","IPY_MODEL_62b8cde6a31e4491bd4e7bc568a01a04","IPY_MODEL_4ef08039cde14b9bbf1b7568777e32b9"],"layout":"IPY_MODEL_18bd7cd331fb45bba05a153f9feca00e"}},"cd3a7f9f7852420881a694eb8d9068fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf2df69129684f2bab1c84a8b1aca3e4","placeholder":"​","style":"IPY_MODEL_ae591a0bd60243edad58c9470d31a127","value":"Validation DataLoader 0: 100%"}},"62b8cde6a31e4491bd4e7bc568a01a04":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7119da71288a4a64826c5d76ae9641df","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c61e3242ec6c46b9aab4197fac05f08f","value":7}},"4ef08039cde14b9bbf1b7568777e32b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3b537745299439b8272553fb6f41b2b","placeholder":"​","style":"IPY_MODEL_af502f81c97b4c90b9f2c0f6d32d7f8b","value":" 7/7 [00:00&lt;00:00, 111.75it/s]"}},"18bd7cd331fb45bba05a153f9feca00e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"cf2df69129684f2bab1c84a8b1aca3e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae591a0bd60243edad58c9470d31a127":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7119da71288a4a64826c5d76ae9641df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c61e3242ec6c46b9aab4197fac05f08f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3b537745299439b8272553fb6f41b2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af502f81c97b4c90b9f2c0f6d32d7f8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"379aad276713407ca5ef3ce3a1f45113":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94198cb801634ece8dce354a781f93af","IPY_MODEL_83ea4c43468b4bfc8247b7d397c21625","IPY_MODEL_953a72feaa7f41abbc83d95e75233242"],"layout":"IPY_MODEL_71e8857016834e7d9f2c9b36f4298336"}},"94198cb801634ece8dce354a781f93af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d416fbc346b425ab56bc1e34a57ccf5","placeholder":"​","style":"IPY_MODEL_5579d69fcf464d4884decec5304e43cb","value":"Validation DataLoader 0: 100%"}},"83ea4c43468b4bfc8247b7d397c21625":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b20b76341c88435e93cfb55be6db267d","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_908a27bf3a224fc78b16e32f39357077","value":7}},"953a72feaa7f41abbc83d95e75233242":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_650d4529abaf499d890920ea1b45e885","placeholder":"​","style":"IPY_MODEL_c8fc31f73d1b46e09fca2104fdfb4342","value":" 7/7 [00:00&lt;00:00, 131.74it/s]"}},"71e8857016834e7d9f2c9b36f4298336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"6d416fbc346b425ab56bc1e34a57ccf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5579d69fcf464d4884decec5304e43cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b20b76341c88435e93cfb55be6db267d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"908a27bf3a224fc78b16e32f39357077":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"650d4529abaf499d890920ea1b45e885":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8fc31f73d1b46e09fca2104fdfb4342":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09de7cb0447443f1b559f9f4b9b163dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52bbf05f863f49c188c602e1814bd318","IPY_MODEL_1b9de06794db408a95a7657286350d18","IPY_MODEL_dea2527bbab54a159da687316bb392e1"],"layout":"IPY_MODEL_db39b22d1dec475883807ca832d07c22"}},"52bbf05f863f49c188c602e1814bd318":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6d487c99ac74d4997c7d33d21cbf0e0","placeholder":"​","style":"IPY_MODEL_683e190121bd472fb0df27e67182f310","value":"Validation DataLoader 0: 100%"}},"1b9de06794db408a95a7657286350d18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a11ee6704c349b1b86783b09ae6b421","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c25030b8e5f426e827a6bab74069168","value":7}},"dea2527bbab54a159da687316bb392e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe6f4246ea014b0da5632f99e3d5b160","placeholder":"​","style":"IPY_MODEL_0c4788cfc78d44e28e23906d61b633fd","value":" 7/7 [00:00&lt;00:00, 115.22it/s]"}},"db39b22d1dec475883807ca832d07c22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"e6d487c99ac74d4997c7d33d21cbf0e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"683e190121bd472fb0df27e67182f310":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a11ee6704c349b1b86783b09ae6b421":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c25030b8e5f426e827a6bab74069168":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fe6f4246ea014b0da5632f99e3d5b160":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c4788cfc78d44e28e23906d61b633fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4c9884ad7a548d3ad460a8548371f5b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5973ac594dd243d8b13b68d45216a6cb","IPY_MODEL_5078acafeb7243f48fa1b7e499527231","IPY_MODEL_0b75c54463a04eb2bc9d08d0185ec397"],"layout":"IPY_MODEL_246eaaa374e143009a679d56c273407d"}},"5973ac594dd243d8b13b68d45216a6cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_458023ddb89844b1a24bf1ba2b9ff3cd","placeholder":"​","style":"IPY_MODEL_61453188eefa4c22beedc198c106d2e6","value":"Validation DataLoader 0: 100%"}},"5078acafeb7243f48fa1b7e499527231":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1ac05d4bd1a40d5913d6b63f5f3f911","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5686130aa56d40cb95a58c3791617665","value":7}},"0b75c54463a04eb2bc9d08d0185ec397":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1a1b059663a4e9aaf37f217cad6b82e","placeholder":"​","style":"IPY_MODEL_a08cdd975d554e288c7ff1a6719495dc","value":" 7/7 [00:00&lt;00:00, 159.38it/s]"}},"246eaaa374e143009a679d56c273407d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"458023ddb89844b1a24bf1ba2b9ff3cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61453188eefa4c22beedc198c106d2e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1ac05d4bd1a40d5913d6b63f5f3f911":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5686130aa56d40cb95a58c3791617665":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1a1b059663a4e9aaf37f217cad6b82e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a08cdd975d554e288c7ff1a6719495dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6877eaf4fcab4e239e8f43867f1f31bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54a68a71f7d14d818ef308ff5a82323d","IPY_MODEL_49bc6eccbb0d47998cc96c3986b77a2b","IPY_MODEL_0bd623318a154221aad1964728fae0d4"],"layout":"IPY_MODEL_fd87d09e29e4422db4f608d03164383e"}},"54a68a71f7d14d818ef308ff5a82323d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdeae6bec38249c2b75e4391486323e5","placeholder":"​","style":"IPY_MODEL_22f4120566204891a06730a408e9e4e7","value":"Validation DataLoader 0: 100%"}},"49bc6eccbb0d47998cc96c3986b77a2b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0eacbb1b358b480996aaaed275e18b1a","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6ca46035f464d54838588600f4ab17f","value":7}},"0bd623318a154221aad1964728fae0d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_633ec8eafed348b48702d9c40491172b","placeholder":"​","style":"IPY_MODEL_3b5658c32f6a4362b4ed12d9ac1e600c","value":" 7/7 [00:00&lt;00:00, 94.92it/s]"}},"fd87d09e29e4422db4f608d03164383e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"cdeae6bec38249c2b75e4391486323e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22f4120566204891a06730a408e9e4e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0eacbb1b358b480996aaaed275e18b1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6ca46035f464d54838588600f4ab17f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"633ec8eafed348b48702d9c40491172b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b5658c32f6a4362b4ed12d9ac1e600c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"500e493d01674c2dbf7711b0a9df07fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_daf324a40fc64fc58369ef0a9f377d14","IPY_MODEL_c6e1b779df0f4114b97f4fc747cbdfc4","IPY_MODEL_f865e387e19b4aebbb76fac51a496a99"],"layout":"IPY_MODEL_47a0626df85b42e6893a06ce47aa533a"}},"daf324a40fc64fc58369ef0a9f377d14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fb64911dc604cf4af6f6a8298ffe24b","placeholder":"​","style":"IPY_MODEL_060132e2fb8d4fc4a4f56d1f3651f46e","value":"Validation DataLoader 0: 100%"}},"c6e1b779df0f4114b97f4fc747cbdfc4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6495dc51a99747fcad76c3a4af680203","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_851956fda83c4e148fc32cfd4d431f6b","value":7}},"f865e387e19b4aebbb76fac51a496a99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbf3a1c63b8f446c828e75ea5a8b2ead","placeholder":"​","style":"IPY_MODEL_3957f9c3e9dc4afe83efc93dd98a8d65","value":" 7/7 [00:00&lt;00:00, 113.91it/s]"}},"47a0626df85b42e6893a06ce47aa533a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"7fb64911dc604cf4af6f6a8298ffe24b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"060132e2fb8d4fc4a4f56d1f3651f46e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6495dc51a99747fcad76c3a4af680203":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"851956fda83c4e148fc32cfd4d431f6b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bbf3a1c63b8f446c828e75ea5a8b2ead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3957f9c3e9dc4afe83efc93dd98a8d65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64b285f7a8c4459ea96682f9bdc76638":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8effd8e67f0141d68734241dfcdc32ab","IPY_MODEL_44612bb34c594a4da62ab52ff97865d2","IPY_MODEL_4e21a36da1914e9883de7fcf560140c5"],"layout":"IPY_MODEL_deffbfac9e864783810ee41235e41ace"}},"8effd8e67f0141d68734241dfcdc32ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_405c39fb35c643f0a0139f48df77927f","placeholder":"​","style":"IPY_MODEL_4c8b701a1f3743dbb971db3028db9924","value":"Validation DataLoader 0: 100%"}},"44612bb34c594a4da62ab52ff97865d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_192eeac39fb3464bb2e59b1b6d7f3655","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5da94cf5666c4ae9ba1cfa267ff685ff","value":7}},"4e21a36da1914e9883de7fcf560140c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_650013b34c134e208a28da9f46c11134","placeholder":"​","style":"IPY_MODEL_851d729355214e8c9ae046f98c148b1f","value":" 7/7 [00:00&lt;00:00, 107.26it/s]"}},"deffbfac9e864783810ee41235e41ace":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"405c39fb35c643f0a0139f48df77927f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c8b701a1f3743dbb971db3028db9924":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"192eeac39fb3464bb2e59b1b6d7f3655":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5da94cf5666c4ae9ba1cfa267ff685ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"650013b34c134e208a28da9f46c11134":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"851d729355214e8c9ae046f98c148b1f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a755bee598644e98bb9efe910c875faa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b630c4ef5fb4a3dab5183d147c4abbe","IPY_MODEL_fe8deda93a8042beb35496356ee23d9b","IPY_MODEL_5c8d5537771e4f6f85901f37dbe1b141"],"layout":"IPY_MODEL_c4a8caf91bb54542867e63b00e628e15"}},"4b630c4ef5fb4a3dab5183d147c4abbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5254077986644ea7bb99b443681650f6","placeholder":"​","style":"IPY_MODEL_fcd35ba3f2304654b1a27a8fe55327bc","value":"Validation DataLoader 0: 100%"}},"fe8deda93a8042beb35496356ee23d9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1dc5b883a47546b08bc7baa5bc06ffaa","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_839252214fc64cab94b05e164468b62a","value":7}},"5c8d5537771e4f6f85901f37dbe1b141":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0dba8bc7b4d42648d8300568dfd5858","placeholder":"​","style":"IPY_MODEL_ff0a19562984485ebc8a84e34d53db58","value":" 7/7 [00:00&lt;00:00, 129.39it/s]"}},"c4a8caf91bb54542867e63b00e628e15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"5254077986644ea7bb99b443681650f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcd35ba3f2304654b1a27a8fe55327bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1dc5b883a47546b08bc7baa5bc06ffaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"839252214fc64cab94b05e164468b62a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0dba8bc7b4d42648d8300568dfd5858":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff0a19562984485ebc8a84e34d53db58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f17a05eb1255433e9eb8bc5517fbed8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_871d5256f77247cfaf11d336a2af37ee","IPY_MODEL_61b8bc94a6234e868b15d005c5fe141b","IPY_MODEL_abd19ca49d8849af8e5585083eb735f2"],"layout":"IPY_MODEL_706ef279f3f44c2c9c0f88636318ac3f"}},"871d5256f77247cfaf11d336a2af37ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dc6ae313ecf496fa73df2077dc5c9ba","placeholder":"​","style":"IPY_MODEL_1804d66f5c5d4b05b7d710568621ecee","value":"Validation DataLoader 0: 100%"}},"61b8bc94a6234e868b15d005c5fe141b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d02fc3cedd22478286bd5a53e5c79bfb","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_957e4c8a4cc44e4ab753324a59aabb3b","value":7}},"abd19ca49d8849af8e5585083eb735f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f33efc6d211e4c3eb86f93a5f1d2344f","placeholder":"​","style":"IPY_MODEL_61dc840f02fc4fa081363f7088454377","value":" 7/7 [00:00&lt;00:00, 90.19it/s]"}},"706ef279f3f44c2c9c0f88636318ac3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"8dc6ae313ecf496fa73df2077dc5c9ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1804d66f5c5d4b05b7d710568621ecee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d02fc3cedd22478286bd5a53e5c79bfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"957e4c8a4cc44e4ab753324a59aabb3b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f33efc6d211e4c3eb86f93a5f1d2344f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61dc840f02fc4fa081363f7088454377":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40651dea98bc4c16903d233114caff09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbf96ace8d844be5bbe94c1ae7ddbf23","IPY_MODEL_f26008c6ed434fd3a55bdd553bb081b3","IPY_MODEL_3c11dcda16a443b880a5130064346a06"],"layout":"IPY_MODEL_793369b7a26649248f3f3bf5d30cc8a5"}},"fbf96ace8d844be5bbe94c1ae7ddbf23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d38847375c543b2abf864b7cb99757b","placeholder":"​","style":"IPY_MODEL_0f36d14c9a394c7ab27e5deb595d5ff8","value":"Validation DataLoader 0: 100%"}},"f26008c6ed434fd3a55bdd553bb081b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_580558092e3845799c4b176b2f2892af","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b265fa8a542f4fd3b0776a74653e9bc4","value":7}},"3c11dcda16a443b880a5130064346a06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb44213b76c841449898661ac3332d89","placeholder":"​","style":"IPY_MODEL_e5107ad75c6541b1808778fe02ada8fc","value":" 7/7 [00:00&lt;00:00, 124.17it/s]"}},"793369b7a26649248f3f3bf5d30cc8a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"9d38847375c543b2abf864b7cb99757b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f36d14c9a394c7ab27e5deb595d5ff8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"580558092e3845799c4b176b2f2892af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b265fa8a542f4fd3b0776a74653e9bc4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb44213b76c841449898661ac3332d89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5107ad75c6541b1808778fe02ada8fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c78d3be0459e4d31a18184660ddf9d78":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f35fa2ceebc14621acece4cad9cd759c","IPY_MODEL_dd09a28442b44ba59aa0597218aebbf8","IPY_MODEL_06552821300b420998ec15a557c951d5"],"layout":"IPY_MODEL_adb0657221124855a53f39d06108fc22"}},"f35fa2ceebc14621acece4cad9cd759c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dd505bc9b2a4f37a54fada45c101b68","placeholder":"​","style":"IPY_MODEL_b3f63c699ebd470db7d0443d3ae3d877","value":"Validation DataLoader 0: 100%"}},"dd09a28442b44ba59aa0597218aebbf8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_49bcf16e263c4430a6ebf0a9b9f1748f","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28fee7854c224485b5c2344bee656a3d","value":7}},"06552821300b420998ec15a557c951d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d993e77f93104968b7642da7399fa833","placeholder":"​","style":"IPY_MODEL_01507ddf2b514a00ab4457b4a920bb92","value":" 7/7 [00:00&lt;00:00, 127.83it/s]"}},"adb0657221124855a53f39d06108fc22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"4dd505bc9b2a4f37a54fada45c101b68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3f63c699ebd470db7d0443d3ae3d877":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49bcf16e263c4430a6ebf0a9b9f1748f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28fee7854c224485b5c2344bee656a3d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d993e77f93104968b7642da7399fa833":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01507ddf2b514a00ab4457b4a920bb92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fe93307a89443159be5d46a442d7ce8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e42dc92d498343e0a12dd3786009e1bc","IPY_MODEL_a140681c7c75410bbf5ef08a67208cc3","IPY_MODEL_33faa60f253f4793bdd39ef1c4a4a47b"],"layout":"IPY_MODEL_9cb571cf399149aa874557ffa9de6bc4"}},"e42dc92d498343e0a12dd3786009e1bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec34afa25d6e4594a8e977243250453a","placeholder":"​","style":"IPY_MODEL_e285c64d702d48b580cd0464c8011579","value":"Validation DataLoader 0: 100%"}},"a140681c7c75410bbf5ef08a67208cc3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e4d58fca5e344999276f656bebca6cd","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a24f6a8b368b44e5a0ba0cad07c9a2ab","value":7}},"33faa60f253f4793bdd39ef1c4a4a47b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcc2beb2ec7e4d399ebf93910a57737d","placeholder":"​","style":"IPY_MODEL_f28934c4827f4c629f795208ca8e80ec","value":" 7/7 [00:00&lt;00:00, 126.60it/s]"}},"9cb571cf399149aa874557ffa9de6bc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"ec34afa25d6e4594a8e977243250453a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e285c64d702d48b580cd0464c8011579":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e4d58fca5e344999276f656bebca6cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a24f6a8b368b44e5a0ba0cad07c9a2ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcc2beb2ec7e4d399ebf93910a57737d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f28934c4827f4c629f795208ca8e80ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ff89157613b43ab831fd22f59e50055":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a0e8b0a9ed8f4f56b5c6d4aa2fa3a9ad","IPY_MODEL_8bb283d10c2e400184dabe235d8bcb9d","IPY_MODEL_96cf79e826ba4870aed1a33ceb32f5a6"],"layout":"IPY_MODEL_43864c38b4ec442e88f9f2628bc9d8af"}},"a0e8b0a9ed8f4f56b5c6d4aa2fa3a9ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f81fb0cb81194408a7d82178a8fd4288","placeholder":"​","style":"IPY_MODEL_169d539f49384e9c80f5354964a870b4","value":"Validation DataLoader 0: 100%"}},"8bb283d10c2e400184dabe235d8bcb9d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_fef03503c1484c53aee0ef96ea9eb72e","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_747b2eaa675a4e9f8c1946d43e16f33e","value":7}},"96cf79e826ba4870aed1a33ceb32f5a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91eba61f46b247b7acff989866e5aa25","placeholder":"​","style":"IPY_MODEL_f584accea784454d921ef41fae9dbba7","value":" 7/7 [00:00&lt;00:00, 117.53it/s]"}},"43864c38b4ec442e88f9f2628bc9d8af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"f81fb0cb81194408a7d82178a8fd4288":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"169d539f49384e9c80f5354964a870b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fef03503c1484c53aee0ef96ea9eb72e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"747b2eaa675a4e9f8c1946d43e16f33e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91eba61f46b247b7acff989866e5aa25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f584accea784454d921ef41fae9dbba7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"907904e733224716a117bd347fb284b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1957bc9b524b4b29813c810f2a57aa58","IPY_MODEL_6f7bbc3fbea048eda2a072d3deffd1d0","IPY_MODEL_a0c346bff1ff4081b40ed41cba947cf1"],"layout":"IPY_MODEL_0b3f15dd1bcb4080abdbece99109c963"}},"1957bc9b524b4b29813c810f2a57aa58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f72f7a0701d48deb9f27ccfba0f53ff","placeholder":"​","style":"IPY_MODEL_8730fe3280324a418c032e8afa2a7f6b","value":"Validation DataLoader 0: 100%"}},"6f7bbc3fbea048eda2a072d3deffd1d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_591943304a4f41ed88e9bbd0f9c9b2e2","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f2fdf8897b742849b88863d01ab64a6","value":7}},"a0c346bff1ff4081b40ed41cba947cf1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69d3e434124a441fb498d3cf58bef8e7","placeholder":"​","style":"IPY_MODEL_a645ddca20fd4d7096884871c6b49d19","value":" 7/7 [00:00&lt;00:00, 146.26it/s]"}},"0b3f15dd1bcb4080abdbece99109c963":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"3f72f7a0701d48deb9f27ccfba0f53ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8730fe3280324a418c032e8afa2a7f6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"591943304a4f41ed88e9bbd0f9c9b2e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f2fdf8897b742849b88863d01ab64a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69d3e434124a441fb498d3cf58bef8e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a645ddca20fd4d7096884871c6b49d19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c597b1db6e3474e959405146ed1961a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bcc81e8979f440f1bfd34da9861ec1e6","IPY_MODEL_a5e52ee93afc41fb92b9a3fce470e54d","IPY_MODEL_c2e96a4834b5488d942902c33a59d404"],"layout":"IPY_MODEL_12be426a05ae4e98a91a59efe1e0d075"}},"bcc81e8979f440f1bfd34da9861ec1e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0dc1e3abca34d6da926a918cf5fac3f","placeholder":"​","style":"IPY_MODEL_c3646debe46849c1bc04dbfbcc2e739f","value":"Validation DataLoader 0: 100%"}},"a5e52ee93afc41fb92b9a3fce470e54d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1aa8c5b421246c0865d26f1f5a519eb","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47031139f33c4e75af8dd90d995f5f18","value":7}},"c2e96a4834b5488d942902c33a59d404":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_479a1437bc7a427ba6737488a5472ea1","placeholder":"​","style":"IPY_MODEL_4ff2c246ff684917903a83b5817d1378","value":" 7/7 [00:00&lt;00:00, 127.51it/s]"}},"12be426a05ae4e98a91a59efe1e0d075":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"a0dc1e3abca34d6da926a918cf5fac3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3646debe46849c1bc04dbfbcc2e739f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1aa8c5b421246c0865d26f1f5a519eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47031139f33c4e75af8dd90d995f5f18":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"479a1437bc7a427ba6737488a5472ea1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ff2c246ff684917903a83b5817d1378":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e695dbc7f88b4bb1b5a6d2e29738f40c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e94c071565de4a4bbe42d33997f7964d","IPY_MODEL_15dc4916231446a4946db059f5056a31","IPY_MODEL_d55eb2c094ca42479e8f261d18079521"],"layout":"IPY_MODEL_d42dc1e1a8bd4915bf00fbd1ac879b9f"}},"e94c071565de4a4bbe42d33997f7964d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_927da39162fa451f85cda7c2cf1b520b","placeholder":"​","style":"IPY_MODEL_b25039b8134647dfba3247b06428cd09","value":"Validation DataLoader 0: 100%"}},"15dc4916231446a4946db059f5056a31":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7326d4fe35e84f41bfd9abd674462d6d","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0086dd5cf1aa4777b04f1f661b48e07a","value":7}},"d55eb2c094ca42479e8f261d18079521":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7335a3b8fa24a4ca0d55e5012696089","placeholder":"​","style":"IPY_MODEL_3a84b2e779b44bbd86c3946130793e13","value":" 7/7 [00:00&lt;00:00, 118.92it/s]"}},"d42dc1e1a8bd4915bf00fbd1ac879b9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"927da39162fa451f85cda7c2cf1b520b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b25039b8134647dfba3247b06428cd09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7326d4fe35e84f41bfd9abd674462d6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0086dd5cf1aa4777b04f1f661b48e07a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7335a3b8fa24a4ca0d55e5012696089":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a84b2e779b44bbd86c3946130793e13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e47670255994deda4d23bb2f77e4975":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84e332d47bb44c3484317ae2cb5a9026","IPY_MODEL_3c5f457e07384e778f6fdbc5a999e64d","IPY_MODEL_daef9aa494594912b8ae8a5ebe27bd85"],"layout":"IPY_MODEL_444e9835dcaf4ea696e7029f2b2f0264"}},"84e332d47bb44c3484317ae2cb5a9026":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c951573c8f344cefb079226b6d75993b","placeholder":"​","style":"IPY_MODEL_d541be76ed384d6d88cd3e957bb10512","value":"Validation DataLoader 0: 100%"}},"3c5f457e07384e778f6fdbc5a999e64d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d875d6c78734686a2663af216f4a2ed","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_065ae366b2ed41469e3201fc14525234","value":7}},"daef9aa494594912b8ae8a5ebe27bd85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a22dfdaec5994aae82f91bfef357ca61","placeholder":"​","style":"IPY_MODEL_4b600b216c3f4cad8040a2d021426b49","value":" 7/7 [00:00&lt;00:00, 116.09it/s]"}},"444e9835dcaf4ea696e7029f2b2f0264":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"c951573c8f344cefb079226b6d75993b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d541be76ed384d6d88cd3e957bb10512":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d875d6c78734686a2663af216f4a2ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"065ae366b2ed41469e3201fc14525234":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a22dfdaec5994aae82f91bfef357ca61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b600b216c3f4cad8040a2d021426b49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3db8f7c27c3941f491ba091d604944de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f86609bb0d642d986952bb331ce0967","IPY_MODEL_1b5d24537c06477a9bf84a2627ac0f48","IPY_MODEL_acf427477e314e969060af57bbb5c5ae"],"layout":"IPY_MODEL_a1964889e0c743c8b12e48f0f0252da0"}},"6f86609bb0d642d986952bb331ce0967":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1829c7417dd34906975c554ffd0733ab","placeholder":"​","style":"IPY_MODEL_b394f4f7467d4169bdc2ba39bc09515f","value":"Predicting DataLoader 0: 100%"}},"1b5d24537c06477a9bf84a2627ac0f48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_994901efbeaf4f70b1e9eaa324fe0fa2","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d78da13bc7a49aa89cde9a6402bc6a8","value":7}},"acf427477e314e969060af57bbb5c5ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebb4ab1d21d74df9b99dcf8cf2c352dc","placeholder":"​","style":"IPY_MODEL_d06ab0404e8d494ca0e2b4de0ba66e9f","value":" 7/7 [00:00&lt;00:00, 155.50it/s]"}},"a1964889e0c743c8b12e48f0f0252da0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"1829c7417dd34906975c554ffd0733ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b394f4f7467d4169bdc2ba39bc09515f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"994901efbeaf4f70b1e9eaa324fe0fa2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d78da13bc7a49aa89cde9a6402bc6a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebb4ab1d21d74df9b99dcf8cf2c352dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d06ab0404e8d494ca0e2b4de0ba66e9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["#**-------------------------------------TRABALHO PST---------------------------------------**"],"metadata":{"id":"do6sFg1GigUp"}},{"cell_type":"markdown","source":["## **NOTEBOOK 5 | Neural Networks Models**"],"metadata":{"id":"a4TwqV_YjrbE"}},{"cell_type":"markdown","source":["**Realizado por:**\n","- David Carvalho, nº2242131\n","- Lígia Carteado Mena, nº2242194\n","- Rui Filipe Parada, nº2211025\n","\n","---------------------------------------------------------\n","**Dataset escolhido:**\n","- Foods1_CA4 -> Departamento Foods1 da loja 4 do Estado da Califórnia"],"metadata":{"id":"D0fBCCOJit1D"}},{"cell_type":"markdown","source":["## **1. IMPORTS**"],"metadata":{"id":"8MmUZPdYjzyo"}},{"cell_type":"code","source":["!pip install statsforecast"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a31xMNfBJrXk","executionInfo":{"status":"ok","timestamp":1749927484584,"user_tz":-60,"elapsed":19727,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"98a02c9f-a6d6-4e29-ad51-60da25dbb83d","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting statsforecast\n","  Downloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from statsforecast) (3.1.1)\n","Collecting coreforecast>=0.0.12 (from statsforecast)\n","  Downloading coreforecast-0.0.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n","Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.11/dist-packages (from statsforecast) (0.60.0)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from statsforecast) (2.0.2)\n","Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.11/dist-packages (from statsforecast) (2.2.2)\n","Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.11/dist-packages (from statsforecast) (1.15.3)\n","Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from statsforecast) (0.14.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from statsforecast) (4.67.1)\n","Collecting fugue>=0.8.1 (from statsforecast)\n","  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n","Collecting utilsforecast>=0.1.4 (from statsforecast)\n","  Downloading utilsforecast-0.2.12-py3-none-any.whl.metadata (7.6 kB)\n","Requirement already satisfied: threadpoolctl>=3 in /usr/local/lib/python3.11/dist-packages (from statsforecast) (3.6.0)\n","Collecting triad>=0.9.7 (from fugue>=0.8.1->statsforecast)\n","  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n","Collecting adagio>=0.2.4 (from fugue>=0.8.1->statsforecast)\n","  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.55.0->statsforecast) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->statsforecast) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->statsforecast) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->statsforecast) (2025.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->statsforecast) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->statsforecast) (24.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->statsforecast) (1.17.0)\n","Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast) (18.1.0)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast) (2025.3.2)\n","Collecting fs (from triad>=0.9.7->fugue>=0.8.1->statsforecast)\n","  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n","Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.8.1->statsforecast)\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from fs->triad>=0.9.7->fugue>=0.8.1->statsforecast) (75.2.0)\n","Downloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coreforecast-0.0.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (285 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.8/285.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fugue-0.9.1-py3-none-any.whl (278 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading utilsforecast-0.2.12-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\n","Downloading triad-0.9.8-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Installing collected packages: appdirs, fs, coreforecast, utilsforecast, triad, adagio, fugue, statsforecast\n","Successfully installed adagio-0.2.6 appdirs-1.4.4 coreforecast-0.0.16 fs-2.4.16 fugue-0.9.1 statsforecast-2.0.1 triad-0.9.8 utilsforecast-0.2.12\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DsbvsKVPiShB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749927599977,"user_tz":-60,"elapsed":115396,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"b051bdfe-11c8-4dd7-d47c-e0815f90a5c4","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting neuralforecast[ltsf]\n","  Downloading neuralforecast-3.0.1-py3-none-any.whl.metadata (14 kB)\n","\u001b[33mWARNING: neuralforecast 3.0.1 does not provide the extra 'ltsf'\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: coreforecast>=0.0.6 in /usr/local/lib/python3.11/dist-packages (from neuralforecast[ltsf]) (0.0.16)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from neuralforecast[ltsf]) (2025.3.2)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from neuralforecast[ltsf]) (2.0.2)\n","Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.11/dist-packages (from neuralforecast[ltsf]) (2.2.2)\n","Requirement already satisfied: torch<=2.6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from neuralforecast[ltsf]) (2.6.0+cu124)\n","Collecting pytorch-lightning>=2.0.0 (from neuralforecast[ltsf])\n","  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n","Collecting ray>=2.2.0 (from ray[tune]>=2.2.0->neuralforecast[ltsf])\n","  Downloading ray-2.47.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (20 kB)\n","Collecting optuna (from neuralforecast[ltsf])\n","  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: utilsforecast>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from neuralforecast[ltsf]) (0.2.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->neuralforecast[ltsf]) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->neuralforecast[ltsf]) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->neuralforecast[ltsf]) (2025.2)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast[ltsf]) (4.67.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast[ltsf]) (6.0.2)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=2.0.0->neuralforecast[ltsf])\n","  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast[ltsf]) (24.2)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast[ltsf]) (4.14.0)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=2.0.0->neuralforecast[ltsf])\n","  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (8.2.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (3.18.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (4.24.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (1.1.0)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (5.29.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (2.32.3)\n","Collecting tensorboardX>=1.9 (from ray[tune]>=2.2.0->neuralforecast[ltsf])\n","  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]>=2.2.0->neuralforecast[ltsf]) (18.1.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf]) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf]) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf])\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf])\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf])\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf])\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf])\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf])\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf])\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf])\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf])\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf]) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf]) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf]) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf])\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf]) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<=2.6.0,>=2.0.0->neuralforecast[ltsf]) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<=2.6.0,>=2.0.0->neuralforecast[ltsf]) (1.3.0)\n","Collecting alembic>=1.5.0 (from optuna->neuralforecast[ltsf])\n","  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna->neuralforecast[ltsf])\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->neuralforecast[ltsf]) (2.0.41)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->neuralforecast[ltsf]) (1.1.3)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast[ltsf]) (3.11.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=2.0.0->neuralforecast[ltsf]) (75.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->neuralforecast[ltsf]) (1.17.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->neuralforecast[ltsf]) (3.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<=2.6.0,>=2.0.0->neuralforecast[ltsf]) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (0.25.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast[ltsf]) (2025.4.26)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast[ltsf]) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast[ltsf]) (1.3.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast[ltsf]) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast[ltsf]) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast[ltsf]) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast[ltsf]) (1.20.0)\n","Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ray-2.47.0-cp311-cp311-manylinux2014_x86_64.whl (68.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.9/68.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading neuralforecast-3.0.1-py3-none-any.whl (260 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading optuna-4.3.0-py3-none-any.whl (386 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n","Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: tensorboardX, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, colorlog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alembic, optuna, nvidia-cusolver-cu12, ray, torchmetrics, pytorch-lightning, neuralforecast\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed alembic-1.16.1 colorlog-6.9.0 lightning-utilities-0.14.3 neuralforecast-3.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 optuna-4.3.0 pytorch-lightning-2.5.1.post0 ray-2.47.0 tensorboardX-2.6.4 torchmetrics-1.7.3\n"]}],"source":["!pip install neuralforecast[ltsf]"]},{"cell_type":"code","source":["import io\n","from google.colab import files\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from scipy import stats\n","import matplotlib.pyplot as plt\n","from utilsforecast.plotting import plot_series\n","from sklearn import metrics\n","\n","from neuralforecast.auto import AutoLSTM, AutoNHITS\n","\n","from statsforecast import StatsForecast\n","from neuralforecast import NeuralForecast\n","\n","from ray import tune\n","from ray.tune.search.hyperopt import HyperOptSearch\n","from neuralforecast.losses.pytorch import MAE\n","from neuralforecast.losses.pytorch import MQLoss"],"metadata":{"id":"455-f-d8j4KY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **2. DATA UPLOAD | DIVISÃO TREINO E TESTE**"],"metadata":{"id":"BbgBtSHjj4dI"}},{"cell_type":"markdown","source":["### Data upload: fazer upload dos ficheiros 'Foods1_CA4.csv' e 'results_PST4'"],"metadata":{"id":"yq29m90AI-6q"}},{"cell_type":"code","source":["uploaded = files.upload()\n","\n","if 'Foods1_CA4.csv' in uploaded and 'results_PST4.csv' in uploaded:\n","    df = pd.read_csv(io.BytesIO(uploaded['Foods1_CA4.csv']), parse_dates=['ds'])\n","    Models_results = pd.read_csv(io.BytesIO(uploaded['results_PST4.csv']), sep=',')\n","    print(\"Both files uploaded successfully.\")\n","else:\n","    print(\"Please ensure both 'Foods1_CA4.csv' and 'results_PST4.csv' are uploaded.\")\n","\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":531},"id":"yoepX-wJRm3K","executionInfo":{"status":"ok","timestamp":1749927775889,"user_tz":-60,"elapsed":41381,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"171f08f1-314d-44bd-f764-50e2c551a2da"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-96649775-5fe0-416f-8818-7b8c71fbd310\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-96649775-5fe0-416f-8818-7b8c71fbd310\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Foods1_CA4.csv to Foods1_CA4.csv\n","Saving results_PST4.csv to results_PST4.csv\n","Both files uploaded successfully.\n"]},{"output_type":"execute_result","data":{"text/plain":["               unique_id         ds    y\n","0       FOODS_1_001_CA_4 2011-01-30  1.0\n","1       FOODS_1_001_CA_4 2011-01-31  1.0\n","2       FOODS_1_001_CA_4 2011-02-01  1.0\n","3       FOODS_1_001_CA_4 2011-02-02  1.0\n","4       FOODS_1_001_CA_4 2011-02-03  1.0\n","...                  ...        ...  ...\n","355368  FOODS_1_219_CA_4 2016-06-15  2.0\n","355369  FOODS_1_219_CA_4 2016-06-16  1.0\n","355370  FOODS_1_219_CA_4 2016-06-17  4.0\n","355371  FOODS_1_219_CA_4 2016-06-18  0.0\n","355372  FOODS_1_219_CA_4 2016-06-19  0.0\n","\n","[355373 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-8b3ff132-2ac3-4b52-83fd-a9c47f727531\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>unique_id</th>\n","      <th>ds</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2011-01-30</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2011-01-31</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2011-02-01</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2011-02-02</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2011-02-03</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>355368</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-15</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>355369</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-16</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>355370</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-17</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>355371</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-18</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>355372</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-19</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>355373 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b3ff132-2ac3-4b52-83fd-a9c47f727531')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8b3ff132-2ac3-4b52-83fd-a9c47f727531 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8b3ff132-2ac3-4b52-83fd-a9c47f727531');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-bde82f58-394c-4f60-be76-19f6efdd7918\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bde82f58-394c-4f60-be76-19f6efdd7918')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-bde82f58-394c-4f60-be76-19f6efdd7918 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_6763bf24-a059-4570-87e0-77461e153a3a\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_6763bf24-a059-4570-87e0-77461e153a3a button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["### Conjunto de treino e teste"],"metadata":{"id":"VIKaPvbok61J"}},{"cell_type":"code","source":["train = df[df['ds'] <= '2016-05-22']\n","train"],"metadata":{"id":"_Ti6b3qJkvCx","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1749927777540,"user_tz":-60,"elapsed":90,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"3e0c28a0-2036-4c09-9a87-6a660d2cdf54"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               unique_id         ds    y\n","0       FOODS_1_001_CA_4 2011-01-30  1.0\n","1       FOODS_1_001_CA_4 2011-01-31  1.0\n","2       FOODS_1_001_CA_4 2011-02-01  1.0\n","3       FOODS_1_001_CA_4 2011-02-02  1.0\n","4       FOODS_1_001_CA_4 2011-02-03  1.0\n","...                  ...        ...  ...\n","355340  FOODS_1_219_CA_4 2016-05-18  3.0\n","355341  FOODS_1_219_CA_4 2016-05-19  2.0\n","355342  FOODS_1_219_CA_4 2016-05-20  2.0\n","355343  FOODS_1_219_CA_4 2016-05-21  6.0\n","355344  FOODS_1_219_CA_4 2016-05-22  2.0\n","\n","[349325 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-b337b377-d28a-44a0-b7dd-1719d8e762d2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>unique_id</th>\n","      <th>ds</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2011-01-30</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2011-01-31</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2011-02-01</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2011-02-02</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2011-02-03</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>355340</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-05-18</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>355341</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-05-19</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>355342</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-05-20</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>355343</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-05-21</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>355344</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-05-22</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>349325 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b337b377-d28a-44a0-b7dd-1719d8e762d2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b337b377-d28a-44a0-b7dd-1719d8e762d2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b337b377-d28a-44a0-b7dd-1719d8e762d2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-68c7fe3c-d98c-44f9-840d-0e51b11626e4\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68c7fe3c-d98c-44f9-840d-0e51b11626e4')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-68c7fe3c-d98c-44f9-840d-0e51b11626e4 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_c4f01f3f-4672-42b6-9221-b756ef1b3558\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_c4f01f3f-4672-42b6-9221-b756ef1b3558 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('train');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["test = df[df['ds'] > '2016-05-22'].rename(columns={'y': 'y_test'})\n","test"],"metadata":{"id":"YaIrQU1GkvAS","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1749927780480,"user_tz":-60,"elapsed":74,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"b5106516-ef0a-4fe5-d948-e06fc55aee0e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               unique_id         ds  y_test\n","1940    FOODS_1_001_CA_4 2016-05-23     2.0\n","1941    FOODS_1_001_CA_4 2016-05-24     0.0\n","1942    FOODS_1_001_CA_4 2016-05-25     0.0\n","1943    FOODS_1_001_CA_4 2016-05-26     6.0\n","1944    FOODS_1_001_CA_4 2016-05-27     0.0\n","...                  ...        ...     ...\n","355368  FOODS_1_219_CA_4 2016-06-15     2.0\n","355369  FOODS_1_219_CA_4 2016-06-16     1.0\n","355370  FOODS_1_219_CA_4 2016-06-17     4.0\n","355371  FOODS_1_219_CA_4 2016-06-18     0.0\n","355372  FOODS_1_219_CA_4 2016-06-19     0.0\n","\n","[6048 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-f6dc2ee7-623f-4241-8e3d-8ec6e7c43e63\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>unique_id</th>\n","      <th>ds</th>\n","      <th>y_test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1940</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2016-05-23</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>1941</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2016-05-24</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1942</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2016-05-25</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1943</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2016-05-26</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>1944</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2016-05-27</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>355368</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-15</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>355369</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-16</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>355370</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-17</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>355371</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-18</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>355372</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-19</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6048 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6dc2ee7-623f-4241-8e3d-8ec6e7c43e63')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f6dc2ee7-623f-4241-8e3d-8ec6e7c43e63 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f6dc2ee7-623f-4241-8e3d-8ec6e7c43e63');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-9f2614fc-3d58-4375-8b69-1b393ecac3d1\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f2614fc-3d58-4375-8b69-1b393ecac3d1')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-9f2614fc-3d58-4375-8b69-1b393ecac3d1 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_06ef5f4c-6da8-49f1-8373-d14623a810b7\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_06ef5f4c-6da8-49f1-8373-d14623a810b7 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('test');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test","summary":"{\n  \"name\": \"test\",\n  \"rows\": 6048,\n  \"fields\": [\n    {\n      \"column\": \"unique_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 216,\n        \"samples\": [\n          \"FOODS_1_205_CA_4\",\n          \"FOODS_1_217_CA_4\",\n          \"FOODS_1_141_CA_4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ds\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2016-05-23 00:00:00\",\n        \"max\": \"2016-06-19 00:00:00\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"2016-06-01 00:00:00\",\n          \"2016-06-17 00:00:00\",\n          \"2016-05-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.203898757983575,\n        \"min\": 0.0,\n        \"max\": 32.0,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          14.0,\n          10.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["train.shape, test.shape"],"metadata":{"id":"6BONOt_Xku-E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749927782093,"user_tz":-60,"elapsed":14,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"6caa3499-3656-4421-d174-01e7fd4bb6de"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((349325, 3), (6048, 3))"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## **3. MODELING**"],"metadata":{"id":"L8IOUC7elUQm"}},{"cell_type":"markdown","source":["### Dataset parameters"],"metadata":{"id":"z_b35DpQlbWB"}},{"cell_type":"code","source":["freq = 'D'\n","season_length = 7\n","horizon = 28"],"metadata":{"id":"Ad9ye_fslWbH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Instanciar modelos"],"metadata":{"id":"uZx6LZE2le1v"}},{"cell_type":"markdown","source":["Define-se dois modelos de deep learning automáticos — AutoNHITS e AutoLSTM —  com otimização de hiperparâmetros usando Ray Tune + HyperOpt"],"metadata":{"id":"IWt58zPzj6E6"}},{"cell_type":"code","source":["nhits_config = {\n","    \"max_steps\": 1000,\n","    \"input_size\": 2*horizon,\n","    \"learning_rate\": tune.loguniform(1e-5, 1e-1),\n","    \"n_pool_kernel_size\": tune.choice([[2, 2, 2], [16, 8, 1]]),\n","    \"n_freq_downsample\": tune.choice([[168, 24, 1], [24, 12, 1], [1, 1, 1]]),\n","    \"val_check_steps\": 50,\n","    \"early_stop_patience_steps\": 2,\n","    \"random_seed\": tune.randint(1, 10)\n","}\n","\n","\n","lstm_config = {\n","    \"max_steps\": 1000,\n","    \"input_size\": 2 * horizon,\n","    \"encoder_hidden_size\":128,\n","    \"decoder_hidden_size\":128,\n","    \"learning_rate\": tune.loguniform(1e-4, 5e-3),\n","    \"val_check_steps\": 50,\n","    \"early_stop_patience_steps\": 2,\n","    \"random_seed\": tune.randint(1, 10)\n","}\n","\n","\n","models = [\n","    AutoNHITS(\n","        h=horizon,\n","        loss=MQLoss(),\n","        config=nhits_config,\n","        search_alg=HyperOptSearch(),\n","        backend='ray',\n","        num_samples=20\n","    ),\n","    AutoLSTM(\n","        h=horizon,\n","        loss=MQLoss(),\n","        config=lstm_config,\n","        search_alg=HyperOptSearch(),\n","        backend='ray',\n","        num_samples=20\n","    )\n","]"],"metadata":{"id":"6RiZnH1RE94-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instanciar pipeline com os modelos definidos\n","nf = NeuralForecast(models=models,\n","                    freq=freq\n","                    )"],"metadata":{"id":"WYg1ANS7ZoAm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import logging\n","logging.getLogger(\"ray\").setLevel(logging.WARNING)  # Para menos \"ruído\" no output\n","\n","nf.fit(df=train, val_size=horizon)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1b4ccd3092164890aca06e0bdc4b8da8","0ce7ca0cedd4443282d31bf2f40be665","b0b14f1dc4f442c783fccaecfd82840f","2e0d8e34e7a54f0a8bea5646d5cf2b4e","1942407dc08c45139581675c9092bf0a","4ca5e5e6fcea490e919643bd857d8844","644598da1c4e48feb3fff22cd84b1982","d70c17526f5d42949b8f0299ad9d4a66","69f07122e5ae411394775b2a86bb1f35","1a0ab738ef9a4b78a908898979c2d1c2","97576b9cceef4a12b77d3ab2fdb43772","4b0e5ceb6e3b4be586e781baa31ea25b","3ad97ac666fb4658b28c455e0009c6da","8d950b225a594e2fa12d781db2e72501","3306aa5561d34ee8901ce007b4e2470e","041f70d6bad4490aa3de47065d71b3e1","c2bc967ff20044269f4f7ac0efa291d2","7b0276b4875f44bd98c96c4510cf151d","5e11dd04a3014fb689b2192713c02478","18367889aaba4ceaab3eb647f2db1461","f973d503a9984fbabef849b8ab2a302e","6a9929dfecd14e26953a939d0107fe1d","82fe3f59990b48e2bdacb3f2b74ed6d4","915fb0aefacf406abb9d5dfbd0d1ce0e","5e3d388e2bd3423daeb1c679c85a5e3f","b0ae6a58db1144c980feb6a4d0d3f693","0090dcffbe494a4f82735d95d2e2b43e","392edeb3de4a4c01af7bed6417873886","bbbed57991e448c499e3ffa0cac8e884","dbd2a84479a84477af43b8f3e4eb74c9","69525b64bd3d44258334a47cf6e93ed8","d4fc5a1dffc54c64a621b47374191e76","566f641b434a40a0b641062ef1dc7a7f","0ae2c87f2e39452085f7b8550d0507be","c8f6c33dd87a4ebfa498e64070c1df6c","9dabcd52834b4f1a8fb270a206984e8e","152facc1227a482eab717c61b957710c","900bffd6b8c34dd0b5c6ef1163cc2533","2c4ac30934f4407492608c273af12df3","9f2f59e65446495eb62fe51bbbfe48e2","e77f9f9cb9e34ced85b5ec97dbdfdfdd","9ad6077d4d9b4c3ca8ac61f1c57050b0","a64c81112cf843ef815561864beafea3","71c80d73e33542d597af16361269f7c4","28d63001996b4cec82ffcadb2e6e7599","a39503c6824549ee86eebfc5a73cdf78","f8943d0a482a415fb8fa06c6a73a6d8d","f1307b7a206440ba8ec915f92c4ed0f0","58ae48ca5dc84146905938d902ba921b","9a13bce18b8d43dda585632ade81eece","eacd6c7ae6d144e0902deab2ce01f5bd","2170c349582e4a24a6b79e2f8ef2dc4a","d4e22946844e410abee57f020d0b9f2a","d45dce67d8a84ec596d6a047dda5b2f5","de4eabb4560841b28a5f7287ea8a42fe","186dbd8b81ee4be2b8db892502ae2db9","e6f03bb1315142a59b781270e8ba0603","3949e7c329f842d087845a0a67fe2940","dd46adde19d9469ca7bbe6ad579a79cb","7ff8ec1019484d9183cdb39b7f110119","969ffd73e193405b83995d33bc99bbcd","25ae2c1d3c0c4a319cc4fe7d1169ddb1","c04a1004d8934a7c861ab5b42008e4a3","9d4ffdefd2d547128ceca8dfff1032d3","69dc7141979d4491ab163e87441e810b","f169c22034254181a7592957357447e5","61e177c2c79245a8b7724da265589845","4e7ef46cc6424bd389de92009b694984","5b4a768695e0454cb3237a070abf057a","221def5e646c43f7a7d8c917698c0efd","994291390400428e97421af834b1ed25","e1a06844f52a4eb39f636c3534165018","aa05a592a3a34bf0890103f203a128d5","25ed90c741fc4f65ac555edac98174db","17bf77f757c6453680001f7d06a1b90a","f6e449b0f3aa451fa9db8cc9d8aa0e22","713e4b98a839446cbd925284248a5aec","8c6a24ac73be47a480e84e82a8073a79","18d0cdcc51b64f5381dc00b761056719","8a009da9ebfa4ba1aef3e1ead6470531","f4f080b94f464bc386a2219faa783d2a","2ad9c0814da042828d558fd411b1a7c7","6f07281f1aff41a684fe93ab7192de66","2467892450d64b9f85a3b8aad6cb7d0d","0b8fede78cd947de824765646ca22e23","934a171e1895461cbf5b31c5b7ada2c3","808627c439604fb4a53a166bb12095b3","4971d6fb7e7044da871275b2eb191ec0","c692353c7b2d4728ae1a572ecefbfe7e","701e64cf28ab48618fca3b3bf7851e3e","0d5eb0baf11a476f9fd901b2ab35a4d4","3b14e5d4a9174b90aab91a33e4692a06","56f39a43f6d6468a9db0555f92608296","7a0684b932934012a474e5904313e648","bb366752743541d590e8945e4b8e1c47","13317ca5c89b44cbbc824f0b28e086c9","920a870c778d4ca5b630fa35067643c5","a1c788935a074c48b82e1ca86edc79df","f79e5a7bfe6d44b3bb227e6a8cb66970","5d74790f1150415ba4bc0fcb37391245","50b65e59b8594745975232912a0bc7d9","0e2fa0f474d04bd19d26f91ca639ef35","8f189c23100943b795805c575d1af00a","6651e6babc3b4faebcfc2c8b4ecce8d5","f2ccdf5a20dd44cbbb8cb8f5bc4dd96f","0e13fe7df6e24ddda651aa69a75cf643","e68bedaacabe4c5aae179a8a940d0129","63df3e55c8a14b06b60bebf4538eb179","a53d32f14a5b4c7bb30134a13556db50","03c497180ecd462181e8a0b31c6b238f","5d5e85bd67114980b9f020611f22ef8d","212f7cff24c84b34ba1ad9f8e3ea8ab4","bcf8d41a4ea14427b40d9e3ff9bbff06","14f99bca1bbb49d785381792a92b7a55","acf3836f445e43f88bb8279e22d55e6c","135173037fcd4b6dbb17d9a5ec8c7696","b0efbfb2c8c3452d9b26990253c86e02","d756c8e3cb0c49528471bee100da5749","ff970955a4684004be9e9357c090a8c0","c696165ddb09441e9baf5b16a3199b4e","bad2083a568345f39ff11865c784ba3e","8b5ae7ecf7ff4d4f9240a6b3cfa63638","2c8fd7f87bec4525b290ac394aa57bbe","229997fcc26d4a468980c35d1a58148b","ee5b6c18ca3d4034b40d645c9fb8eb6b","7e256554e039469d9e4421677ffbb3fe","19cdaacab3f94dfdbad4805477d5ffe1","7e1c4d6b2dcf47ada9ec7d816490eb73","e862d29379b54ddb8bd6a1258839383e","cb084adf02d748b4956344b4f8bef56b","da953794bb7e4ab49960190818828f15","e90bc971232b476d94c14f8ae33c75af","e21582e0be024404a227404224e7369c","9b2b97de05654bc69deba02128326413","f970fcc91eee43d7a760e969efdcaef0","7d82d9dfe59c4c70bef7d341ce51824d","7534cb4d74084e3babf88f14f0bbdc71","a438e45891b6493ba682f434c6b6e3ef","1531fa8e13834270a048e2f868a7b737","d7ed4889788549fea73ca09f08aecdf4","b52623c2d97844cbbdff18b83f173ecf","e0a72500544e4f66b794d5ffb3cc8971","5b48b463732248b992e42e059baae0eb","c91a2ac5bb574ce59f3a9a7d4cb56306","9e4d8ab71f5846a2b8051e9c8bf183b5","338a1152c5b94be9ac3fc14b32fee6fc","8082637de89946da92ba9a4ee429c9c6","443ce21feb184726aa03bff2787dc799","4c7ae0ea1c8a4a13babdad9d897bd821","ed6fa731ad8641378ec4b61815664c2c","faea6389e60a4516b12624bb103aa135","2af7655a30954d99a09bc5315ac5588e","6fdb2711e0ab488bae0d1df8b7caf731","b10c15801ebb4148a0d4d0e9fa74c24c","086c137f5ed04b7eb9849ca543a4bfc3","f894f06ae92f43a1b36976ae981b25cb","85903073305549a286c5d0af955600ec","85b77526e425425e980a51bacc742405","811175bd0e42414280621e9997451aa2","614c57e8818a4ae69d4fcef057478377","d12b10058d6d4fec9bc18e4cae443d9c","c9c0a876afa24e67873446982cb14d14","f8e60e10440d4b2ba29432152e695c6e","dd04e8ab805a4bf9b1390691134c9b7d","41cf0ac4c4c4446ca33a8c1a78133e5f","68e0e27a676f479f9a335e6d51dd8f78","5bcbec1391ee4e09ac832d97e9b5b7b6","f06f1ce55e5e4627aef40866602d9ec0","6de86be3c746490b89ba5ec1d91aad10","d65832d3e3d54470a2734052f291c1c5","9d4d244d162040b3a75d46c9f3aa9f68","412aebd198db4959b246b315484e48fe","189b636368ff4429a86b48dcc58da171","0f636ce128d043e6b7223d2847a72d89","77c122fc7766415dbc6ae9698852b08c","d4a929224e6d4f6ab9cca1d47b8d830b","7a1b20f837e64420a06c58544d8ccd23","02ebffeead6f405abdccef8119b307a7","ad84c946620c48d0988bdcc98fa86b64","46644cc454344264b1d6b1716717b411","bda41dfc05414aeebd5b464bcacdf38d","c97be772c719491895037f89af3e43f9","3baf55c1a91a481db9eea0f3c9736363","f4ce2a76cbf747ea824b295034e70f59","c0c926fb9ee241619a2b7b943263631f","51b23c5ba4d04218a3d3b68107a4ea4f","a98f970368204ca58af0369f7f0cc475","a8a16f0d6eb84c1b8de64a9462771733","11900808c8d047618b269ccf3da309f9","b354a2991f984ffbaed374a50df6dad2","979734a842084d6caf71a542c38b9d26","ef1b7e43a5f547f2ba26a4f9364656f7","f603f3708e1d4e4caa591c0047370ada","db64a8378f1d45c392f67a34de09b7e1","05f88d4a736b4990a80eead15d0581e5","b2511cb4458e4961a7df3c8ce570ae71","7dc66ddf49a84473a7d96a777618520a","6ece75e5792b42698c1e36521def9754","e9d8f43e5eb949529a67a4ef0d0bd456","c44b28ceaee14af284c6d4e564ae939a","7623d6943fb54f58a963c183bef651be","f47dd97279e346df9f4558d8c688c9ba","a5bc801f087d444e958cc647f6f1ef9a","ede3239a3924465586b64dcdecb7ca7e","3a92e126d9014c7a870661efba4455a9","599c537a26f04bff956fda0a12934aae","1a6aad0c508d4ff1ae67f697867d9512","2ff188065a2042eab7193267a423300e","f8dde9d3af194ba28c37cfe04c96bbae","a6cfcb5eb068444a98b093f94c2f3167","b4dd50c2cc3f4bb888a9fce62052b711","161351c188a1476fb5eec10baca12eeb","2e800e5ad2aa417fa6bc176b57f0b14b","7f75122b2afa4058b6ef34ea67d748fd","a54a3f9aab5449baa7cc75cd5bf17ad6","66911624d0ae4b25a6dc1e4528e306b7","6c23b5928b604ff2a235a10b0543a6ca","f1866df06e55482981ad02f3916e973a","3b900d8432d44b3b8c78fef508466188","e08f352ccca24695b9b164f52606b1f3","7c052c85e1224d7bbb2f6b9e4f3c60c2","bfdd0a8c83444280a306d56ba7f14871","8760ec82616a49669c9d5c6d0a258498","14a2028d0c2b450ca2e1f2a22a0b3846","19cf81201f904defa13b6c09e5dc392b","6ad51cd502a346c884885357c63a5aa2","07902ee6c11e4ff78795677779814997","0bd3c88b5e7a4bf99eb01d7ebfaca511","905a7c981be44f58b67ab017dd98d728","c55f25410e1b43979cd160a9697c2852","7198591bd8554deaaeca5ad789c1a0a9","826015724d314995a7403ab959033670","53838c2992814d55aa73ecb16233ea18","dbd27adf5fe2420caef4a629f2346f63","617f09d177e94b5e8ae858cd0d626e0a","f78ec9781d274716a6c142fefba8eecf","d9e17f316ea04f239c85b35032796550","7c6ff1f800a4432bb77fd3e67cf986c0","9e173ddff2ab46a0a51123774674203b","dd0f6165a78a4958b7e518f5fe164f2b","04ddee2aa9754aa2b71e87424ca7fcf2","10143be6c3ed4d09b38ccedb49c4914e","7e58fea50b9f436c8a672b9c32dff8ea","55c87e6b724f407886a9508599c4e003","488f9a6c4feb4319a5a80d3518a466d4","86355a0b1c0d4f70a18e29b22df3e140","bb23762ecdac457cb80767f474672a51","ffd1e5d3a8db4cf9a39956b3b0559551","7dfe6646658145c9a45d9ab680865c6f","d7b407abd4b14d008682b5014d9f981e","b8d25a0e3abb414dbdc80c33adb625e7","6725426642b84d138ce6c23d4b1895bf","544c7886a8b84580813dd4d77226ed88","c9d837b626bb491a94a881ee05280ed8","22cba3e451bf4d7cadf291d8a7cf660e","e5321a75b1b54ae39989febfa7e22ca9","416a48a575fa44e9b8df78e7aa4c751f","75c201ace32845a8886adac6c5a0e338","916fcac99ba34221b204bdf4d4e3f7f9","37322713f89a42acb03c5ee5373dc3ab","a188288e4b324e4b8128a8f81063c468","6b388591ab4c41418bf48c358fba9b85","de81021d497747a6a5cb988387b00d52","e986fbc355d7444b83cd16b843d2f695"]},"id":"_iXXOS7lZtf1","executionInfo":{"status":"ok","timestamp":1749928707102,"user_tz":-60,"elapsed":899916,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"58ffa1d9-0872-417f-f051-8c6ff13a0e94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2025-06-14 19:03:29,931\tINFO worker.py:1917 -- Started a local Ray instance.\n","2025-06-14 19:03:31,427\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n"]},{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------------------------+\n","| Configuration for experiment     _train_tune_2025-06-14_19-03-27   |\n","+--------------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator                   |\n","| Scheduler                        FIFOScheduler                     |\n","| Number of trials                 20                                |\n","+--------------------------------------------------------------------+\n","\n","View detailed results here: /root/ray_results/_train_tune_2025-06-14_19-03-27\n","To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-14_19-03-27_020465_1199/artifacts/2025-06-14_19-03-31/_train_tune_2025-06-14_19-03-27/driver_artifacts`\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=3044)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=3044)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=3044)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=3044)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=3044)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=3044)\u001b[0m 2025-06-14 19:03:43.203923: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=3044)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=3044)\u001b[0m E0000 00:00:1749927823.468939    3128 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=3044)\u001b[0m E0000 00:00:1749927823.540677    3128 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=3044)\u001b[0m 2025-06-14 19:03:44.099810: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=3044)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=3044)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \n","\u001b[36m(_train_tune pid=3044)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=3044)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=3044)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=3044)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=3044)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=3044)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=3044)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=3044)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=3044)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=3044)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=3044)\u001b[0m 10.286    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=3044)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=3044)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=3044)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.200]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.640]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.550]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.470]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.340]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.260]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.200]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 135.24it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.200, valid_loss=1.480]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.140, valid_loss=1.480]\n","Epoch 8: 100%|██████████| 7/7 [00:00<00:00, 53.73it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.140, valid_loss=1.480]\n","Epoch 8: 100%|██████████| 7/7 [00:00<00:00, 53.47it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.120, valid_loss=1.480]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.120, valid_loss=1.480]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=1.130, valid_loss=1.480]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=1.060, valid_loss=1.480]\n","Epoch 11: 100%|██████████| 7/7 [00:00<00:00, 50.49it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=1.060, valid_loss=1.480]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.080, valid_loss=1.480]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=1.110, valid_loss=1.480]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=1.050, valid_loss=1.480]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.13it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 47.26it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=1.030, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 140.67it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=1.020, valid_loss=1.360]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=1.050, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 208.85it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.040, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 187.97it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 36: 100%|██████████| 7/7 [00:00<00:00, 53.90it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 36: 100%|██████████| 7/7 [00:00<00:00, 53.61it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.040, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:03:56,877\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=3044)\u001b[0m \n","\u001b[36m(_train_tune pid=3044)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 147.34it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3044)\u001b[0m \n","\u001b[36m(_train_tune pid=3044)\u001b[0m \r                                                                       \u001b[A\rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=1.040, valid_loss=1.350]\rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=1.030, valid_loss=1.350]\rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=1.030, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=3212)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=3212)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=3212)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=3212)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=3212)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=3212)\u001b[0m 2025-06-14 19:04:07.003841: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=3212)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=3212)\u001b[0m E0000 00:00:1749927847.026650    3290 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=3212)\u001b[0m E0000 00:00:1749927847.033726    3290 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=3212)\u001b[0m 2025-06-14 19:04:07.058686: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=3212)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=3212)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \n","\u001b[36m(_train_tune pid=3212)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=3212)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=3212)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=3212)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=3212)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=3212)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=3212)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=3212)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=3212)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=3212)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=3212)\u001b[0m 10.286    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=3212)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=3212)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.820]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.430]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.340]\n","Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 56.07it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.340]\n","Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 54.07it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=1.340]\n","Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 53.76it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=1.210]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=1.210]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.200]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.130]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.140]\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 204.64it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=1.140, valid_loss=1.400]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=1.090, valid_loss=1.400]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.070, valid_loss=1.400]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=1.070, valid_loss=1.400]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.050, valid_loss=1.400]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.090, valid_loss=1.400]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=1.060, valid_loss=1.400]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.060, valid_loss=1.400]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 199.46it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=1.030, valid_loss=1.370]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.050, valid_loss=1.370]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 183.36it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=1.020, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 26: 100%|██████████| 7/7 [00:00<00:00, 50.28it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.030, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 157.85it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.070, valid_loss=1.340]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.070, valid_loss=1.340]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.040, valid_loss=1.340]\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 165.37it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 36: 100%|██████████| 7/7 [00:00<00:00, 41.57it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 36: 100%|██████████| 7/7 [00:00<00:00, 40.66it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=1.020, valid_loss=1.340]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.730, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.050, valid_loss=1.340]\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.44it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.070, valid_loss=1.340]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.070, valid_loss=1.340]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=1.020, valid_loss=1.340]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 54.29it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=1.040, valid_loss=1.340]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 135.09it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=1.020, valid_loss=1.350]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=1.020, valid_loss=1.350]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=1.010, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:04:18,754\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=3212)\u001b[0m \rEpoch 55: 100%|██████████| 7/7 [00:00<00:00, 53.82it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=1.010, valid_loss=1.350]\rEpoch 55: 100%|██████████| 7/7 [00:00<00:00, 51.89it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.010, valid_loss=1.350]\rEpoch 55: 100%|██████████| 7/7 [00:00<00:00, 51.69it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.030, valid_loss=1.350]\rEpoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.030, valid_loss=1.350]        \rEpoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.030, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 55.05it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.030, valid_loss=1.350]\rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 53.14it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=1.030, valid_loss=1.350]\rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 52.92it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=1.020, valid_loss=1.350]\rEpoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=1.020, valid_loss=1.350]        \rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=1.020, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.10it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3212)\u001b[0m \n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.340]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=3353)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=3353)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=3353)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=3353)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=3353)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=3353)\u001b[0m 2025-06-14 19:04:28.575924: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=3353)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=3353)\u001b[0m E0000 00:00:1749927868.616250    3435 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=3353)\u001b[0m E0000 00:00:1749927868.632181    3435 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=3353)\u001b[0m 2025-06-14 19:04:28.668405: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=3353)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=3353)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","\u001b[36m(_train_tune pid=3353)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=3353)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=3353)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=3353)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=3353)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=3353)\u001b[0m 3 | blocks       | ModuleList    | 2.7 M  | train\n","\u001b[36m(_train_tune pid=3353)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=3353)\u001b[0m 2.7 M     Trainable params\n","\u001b[36m(_train_tune pid=3353)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=3353)\u001b[0m 2.7 M     Total params\n","\u001b[36m(_train_tune pid=3353)\u001b[0m 10.840    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=3353)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=3353)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=3353)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.670]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.570]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.310, train_loss_epoch=2.520]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.450]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.370]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.210]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=2.020]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 191.37it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=2.020, valid_loss=2.480]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.870, valid_loss=2.480]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.710, valid_loss=2.480]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.620, valid_loss=2.480]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.630, valid_loss=2.480]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.580, valid_loss=2.480]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.600, valid_loss=2.480]\n","Epoch 13: 100%|██████████| 7/7 [00:00<00:00, 50.68it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.600, valid_loss=2.480]\n","Epoch 13: 100%|██████████| 7/7 [00:00<00:00, 49.36it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.600, valid_loss=2.480]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.570, valid_loss=2.480]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 204.44it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=1.570, valid_loss=1.960]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.530, valid_loss=1.960]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.470, valid_loss=1.960]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.460, valid_loss=1.960]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.520, valid_loss=1.960]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.490, valid_loss=1.960]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.470, valid_loss=1.960]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.460, valid_loss=1.960]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 189.89it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.460, valid_loss=1.790]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.400, valid_loss=1.790]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.380, valid_loss=1.790]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.370, valid_loss=1.790]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.290, valid_loss=1.790]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.240, valid_loss=1.790]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=1.260, valid_loss=1.790]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.220, valid_loss=1.790]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 156.36it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.200, valid_loss=1.550]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.190, valid_loss=1.550]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.150, valid_loss=1.550]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=1.160, valid_loss=1.550]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.180, valid_loss=1.550]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.150, valid_loss=1.550]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.180, valid_loss=1.550]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 163.79it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.180, valid_loss=1.460]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.140, valid_loss=1.460]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.110, valid_loss=1.460]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=1.090, valid_loss=1.460]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.080, valid_loss=1.460]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.120, valid_loss=1.460]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.110, valid_loss=1.460]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=1.070, valid_loss=1.460]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 199.05it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.110, valid_loss=1.410]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=1.090, valid_loss=1.410]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=1.410]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.090, valid_loss=1.410]\n","Epoch 46: 100%|██████████| 7/7 [00:00<00:00, 46.92it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.090, valid_loss=1.410]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.110, valid_loss=1.410]        \n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.110, valid_loss=1.410]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=1.050, valid_loss=1.410]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=1.060, valid_loss=1.410]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 47.67it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=1.060, valid_loss=1.410]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 206.16it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=1.080, valid_loss=1.390]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=1.080, valid_loss=1.390]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.070, valid_loss=1.390]\n","Epoch 52: 100%|██████████| 7/7 [00:00<00:00, 48.66it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.110, valid_loss=1.390]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.110, valid_loss=1.390]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.070, valid_loss=1.390]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.090, valid_loss=1.390]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=1.060, valid_loss=1.390]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.090, valid_loss=1.390]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.93it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.090, valid_loss=1.390]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=1.070, valid_loss=1.390]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.050, valid_loss=1.390]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=1.060, valid_loss=1.390]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.100, valid_loss=1.390]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.090, valid_loss=1.390]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.100, valid_loss=1.390]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.120, valid_loss=1.390]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 193.67it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.120, valid_loss=1.380]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.090, valid_loss=1.380]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.080, valid_loss=1.380]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.060, valid_loss=1.380]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.090, valid_loss=1.380]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.56it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=1.090, valid_loss=1.380]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=1.060, valid_loss=1.380]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=1.080, valid_loss=1.380]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.060, valid_loss=1.380]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=1.050, valid_loss=1.380]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.040, valid_loss=1.380]\n","Epoch 77: 100%|██████████| 7/7 [00:00<00:00, 48.83it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.040, valid_loss=1.380]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.070, valid_loss=1.380]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 198.63it/s]\u001b[A\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 82:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=1.070, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.26it/s]\u001b[A\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.858, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.080, valid_loss=1.370]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.080, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 186.06it/s]\u001b[A\n","Epoch 93:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.370]\n","Epoch 94:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 95:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.100, valid_loss=1.370]\n","Epoch 96:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 97:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 98:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 99:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 99: 100%|██████████| 7/7 [00:00<00:00, 48.49it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=1.070, valid_loss=1.370]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 205.98it/s]\u001b[A\n","Epoch 100:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 101:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.843, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 102:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 103:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.080, valid_loss=1.370]\n","Epoch 104:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 105:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.090, valid_loss=1.370]\n","Epoch 106:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=1.050, valid_loss=1.370]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 138.40it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 108:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 109:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 110:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 111:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 112:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=1.080, valid_loss=1.370]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 119.97it/s]\u001b[A\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 115:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 116:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 117:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 118:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 119:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 120:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.070, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 121.80it/s]\u001b[A\n","Epoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 122:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 123:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 124:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 125:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 126:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 127:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.060, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.57it/s]\u001b[A\n","Epoch 129:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 130:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 131:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 132:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 133:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.090, valid_loss=1.360]\n","Epoch 134:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=1.030, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:04:57,958\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=3353)\u001b[0m \rEpoch 134: 100%|██████████| 7/7 [00:00<00:00, 49.93it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=1.030, valid_loss=1.360]\rEpoch 134: 100%|██████████| 7/7 [00:00<00:00, 48.71it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.030, valid_loss=1.360]\rEpoch 134: 100%|██████████| 7/7 [00:00<00:00, 48.54it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.080, valid_loss=1.360]\rEpoch 134:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.080, valid_loss=1.360]        \rEpoch 135:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.080, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \n","\u001b[36m(_train_tune pid=3353)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.74it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3353)\u001b[0m \r                                                                       \u001b[A\rEpoch 135:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.080, valid_loss=1.360]\rEpoch 135:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.030, valid_loss=1.360]\rEpoch 135:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.030, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=3574)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=3574)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=3574)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=3574)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=3574)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=3574)\u001b[0m 2025-06-14 19:05:07.416539: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=3574)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=3574)\u001b[0m E0000 00:00:1749927907.455804    3646 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=3574)\u001b[0m E0000 00:00:1749927907.469911    3646 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=3574)\u001b[0m 2025-06-14 19:05:07.509228: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=3574)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=3574)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \n","\u001b[36m(_train_tune pid=3574)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=3574)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=3574)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=3574)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=3574)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=3574)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=3574)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=3574)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=3574)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=3574)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=3574)\u001b[0m 10.297    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=3574)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=3574)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=83.40, train_loss_epoch=5.98e+10]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=976.0, train_loss_epoch=3.64e+4]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.59e+3, train_loss_epoch=8.8e+4]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.22e+3, train_loss_epoch=1.7e+3]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.55e+4, train_loss_epoch=2.53e+4]\n","Epoch 5: 100%|██████████| 7/7 [00:00<00:00, 55.12it/s, v_num=0, train_loss_step=7.55e+4, train_loss_epoch=2.53e+4]\n","Epoch 5: 100%|██████████| 7/7 [00:00<00:00, 53.06it/s, v_num=0, train_loss_step=8.58e+3, train_loss_epoch=2.53e+4]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.58e+3, train_loss_epoch=2.19e+4]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=181.0, train_loss_epoch=1.88e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 185.74it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+3, train_loss_epoch=1.88e+3, valid_loss=245.0]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.16e+3, train_loss_epoch=784.0, valid_loss=245.0]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=297.0, train_loss_epoch=398.0, valid_loss=245.0]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=85.70, train_loss_epoch=151.0, valid_loss=245.0]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=142.0, valid_loss=245.0]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=365.0, valid_loss=245.0]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=40.30, valid_loss=245.0]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=59.30, valid_loss=245.0]        \n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=59.30, valid_loss=245.0]\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.92it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=69.90, train_loss_epoch=59.30, valid_loss=2.580]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=172.0, train_loss_epoch=82.00, valid_loss=2.580]\n","Epoch 15: 100%|██████████| 7/7 [00:00<00:00, 55.14it/s, v_num=0, train_loss_step=172.0, train_loss_epoch=82.00, valid_loss=2.580]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.470, train_loss_epoch=246.0, valid_loss=2.580]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=21.70, train_loss_epoch=114.0, valid_loss=2.580]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=950.0, valid_loss=2.580]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=21.30, valid_loss=2.580]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=98.20, train_loss_epoch=23.70, valid_loss=2.580]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=172.0, train_loss_epoch=29.80, valid_loss=2.580]\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.60it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=29.80, valid_loss=2.210]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=111.0, valid_loss=2.210]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=6.150, valid_loss=2.210]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.150, train_loss_epoch=16.30, valid_loss=2.210]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.960, train_loss_epoch=7.500, valid_loss=2.210]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=3.710, valid_loss=2.210]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.350, valid_loss=2.210]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=3.180, valid_loss=2.210]\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.02it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=5.080, valid_loss=2.160]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=3.230, valid_loss=2.160]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=8.210, valid_loss=2.160]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=30.80, valid_loss=2.160]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.190, valid_loss=2.160]\n","Epoch 33: 100%|██████████| 7/7 [00:00<00:00, 52.36it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=2.190, valid_loss=2.160]\n","Epoch 33: 100%|██████████| 7/7 [00:00<00:00, 52.07it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=2.530, valid_loss=2.160]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=2.530, valid_loss=2.160]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=2.360, valid_loss=2.160]\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 156.14it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=2.360, valid_loss=2.140]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.430, train_loss_epoch=8.840, valid_loss=2.140]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.780, train_loss_epoch=2.850, valid_loss=2.140]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=2.460, valid_loss=2.140]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=2.980, valid_loss=2.140]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=2.200, valid_loss=2.140]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.840, valid_loss=2.140]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=13.30, valid_loss=2.140]\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 143.49it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.400, train_loss_epoch=2.260, valid_loss=2.120]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=6.710, valid_loss=2.120]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.550, valid_loss=2.120]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.490, valid_loss=2.120]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.210, valid_loss=2.120]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.110, valid_loss=2.120]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.090, valid_loss=2.120]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 53.68it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=2.090, valid_loss=2.120]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 188.80it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=2.200, valid_loss=2.120]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=2.200, valid_loss=2.120]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=5.360, valid_loss=2.120]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.140, valid_loss=2.120]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=10.30, valid_loss=2.120]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=2.130, valid_loss=2.120]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=2.100, valid_loss=2.120]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.080, valid_loss=2.120]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.12it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=2.080, valid_loss=2.080]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.850, valid_loss=2.080]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=20.60, valid_loss=2.080]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.010, valid_loss=2.080]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.860, valid_loss=2.080]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=200.0, train_loss_epoch=30.20, valid_loss=2.080]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.080, valid_loss=2.080]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=2.070, valid_loss=2.080]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 116.11it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=2.070, valid_loss=2.090]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.920, valid_loss=2.090]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=2.020, valid_loss=2.090]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=2.010, valid_loss=2.090]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=52.00, valid_loss=2.090]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=1.960, valid_loss=2.090]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=2.210, valid_loss=2.090]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:05:21,672\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=3574)\u001b[0m \rEpoch 70: 100%|██████████| 7/7 [00:00<00:00, 41.90it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=2.210, valid_loss=2.090]\rEpoch 70: 100%|██████████| 7/7 [00:00<00:00, 41.35it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=2.210, valid_loss=2.090]\rEpoch 70: 100%|██████████| 7/7 [00:00<00:00, 41.17it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=2.380, valid_loss=2.090]\rEpoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=2.380, valid_loss=2.090]        \rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=2.380, valid_loss=2.090]\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \n","\u001b[36m(_train_tune pid=3574)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 149.28it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3574)\u001b[0m \r                                                                       \u001b[A\rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.380, valid_loss=2.100]\rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=1.970, valid_loss=2.100]\rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=1.970, valid_loss=2.100]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=3715)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=3715)\u001b[0m Seed set to 3\n","\u001b[36m(_train_tune pid=3715)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=3715)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=3715)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=3715)\u001b[0m 2025-06-14 19:05:32.094190: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=3715)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=3715)\u001b[0m E0000 00:00:1749927932.137031    3797 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=3715)\u001b[0m E0000 00:00:1749927932.149918    3797 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=3715)\u001b[0m 2025-06-14 19:05:32.190805: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=3715)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=3715)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","\u001b[36m(_train_tune pid=3715)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=3715)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=3715)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=3715)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=3715)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=3715)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=3715)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=3715)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=3715)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=3715)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=3715)\u001b[0m 10.286    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=3715)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=3715)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=3715)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 11.47it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=2.450]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=2.110]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.830]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.670]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.560]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.570]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.550]\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.76it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.550, valid_loss=1.890]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.450, valid_loss=1.890]\n","Epoch 8: 100%|██████████| 7/7 [00:00<00:00, 53.74it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.430, valid_loss=1.890]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.430, valid_loss=1.890]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.380, valid_loss=1.890]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.300, valid_loss=1.890]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.250, valid_loss=1.890]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.200, valid_loss=1.890]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.160, valid_loss=1.890]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 157.83it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=1.160, valid_loss=1.500]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.170, valid_loss=1.500]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.140, valid_loss=1.500]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.120, valid_loss=1.500]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.120, valid_loss=1.500]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.100, valid_loss=1.500]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.100, valid_loss=1.500]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.120, valid_loss=1.500]\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 150.52it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.090, valid_loss=1.410]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=1.060, valid_loss=1.410]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=1.060, valid_loss=1.410]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=1.060, valid_loss=1.410]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.040, valid_loss=1.410]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.100, valid_loss=1.410]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.050, valid_loss=1.410]\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 213.18it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.050, valid_loss=1.380]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.060, valid_loss=1.380]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.100, valid_loss=1.380]\n","Epoch 31: 100%|██████████| 7/7 [00:00<00:00, 53.39it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.100, valid_loss=1.380]\n","Epoch 31: 100%|██████████| 7/7 [00:00<00:00, 52.88it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.060, valid_loss=1.380]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.060, valid_loss=1.380]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.080, valid_loss=1.380]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=1.060, valid_loss=1.380]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=1.040, valid_loss=1.380]\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.98it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.080, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 174.72it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=1.020, valid_loss=1.360]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=1.010, valid_loss=1.360]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 53.26it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=1.050, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.49it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=1.020, valid_loss=1.350]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.040, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 154.68it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.080, valid_loss=1.340]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=1.040, valid_loss=1.340]\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 143.87it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.020, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:05:48,246\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=3715)\u001b[0m \n","\u001b[36m(_train_tune pid=3715)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \n","\u001b[36m(_train_tune pid=3715)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 120.47it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3715)\u001b[0m \r                                                                       \u001b[A\rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.020, valid_loss=1.350]\rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.040, valid_loss=1.350]\rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.040, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=3875)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=3875)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=3875)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=3875)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=3875)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=3875)\u001b[0m 2025-06-14 19:05:57.969948: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=3875)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=3875)\u001b[0m E0000 00:00:1749927958.001445    3953 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=3875)\u001b[0m E0000 00:00:1749927958.009007    3953 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=3875)\u001b[0m 2025-06-14 19:05:58.034177: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=3875)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=3875)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \n","\u001b[36m(_train_tune pid=3875)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=3875)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=3875)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=3875)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=3875)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=3875)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=3875)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=3875)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=3875)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=3875)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=3875)\u001b[0m 10.252    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=3875)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=3875)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.19e+6, train_loss_epoch=7.8e+10]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.75e+3, train_loss_epoch=4.51e+5]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+5, train_loss_epoch=1.38e+5]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.41e+5, train_loss_epoch=2.99e+5]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+5, train_loss_epoch=1.83e+5]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.77e+3, train_loss_epoch=5.41e+4]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.76e+3, train_loss_epoch=2.11e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 191.14it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.83e+3, train_loss_epoch=2.11e+3, valid_loss=4.23e+3]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.67e+3, train_loss_epoch=3.13e+3, valid_loss=4.23e+3]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.04e+3, train_loss_epoch=3.33e+3, valid_loss=4.23e+3]\n","Epoch 9: 100%|██████████| 7/7 [00:00<00:00, 52.73it/s, v_num=0, train_loss_step=2.02e+3, train_loss_epoch=3.33e+3, valid_loss=4.23e+3]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.02e+3, train_loss_epoch=2.65e+3, valid_loss=4.23e+3]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+3, train_loss_epoch=1.56e+3, valid_loss=4.23e+3]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.37e+3, train_loss_epoch=1.09e+3, valid_loss=4.23e+3]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=590.0, train_loss_epoch=633.0, valid_loss=4.23e+3]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=312.0, train_loss_epoch=447.0, valid_loss=4.23e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.37it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=396.0, train_loss_epoch=447.0, valid_loss=336.0]  \n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=303.0, train_loss_epoch=311.0, valid_loss=336.0]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=283.0, train_loss_epoch=225.0, valid_loss=336.0]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=172.0, train_loss_epoch=249.0, valid_loss=336.0]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=470.0, train_loss_epoch=288.0, valid_loss=336.0]\n","Epoch 18: 100%|██████████| 7/7 [00:00<00:00, 54.29it/s, v_num=0, train_loss_step=470.0, train_loss_epoch=288.0, valid_loss=336.0]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=256.0, train_loss_epoch=486.0, valid_loss=336.0]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=305.0, train_loss_epoch=417.0, valid_loss=336.0]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=250.0, train_loss_epoch=251.0, valid_loss=336.0]\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.48it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=210.0, train_loss_epoch=251.0, valid_loss=220.0]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=129.0, train_loss_epoch=186.0, valid_loss=220.0]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=317.0, train_loss_epoch=199.0, valid_loss=220.0]\n","Epoch 23: 100%|██████████| 7/7 [00:00<00:00, 52.74it/s, v_num=0, train_loss_step=214.0, train_loss_epoch=274.0, valid_loss=220.0]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=214.0, train_loss_epoch=274.0, valid_loss=220.0]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=226.0, train_loss_epoch=261.0, valid_loss=220.0]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=210.0, train_loss_epoch=279.0, valid_loss=220.0]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=146.0, train_loss_epoch=239.0, valid_loss=220.0]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=253.0, train_loss_epoch=178.0, valid_loss=220.0]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 172.40it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=363.0, train_loss_epoch=288.0, valid_loss=330.0]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=222.0, train_loss_epoch=245.0, valid_loss=330.0]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=178.0, train_loss_epoch=243.0, valid_loss=330.0]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=188.0, train_loss_epoch=232.0, valid_loss=330.0]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=238.0, train_loss_epoch=207.0, valid_loss=330.0]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=138.0, train_loss_epoch=168.0, valid_loss=330.0]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=193.0, train_loss_epoch=167.0, valid_loss=330.0]\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 198.06it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=130.0, train_loss_epoch=167.0, valid_loss=121.0]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=99.70, train_loss_epoch=140.0, valid_loss=121.0]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=156.0, train_loss_epoch=94.30, valid_loss=121.0]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=163.0, train_loss_epoch=137.0, valid_loss=121.0]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=246.0, train_loss_epoch=205.0, valid_loss=121.0]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=162.0, train_loss_epoch=138.0, valid_loss=121.0]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=151.0, train_loss_epoch=167.0, valid_loss=121.0]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=240.0, train_loss_epoch=184.0, valid_loss=121.0]\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 204.84it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=132.0, valid_loss=135.0]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=120.0, valid_loss=135.0]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=77.80, train_loss_epoch=114.0, valid_loss=135.0]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=115.0, valid_loss=135.0]\n","Epoch 46: 100%|██████████| 7/7 [00:00<00:00, 54.31it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=115.0, valid_loss=135.0]\n","Epoch 46: 100%|██████████| 7/7 [00:00<00:00, 51.82it/s, v_num=0, train_loss_step=135.0, train_loss_epoch=126.0, valid_loss=135.0]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=135.0, train_loss_epoch=126.0, valid_loss=135.0]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=90.50, train_loss_epoch=128.0, valid_loss=135.0]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=96.70, train_loss_epoch=98.60, valid_loss=135.0]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 52.19it/s, v_num=0, train_loss_step=36.20, train_loss_epoch=98.60, valid_loss=135.0]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 192.28it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=36.20, train_loss_epoch=70.50, valid_loss=51.30]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=63.80, train_loss_epoch=52.40, valid_loss=51.30]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=37.90, train_loss_epoch=46.80, valid_loss=51.30]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=35.90, valid_loss=51.30]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=26.10, train_loss_epoch=29.30, valid_loss=51.30]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=36.70, train_loss_epoch=37.40, valid_loss=51.30]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=54.20, train_loss_epoch=39.30, valid_loss=51.30]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=69.40, train_loss_epoch=65.90, valid_loss=51.30]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 191.74it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=42.50, train_loss_epoch=65.90, valid_loss=44.80]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=51.10, train_loss_epoch=47.10, valid_loss=44.80]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=42.80, train_loss_epoch=39.10, valid_loss=44.80]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=41.10, train_loss_epoch=36.70, valid_loss=44.80]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=35.50, train_loss_epoch=39.50, valid_loss=44.80]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=45.60, train_loss_epoch=61.40, valid_loss=44.80]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=31.70, train_loss_epoch=40.60, valid_loss=44.80]\n","Epoch 63: 100%|██████████| 7/7 [00:00<00:00, 53.51it/s, v_num=0, train_loss_step=48.50, train_loss_epoch=40.60, valid_loss=44.80]\n","Epoch 63: 100%|██████████| 7/7 [00:00<00:00, 53.18it/s, v_num=0, train_loss_step=48.50, train_loss_epoch=61.40, valid_loss=44.80]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=48.50, train_loss_epoch=61.40, valid_loss=44.80]\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 192.00it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=42.80, train_loss_epoch=61.40, valid_loss=76.80]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=50.90, train_loss_epoch=53.90, valid_loss=76.80]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=46.60, train_loss_epoch=53.60, valid_loss=76.80]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=66.10, train_loss_epoch=51.30, valid_loss=76.80]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=47.10, train_loss_epoch=39.00, valid_loss=76.80]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=32.40, train_loss_epoch=44.90, valid_loss=76.80]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=59.60, train_loss_epoch=41.50, valid_loss=76.80]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=62.30, train_loss_epoch=63.20, valid_loss=76.80]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:06:12,393\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=3875)\u001b[0m \n","\u001b[36m(_train_tune pid=3875)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 144.84it/s]\u001b[A\n","\u001b[36m(_train_tune pid=3875)\u001b[0m \n","\u001b[36m(_train_tune pid=3875)\u001b[0m \r                                                                       \u001b[A\rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=52.50, train_loss_epoch=63.20, valid_loss=49.20]\rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=52.50, train_loss_epoch=61.40, valid_loss=49.20]\rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=52.50, train_loss_epoch=61.40, valid_loss=49.20]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=4023)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=4023)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=4023)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=4023)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=4023)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=4023)\u001b[0m 2025-06-14 19:06:23.252171: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=4023)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=4023)\u001b[0m E0000 00:00:1749927983.275875    4104 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=4023)\u001b[0m E0000 00:00:1749927983.283114    4104 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=4023)\u001b[0m 2025-06-14 19:06:23.309609: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=4023)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=4023)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=4023)\u001b[0m \n","\u001b[36m(_train_tune pid=4023)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=4023)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4023)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=4023)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=4023)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=4023)\u001b[0m 3 | blocks       | ModuleList    | 2.7 M  | train\n","\u001b[36m(_train_tune pid=4023)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4023)\u001b[0m 2.7 M     Trainable params\n","\u001b[36m(_train_tune pid=4023)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=4023)\u001b[0m 2.7 M     Total params\n","\u001b[36m(_train_tune pid=4023)\u001b[0m 10.840    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=4023)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=4023)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=4023)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 13.72it/s]\n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.86e+5, train_loss_epoch=2.22e+8]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.62e+3, train_loss_epoch=1.82e+5]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=146.0, train_loss_epoch=847.0]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=139.0, train_loss_epoch=117.0]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=20.40]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.190, train_loss_epoch=5.280]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=3.790]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.68it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=3.790, valid_loss=2.220]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.800, train_loss_epoch=2.850, valid_loss=2.220]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.170, valid_loss=2.220]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=2.180, valid_loss=2.220]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.850, valid_loss=2.220]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=1.960, valid_loss=2.220]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.070, valid_loss=2.220]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.980, valid_loss=2.220]\n","\u001b[36m(_train_tune pid=4023)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.15it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.980, valid_loss=2.070]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=1.890, valid_loss=2.070]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.890, train_loss_epoch=2.140, valid_loss=2.070]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.830, valid_loss=2.070]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.960, valid_loss=2.070]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.860, valid_loss=2.070]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.870, valid_loss=2.070]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.810, valid_loss=2.070]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4023)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 194.53it/s]\u001b[A\n","Epoch 21: 100%|██████████| 7/7 [00:00<00:00, 37.45it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.810, valid_loss=2.070]\n","Epoch 21: 100%|██████████| 7/7 [00:00<00:00, 36.47it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.740, valid_loss=2.070]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.740, valid_loss=2.070]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.850, valid_loss=2.070]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.870, valid_loss=2.070]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.950, valid_loss=2.070]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.880, valid_loss=2.070]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.840, valid_loss=2.070]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.840, valid_loss=2.070]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:06:31,858\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=4023)\u001b[0m \n","\u001b[36m(_train_tune pid=4023)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4023)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4023)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4023)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 205.78it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4023)\u001b[0m \r                                                                       \u001b[A\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.840, valid_loss=2.070]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.870, valid_loss=2.070]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.870, valid_loss=2.070]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=4153)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=4153)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=4153)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=4153)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=4153)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=4153)\u001b[0m 2025-06-14 19:06:42.134894: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=4153)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=4153)\u001b[0m E0000 00:00:1749928002.160148    4235 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=4153)\u001b[0m E0000 00:00:1749928002.167606    4235 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=4153)\u001b[0m 2025-06-14 19:06:42.194685: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=4153)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=4153)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=4153)\u001b[0m \n","\u001b[36m(_train_tune pid=4153)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=4153)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4153)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=4153)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=4153)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=4153)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=4153)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4153)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=4153)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=4153)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=4153)\u001b[0m 10.252    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=4153)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=4153)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 20.32it/s]\n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.590]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.480]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.390]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.280]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.170]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=1.120]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.85it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4153)\u001b[0m \n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=1.120, valid_loss=1.430]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.130, valid_loss=1.430]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.110, valid_loss=1.430]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.100, valid_loss=1.430]\n","Epoch 10: 100%|██████████| 7/7 [00:00<00:00, 53.99it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.100, valid_loss=1.430]\n","Epoch 10: 100%|██████████| 7/7 [00:00<00:00, 52.94it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.100, valid_loss=1.430]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.100, valid_loss=1.430]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.100, valid_loss=1.430]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=1.050, valid_loss=1.430]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=1.060, valid_loss=1.430]\n","\u001b[36m(_train_tune pid=4153)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.72it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.865, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=1.050, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4153)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 198.88it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.040, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=4153)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.39it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4153)\u001b[0m \n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=1.020, valid_loss=1.360]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=1.030, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=4153)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.41it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 38: 100%|██████████| 7/7 [00:00<00:00, 47.52it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=1.020, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=4153)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4153)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 131.13it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 48.28it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=1.050, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4153)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 131.27it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=1.030, valid_loss=1.330]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=1.020, valid_loss=1.330]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=1.050, valid_loss=1.330]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.060, valid_loss=1.330]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.030, valid_loss=1.330]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=1.030, valid_loss=1.330]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=1.030, valid_loss=1.330]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.010, valid_loss=1.330]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4153)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 187.55it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 59: 100%|██████████| 7/7 [00:00<00:00, 54.19it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 59: 100%|██████████| 7/7 [00:00<00:00, 52.69it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.999, valid_loss=1.340]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.020, valid_loss=1.340]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.11it/s]\u001b[A\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:06:54,950\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=4153)\u001b[0m \n","\u001b[36m(_train_tune pid=4153)\u001b[0m \r                                                                       \u001b[A\rEpoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=1.020, valid_loss=1.340]\rEpoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.984, valid_loss=1.340]\rEpoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.984, valid_loss=1.340]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=4300)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=4300)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=4300)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=4300)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=4300)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=4300)\u001b[0m 2025-06-14 19:07:04.078986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=4300)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=4300)\u001b[0m E0000 00:00:1749928024.120204    4376 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=4300)\u001b[0m E0000 00:00:1749928024.132009    4376 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=4300)\u001b[0m 2025-06-14 19:07:04.172351: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=4300)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=4300)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=4300)\u001b[0m \n","\u001b[36m(_train_tune pid=4300)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=4300)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4300)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=4300)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=4300)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=4300)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=4300)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4300)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=4300)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=4300)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=4300)\u001b[0m 10.297    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=4300)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=4300)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=1.920]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.470]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.280]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.170]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.110]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.100]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.090]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4300)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 177.85it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.090, valid_loss=1.370]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=1.100, valid_loss=1.370]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=1.090, valid_loss=1.370]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=1.050, valid_loss=1.370]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.65it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=1.030, valid_loss=1.370]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=1.020, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=4300)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.78it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.020, valid_loss=1.350]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=1.010, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 27: 100%|██████████| 7/7 [00:00<00:00, 52.38it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=1.050, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=4300)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4300)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 184.09it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=1.020, valid_loss=1.360]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.040, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:07:13,237\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=4300)\u001b[0m \n","\u001b[36m(_train_tune pid=4300)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4300)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4300)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4300)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 196.24it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4300)\u001b[0m \r                                                                       \u001b[A\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=1.040, valid_loss=1.370]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=1.020, valid_loss=1.370]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=1.020, valid_loss=1.370]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=4431)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=4431)\u001b[0m Seed set to 4\n","\u001b[36m(_train_tune pid=4431)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=4431)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=4431)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=4431)\u001b[0m 2025-06-14 19:07:24.189580: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=4431)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=4431)\u001b[0m E0000 00:00:1749928044.213159    4512 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=4431)\u001b[0m E0000 00:00:1749928044.220439    4512 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=4431)\u001b[0m 2025-06-14 19:07:24.244955: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=4431)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=4431)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=4431)\u001b[0m \n","\u001b[36m(_train_tune pid=4431)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=4431)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4431)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=4431)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=4431)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=4431)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=4431)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4431)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=4431)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=4431)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=4431)\u001b[0m 10.262    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=4431)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=4431)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+5, train_loss_epoch=1.05e+12]\n","Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 45.32it/s, v_num=0, train_loss_step=1.07e+5, train_loss_epoch=1.05e+12]\n","Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 43.43it/s, v_num=0, train_loss_step=1.26e+8, train_loss_epoch=1.05e+12]\n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+8, train_loss_epoch=6.16e+9]        \n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+8, train_loss_epoch=6.16e+9]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.86e+6, train_loss_epoch=5.76e+8]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+5, train_loss_epoch=2.24e+6]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.44e+5, train_loss_epoch=4.95e+5]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.17e+4, train_loss_epoch=1.14e+5]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.63e+3, train_loss_epoch=5.23e+4]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4431)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 185.49it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+4, train_loss_epoch=5.23e+4, valid_loss=7.06e+3]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=155.0, train_loss_epoch=2.32e+4, valid_loss=7.06e+3]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.860, train_loss_epoch=4.46e+3, valid_loss=7.06e+3]\n","Epoch 9: 100%|██████████| 7/7 [00:00<00:00, 53.87it/s, v_num=0, train_loss_step=8.860, train_loss_epoch=4.46e+3, valid_loss=7.06e+3]\n","Epoch 9: 100%|██████████| 7/7 [00:00<00:00, 51.93it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=4.46e+3, valid_loss=7.06e+3]\n","Epoch 9: 100%|██████████| 7/7 [00:00<00:00, 51.65it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=35.90, valid_loss=7.06e+3]  \n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=35.90, valid_loss=7.06e+3]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=43.90, train_loss_epoch=1.39e+3, valid_loss=7.06e+3]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=20.90, train_loss_epoch=941.0, valid_loss=7.06e+3]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=17.30, valid_loss=7.06e+3]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=13.30, valid_loss=7.06e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.90it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4431)\u001b[0m \n","                                                                       \u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=2.450]  \n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.400, train_loss_epoch=16.10, valid_loss=2.450]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.790, train_loss_epoch=13.60, valid_loss=2.450]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=12.80, valid_loss=2.450]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.730, train_loss_epoch=18.80, valid_loss=2.450]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.60, valid_loss=2.450]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.120, train_loss_epoch=127.0, valid_loss=2.450]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=23.00, train_loss_epoch=21.00, valid_loss=2.450]\n","\u001b[36m(_train_tune pid=4431)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 158.00it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=21.00, valid_loss=2.140]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=11.80, valid_loss=2.140]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=17.20, valid_loss=2.140]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=14.10, valid_loss=2.140]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=11.00, valid_loss=2.140]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.50, valid_loss=2.140]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=13.20, valid_loss=2.140]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=23.10, train_loss_epoch=13.20, valid_loss=2.140]\n","\u001b[36m(_train_tune pid=4431)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 97.97it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4431)\u001b[0m \n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=12.50, valid_loss=2.100]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=16.20, valid_loss=2.100]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.40, valid_loss=2.100]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=17.70, valid_loss=2.100]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=12.40, valid_loss=2.100]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=10.90, valid_loss=2.100]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=16.10, valid_loss=2.100]\n","\u001b[36m(_train_tune pid=4431)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 126.11it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=16.10, valid_loss=2.080]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.700, train_loss_epoch=13.80, valid_loss=2.080]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50, valid_loss=2.080]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=13.70, valid_loss=2.080]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=17.50, valid_loss=2.080]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=12.30, valid_loss=2.080]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=14.50, valid_loss=2.080]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=32.70, train_loss_epoch=17.30, valid_loss=2.080]\n","\u001b[36m(_train_tune pid=4431)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 198.67it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=23.10, train_loss_epoch=17.40, valid_loss=2.100]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.130, train_loss_epoch=9.990, valid_loss=2.100]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=16.60, valid_loss=2.100]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=19.50, valid_loss=2.100]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=32.70, train_loss_epoch=16.50, valid_loss=2.100]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.440, train_loss_epoch=12.00, valid_loss=2.100]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:07:35,195\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=4431)\u001b[0m \rEpoch 48: 100%|██████████| 7/7 [00:00<00:00, 55.46it/s, v_num=0, train_loss_step=6.440, train_loss_epoch=12.00, valid_loss=2.100]\rEpoch 48: 100%|██████████| 7/7 [00:00<00:00, 53.56it/s, v_num=0, train_loss_step=2.84e+3, train_loss_epoch=12.00, valid_loss=2.100]\rEpoch 48: 100%|██████████| 7/7 [00:00<00:00, 53.30it/s, v_num=0, train_loss_step=2.84e+3, train_loss_epoch=415.0, valid_loss=2.100]\rEpoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.84e+3, train_loss_epoch=415.0, valid_loss=2.100]        \rEpoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.84e+3, train_loss_epoch=415.0, valid_loss=2.100]\n","\u001b[36m(_train_tune pid=4431)\u001b[0m \rEpoch 49: 100%|██████████| 7/7 [00:00<00:00, 51.97it/s, v_num=0, train_loss_step=2.84e+3, train_loss_epoch=415.0, valid_loss=2.100]\rEpoch 49: 100%|██████████| 7/7 [00:00<00:00, 50.18it/s, v_num=0, train_loss_step=21.80, train_loss_epoch=415.0, valid_loss=2.100]  \n","\u001b[36m(_train_tune pid=4431)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4431)\u001b[0m \n","\u001b[36m(_train_tune pid=4431)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4431)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.59it/s]\u001b[A\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 37.07it/s, v_num=0, train_loss_step=21.80, train_loss_epoch=20.00, valid_loss=2.080]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=4573)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=4573)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=4573)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=4573)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=4573)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=4573)\u001b[0m 2025-06-14 19:07:45.860217: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=4573)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=4573)\u001b[0m E0000 00:00:1749928065.901862    4651 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=4573)\u001b[0m E0000 00:00:1749928065.915789    4651 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=4573)\u001b[0m 2025-06-14 19:07:45.958467: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=4573)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=4573)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=4573)\u001b[0m \n","\u001b[36m(_train_tune pid=4573)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=4573)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4573)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=4573)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=4573)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=4573)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=4573)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4573)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=4573)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=4573)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=4573)\u001b[0m 10.286    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=4573)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=4573)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=4.64e+4]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.810]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.880]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.630]        \n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.630]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.580]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.500]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.490]\n","\u001b[36m(_train_tune pid=4573)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 194.21it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=1.490, valid_loss=1.650]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.370, valid_loss=1.650]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.310, valid_loss=1.650]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.300, valid_loss=1.650]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.210, valid_loss=1.650]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.240, valid_loss=1.650]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=1.210, valid_loss=1.650]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.200, valid_loss=1.650]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4573)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.72it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.200, valid_loss=1.410]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.150, valid_loss=1.410]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=1.150, valid_loss=1.410]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=1.140, valid_loss=1.410]\n","Epoch 17: 100%|██████████| 7/7 [00:00<00:00, 54.12it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=1.140, valid_loss=1.410]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.150, valid_loss=1.410]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.130, valid_loss=1.410]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.090, valid_loss=1.410]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.100, valid_loss=1.410]\n","\u001b[36m(_train_tune pid=4573)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.74it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.100, valid_loss=1.350]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.130, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.110, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.120, valid_loss=1.350]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.150, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.130, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.090, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=4573)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.35it/s]\u001b[A\n","Epoch 28: 100%|██████████| 7/7 [00:00<00:00, 40.22it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.090, valid_loss=1.360]\n","Epoch 28: 100%|██████████| 7/7 [00:00<00:00, 39.17it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=1.120, valid_loss=1.360]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.100, valid_loss=1.360]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.120, valid_loss=1.360]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.110, valid_loss=1.360]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.130, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:07:54,429\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=4573)\u001b[0m \rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 54.80it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.130, valid_loss=1.360]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 52.83it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.130, valid_loss=1.360]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 52.60it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.090, valid_loss=1.360]\rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.090, valid_loss=1.360]        \rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.090, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=4573)\u001b[0m \n","\u001b[36m(_train_tune pid=4573)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4573)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4573)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 193.45it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.080, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=4702)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=4702)\u001b[0m Seed set to 3\n","\u001b[36m(_train_tune pid=4702)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=4702)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=4702)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=4702)\u001b[0m 2025-06-14 19:08:05.102281: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=4702)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=4702)\u001b[0m E0000 00:00:1749928085.125731    4781 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=4702)\u001b[0m E0000 00:00:1749928085.132963    4781 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=4702)\u001b[0m 2025-06-14 19:08:05.157256: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=4702)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=4702)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=4702)\u001b[0m \n","\u001b[36m(_train_tune pid=4702)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=4702)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4702)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=4702)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=4702)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=4702)\u001b[0m 3 | blocks       | ModuleList    | 2.7 M  | train\n","\u001b[36m(_train_tune pid=4702)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4702)\u001b[0m 2.7 M     Trainable params\n","\u001b[36m(_train_tune pid=4702)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=4702)\u001b[0m 2.7 M     Total params\n","\u001b[36m(_train_tune pid=4702)\u001b[0m 10.806    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=4702)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=4702)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=9.5e+3]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.890]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.120, train_loss_epoch=2.440]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.180]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.650]\n","Epoch 5: 100%|██████████| 7/7 [00:00<00:00, 50.39it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.650]\n","Epoch 5: 100%|██████████| 7/7 [00:00<00:00, 48.92it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.650]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.610]        \n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.610]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.590]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4702)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 182.86it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.590, valid_loss=1.940]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.520, valid_loss=1.940]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.540, valid_loss=1.940]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.530, valid_loss=1.940]\n","Epoch 10: 100%|██████████| 7/7 [00:00<00:00, 44.73it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.530, valid_loss=1.940]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.490, valid_loss=1.940]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.490, valid_loss=1.940]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.470, valid_loss=1.940]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.430, valid_loss=1.940]\n","\u001b[36m(_train_tune pid=4702)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 166.45it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.430, valid_loss=1.770]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.470, valid_loss=1.770]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.510, valid_loss=1.770]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.400, valid_loss=1.770]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.340, valid_loss=1.770]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.300, valid_loss=1.770]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.290, valid_loss=1.770]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.540, valid_loss=1.770]\n","\u001b[36m(_train_tune pid=4702)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 123.88it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.540, valid_loss=1.820]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=2.000, valid_loss=1.820]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.420, valid_loss=1.820]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=1.280, valid_loss=1.820]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=1.260, valid_loss=1.820]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.210, valid_loss=1.820]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.240, valid_loss=1.820]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.170, valid_loss=1.820]\n","\u001b[36m(_train_tune pid=4702)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.57it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.170, valid_loss=1.460]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.190, valid_loss=1.460]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=1.460]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.210, valid_loss=1.460]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.160, valid_loss=1.460]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.170, valid_loss=1.460]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=1.170, valid_loss=1.460]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=1.130, valid_loss=1.460]\n","\u001b[36m(_train_tune pid=4702)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4702)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 174.19it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.190, valid_loss=1.570]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.280, valid_loss=1.570]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=1.200, valid_loss=1.570]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=1.170, valid_loss=1.570]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.160, valid_loss=1.570]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.330, valid_loss=1.570]\n","Epoch 41: 100%|██████████| 7/7 [00:00<00:00, 49.39it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.330, valid_loss=1.570]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.270, valid_loss=1.570]        \n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.270, valid_loss=1.570]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:08:15,408\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=4702)\u001b[0m \n","\u001b[36m(_train_tune pid=4702)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4702)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4702)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4702)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 203.62it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4702)\u001b[0m \r                                                                       \u001b[A\rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.270, valid_loss=1.500]\rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.180, valid_loss=1.500]\rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.180, valid_loss=1.500]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=4838)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=4838)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=4838)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=4838)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=4838)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=4838)\u001b[0m 2025-06-14 19:08:26.154471: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=4838)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=4838)\u001b[0m E0000 00:00:1749928106.185606    4916 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=4838)\u001b[0m E0000 00:00:1749928106.194244    4916 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=4838)\u001b[0m 2025-06-14 19:08:26.223038: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=4838)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=4838)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","\u001b[36m(_train_tune pid=4838)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=4838)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4838)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=4838)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=4838)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=4838)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=4838)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=4838)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=4838)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=4838)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=4838)\u001b[0m 10.262    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=4838)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=4838)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.590]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.360]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.140]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=2.000]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.860]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.750]\n","Epoch 6: 100%|██████████| 7/7 [00:00<00:00, 54.23it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.750]\n","Epoch 6: 100%|██████████| 7/7 [00:00<00:00, 52.34it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.750]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.610]\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 194.85it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.610, valid_loss=2.070]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.610, valid_loss=2.070]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.600, valid_loss=2.070]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.560, valid_loss=2.070]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.540, valid_loss=2.070]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.560, valid_loss=2.070]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.490, valid_loss=2.070]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.510, valid_loss=2.070]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 189.01it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.510, valid_loss=1.960]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.520, valid_loss=1.960]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.530, valid_loss=1.960]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.520, valid_loss=1.960]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.510, valid_loss=1.960]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.490, valid_loss=1.960]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.470, valid_loss=1.960]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.490, valid_loss=1.960]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 179.03it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.460, valid_loss=1.870]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.460, valid_loss=1.870]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.430, valid_loss=1.870]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.430, valid_loss=1.870]\n","Epoch 25: 100%|██████████| 7/7 [00:00<00:00, 52.52it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.430, valid_loss=1.870]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.420, valid_loss=1.870]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.360, valid_loss=1.870]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.330, valid_loss=1.870]\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 183.21it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.330, valid_loss=1.650]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.350, valid_loss=1.650]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.270, valid_loss=1.650]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.220, valid_loss=1.650]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.200, valid_loss=1.650]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.170, valid_loss=1.650]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.190, valid_loss=1.650]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.160, valid_loss=1.650]\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.58it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.170, valid_loss=1.490]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.160, valid_loss=1.490]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.180, valid_loss=1.490]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.130, valid_loss=1.490]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.130, valid_loss=1.490]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.130, valid_loss=1.490]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.100, valid_loss=1.490]\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 198.13it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.130, valid_loss=1.440]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.120, valid_loss=1.440]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.100, valid_loss=1.440]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.130, valid_loss=1.440]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.080, valid_loss=1.440]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.100, valid_loss=1.440]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.110, valid_loss=1.440]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 44.74it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.110, valid_loss=1.440]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 155.56it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.090, valid_loss=1.400]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=1.080, valid_loss=1.400]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=1.100, valid_loss=1.400]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.120, valid_loss=1.400]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.400]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=1.090, valid_loss=1.400]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=1.090, valid_loss=1.400]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.060, valid_loss=1.400]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 138.70it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.390]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=1.080, valid_loss=1.390]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.816, train_loss_epoch=1.090, valid_loss=1.390]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.060, valid_loss=1.390]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.050, valid_loss=1.390]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=1.050, valid_loss=1.390]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.070, valid_loss=1.390]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.070, valid_loss=1.390]\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 121.16it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 64: 100%|██████████| 7/7 [00:00<00:00, 30.55it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.080, valid_loss=1.380]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=1.080, valid_loss=1.380]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.090, valid_loss=1.380]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=1.070, valid_loss=1.380]\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 206.29it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.080, valid_loss=1.380]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.080, valid_loss=1.380]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.090, valid_loss=1.380]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=1.040, valid_loss=1.380]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.050, valid_loss=1.380]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=1.070, valid_loss=1.380]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 199.86it/s]\u001b[A\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.090, valid_loss=1.370]\n","Epoch 82:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.080, valid_loss=1.370]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=1.070, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.12it/s]\u001b[A\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.080, valid_loss=1.370]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=1.070, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.16it/s]\u001b[A\n","Epoch 93:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 94:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 95:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 96:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 97:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 98:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.090, valid_loss=1.360]\n","Epoch 99:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 99: 100%|██████████| 7/7 [00:00<00:00, 52.19it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=1.060, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 179.23it/s]\u001b[A\n","Epoch 100:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 101:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 102:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 103:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 104:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 105:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 106:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.080, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 205.53it/s]\u001b[A\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 108:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 109:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 110:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 111:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 111: 100%|██████████| 7/7 [00:00<00:00, 53.77it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 111: 100%|██████████| 7/7 [00:00<00:00, 51.43it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 112:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.040, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:08:46,146\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=4838)\u001b[0m \rEpoch 113: 100%|██████████| 7/7 [00:00<00:00, 55.27it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.040, valid_loss=1.360]\rEpoch 113: 100%|██████████| 7/7 [00:00<00:00, 53.27it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.040, valid_loss=1.360]\rEpoch 113: 100%|██████████| 7/7 [00:00<00:00, 53.07it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.050, valid_loss=1.360]\rEpoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.050, valid_loss=1.360]        \rEpoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.050, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","\u001b[36m(_train_tune pid=4838)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \n","\u001b[36m(_train_tune pid=4838)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.13it/s]\u001b[A\n","\u001b[36m(_train_tune pid=4838)\u001b[0m \r                                                                       \u001b[A\rEpoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.050, valid_loss=1.360]\rEpoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.060, valid_loss=1.360]\rEpoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.060, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=5016)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=5016)\u001b[0m Seed set to 2\n","\u001b[36m(_train_tune pid=5016)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=5016)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=5016)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=5016)\u001b[0m 2025-06-14 19:08:57.102342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=5016)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=5016)\u001b[0m E0000 00:00:1749928137.125902    5099 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=5016)\u001b[0m E0000 00:00:1749928137.133518    5099 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=5016)\u001b[0m 2025-06-14 19:08:57.157198: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=5016)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=5016)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \n","\u001b[36m(_train_tune pid=5016)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=5016)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5016)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=5016)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=5016)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=5016)\u001b[0m 3 | blocks       | ModuleList    | 2.7 M  | train\n","\u001b[36m(_train_tune pid=5016)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5016)\u001b[0m 2.7 M     Trainable params\n","\u001b[36m(_train_tune pid=5016)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=5016)\u001b[0m 2.7 M     Total params\n","\u001b[36m(_train_tune pid=5016)\u001b[0m 10.806    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=5016)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=5016)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=3.36e+4]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.820]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=3.000]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.820]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.590]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.380]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.400]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 189.32it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.400, valid_loss=1.560]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.300, valid_loss=1.560]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.230, valid_loss=1.560]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.230, valid_loss=1.560]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=1.130, valid_loss=1.560]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.170, valid_loss=1.560]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.180, valid_loss=1.560]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=1.140, valid_loss=1.560]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 142.14it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.140, valid_loss=1.410]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=1.090, valid_loss=1.410]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.110, valid_loss=1.410]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.110, valid_loss=1.410]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=1.090, valid_loss=1.410]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.070, valid_loss=1.410]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=1.070, valid_loss=1.410]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=1.100, valid_loss=1.410]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 132.43it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.100, valid_loss=1.380]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.090, valid_loss=1.380]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=1.070, valid_loss=1.380]        \n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.100, valid_loss=1.380]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.110, valid_loss=1.380]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=1.060, valid_loss=1.380]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.765, train_loss_epoch=1.100, valid_loss=1.380]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.120, valid_loss=1.380]\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 128.75it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.120, valid_loss=1.440]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.110, valid_loss=1.440]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.060, valid_loss=1.440]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.130, valid_loss=1.440]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=1.050, valid_loss=1.440]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.090, valid_loss=1.440]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=1.080, valid_loss=1.440]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.090, valid_loss=1.440]\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.91it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.100, valid_loss=1.380]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=1.090, valid_loss=1.380]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 40: 100%|██████████| 7/7 [00:00<00:00, 50.48it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=1.060, valid_loss=1.380]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.080, valid_loss=1.380]\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 203.81it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 47.71it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.040, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.36it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 50: 100%|██████████| 7/7 [00:00<00:00, 49.45it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=1.010, valid_loss=1.360]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.090, valid_loss=1.360]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.090, valid_loss=1.360]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=1.020, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 193.95it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.020, valid_loss=1.350]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.080, valid_loss=1.350]\n","Epoch 61: 100%|██████████| 7/7 [00:00<00:00, 49.29it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.080, valid_loss=1.350]\n","Epoch 61: 100%|██████████| 7/7 [00:00<00:00, 48.26it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.080, valid_loss=1.350]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.100, valid_loss=1.350]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.060, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.54it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 67: 100%|██████████| 7/7 [00:00<00:00, 48.32it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=1.030, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 190.84it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.060, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:09:12,975\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=5016)\u001b[0m \n","\u001b[36m(_train_tune pid=5016)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 160.32it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5016)\u001b[0m \r                                                                       \u001b[A\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.060, valid_loss=1.350]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.040, valid_loss=1.350]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.040, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=5176)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=5176)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=5176)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=5176)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=5176)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=5176)\u001b[0m 2025-06-14 19:09:24.305795: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=5176)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=5176)\u001b[0m E0000 00:00:1749928164.334280    5262 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=5176)\u001b[0m E0000 00:00:1749928164.344371    5262 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=5176)\u001b[0m 2025-06-14 19:09:24.377062: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=5176)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=5176)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=5176)\u001b[0m \n","\u001b[36m(_train_tune pid=5176)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=5176)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5176)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=5176)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=5176)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=5176)\u001b[0m 3 | blocks       | ModuleList    | 2.7 M  | train\n","\u001b[36m(_train_tune pid=5176)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5176)\u001b[0m 2.7 M     Trainable params\n","\u001b[36m(_train_tune pid=5176)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=5176)\u001b[0m 2.7 M     Total params\n","\u001b[36m(_train_tune pid=5176)\u001b[0m 10.840    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=5176)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=5176)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=5176)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=291.0]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.680]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.460]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.370]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.260]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.190]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5176)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 186.80it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.150, valid_loss=1.400]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.120, valid_loss=1.400]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.110, valid_loss=1.400]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=1.150, valid_loss=1.400]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=1.070, valid_loss=1.400]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.100, valid_loss=1.400]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.160, valid_loss=1.400]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=1.080, valid_loss=1.400]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5176)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 139.44it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.080, valid_loss=1.330]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.070, valid_loss=1.330]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.070, valid_loss=1.330]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=1.060, valid_loss=1.330]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.070, valid_loss=1.330]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.090, valid_loss=1.330]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=1.090, valid_loss=1.330]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=1.050, valid_loss=1.330]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5176)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 131.97it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.050, valid_loss=1.390]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.734, train_loss_epoch=1.040, valid_loss=1.390]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.100, valid_loss=1.390]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=1.090, valid_loss=1.390]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=1.080, valid_loss=1.390]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=1.070, valid_loss=1.390]        \n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=1.070, valid_loss=1.390]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=1.080, valid_loss=1.390]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=1.060, valid_loss=1.390]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:09:32,487\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=5176)\u001b[0m \n","\u001b[36m(_train_tune pid=5176)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5176)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5176)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5176)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 194.06it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5176)\u001b[0m \n","\u001b[36m(_train_tune pid=5176)\u001b[0m \r                                                                       \u001b[A\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.060, valid_loss=1.350]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.070, valid_loss=1.350]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.070, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=5311)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=5311)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=5311)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=5311)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=5311)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=5311)\u001b[0m 2025-06-14 19:09:42.157768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=5311)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=5311)\u001b[0m E0000 00:00:1749928182.198492    5389 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=5311)\u001b[0m E0000 00:00:1749928182.211141    5389 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=5311)\u001b[0m 2025-06-14 19:09:42.260903: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=5311)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=5311)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=5311)\u001b[0m \n","\u001b[36m(_train_tune pid=5311)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=5311)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5311)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=5311)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=5311)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=5311)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=5311)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5311)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=5311)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=5311)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=5311)\u001b[0m 10.262    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=5311)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=5311)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.900]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.520]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.310]\n","Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 52.78it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.310]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.160]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.130]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.090]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=1.070]\n","\u001b[36m(_train_tune pid=5311)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 146.35it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=1.090, valid_loss=1.380]\n","Epoch 8: 100%|██████████| 7/7 [00:00<00:00, 54.34it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=1.090, valid_loss=1.380]\n","Epoch 8: 100%|██████████| 7/7 [00:00<00:00, 52.10it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=1.070, valid_loss=1.380]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=1.050, valid_loss=1.380]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.080, valid_loss=1.380]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.060, valid_loss=1.380]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.060, valid_loss=1.380]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.050, valid_loss=1.380]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5311)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 184.85it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.080, valid_loss=1.370]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=1.020, valid_loss=1.370]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.030, valid_loss=1.370]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=1.050, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=5311)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.48it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.820, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 26: 100%|██████████| 7/7 [00:00<00:00, 55.15it/s, v_num=0, train_loss_step=0.820, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=1.030, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=5311)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 199.20it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.030, valid_loss=1.370]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=1.010, valid_loss=1.370]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=1.040, valid_loss=1.370]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.060, valid_loss=1.370]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:09:51,430\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=5311)\u001b[0m \rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 55.58it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.060, valid_loss=1.370]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 53.60it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.060, valid_loss=1.370]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 53.39it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.080, valid_loss=1.370]\rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.080, valid_loss=1.370]        \rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.080, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=5311)\u001b[0m \n","\u001b[36m(_train_tune pid=5311)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5311)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5311)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.20it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=1.060, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=5440)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=5440)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=5440)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=5440)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=5440)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=5440)\u001b[0m 2025-06-14 19:10:02.105946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=5440)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=5440)\u001b[0m E0000 00:00:1749928202.129137    5524 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=5440)\u001b[0m E0000 00:00:1749928202.136544    5524 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=5440)\u001b[0m 2025-06-14 19:10:02.160754: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=5440)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=5440)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=5440)\u001b[0m \n","\u001b[36m(_train_tune pid=5440)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=5440)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5440)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=5440)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=5440)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=5440)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=5440)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5440)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=5440)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=5440)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=5440)\u001b[0m 10.297    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=5440)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=5440)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=5440)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=5.490]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=2.020]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.530]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.390]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.250]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.130]\n","Epoch 6: 100%|██████████| 7/7 [00:00<00:00, 53.12it/s, v_num=0, train_loss_step=0.772, train_loss_epoch=1.130]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.772, train_loss_epoch=1.090]\n","\u001b[36m(_train_tune pid=5440)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 204.70it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.090, valid_loss=1.360]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.100, valid_loss=1.360]\n","Epoch 8: 100%|██████████| 7/7 [00:00<00:00, 54.67it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.100, valid_loss=1.360]\n","Epoch 8: 100%|██████████| 7/7 [00:00<00:00, 53.33it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.100, valid_loss=1.360]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.120, valid_loss=1.360]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=1.110, valid_loss=1.360]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.150, valid_loss=1.360]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.100, valid_loss=1.360]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.110, valid_loss=1.360]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.100, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5440)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 192.38it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.100, valid_loss=1.360]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.090, valid_loss=1.360]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.050, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:10:08,515\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=5440)\u001b[0m \rEpoch 20: 100%|██████████| 7/7 [00:00<00:00, 46.61it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.050, valid_loss=1.360]\rEpoch 20: 100%|██████████| 7/7 [00:00<00:00, 45.77it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=1.050, valid_loss=1.360]\rEpoch 20: 100%|██████████| 7/7 [00:00<00:00, 45.55it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=1.070, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=5440)\u001b[0m \rEpoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=1.070, valid_loss=1.360]        \rEpoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=1.070, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=5440)\u001b[0m \n","\u001b[36m(_train_tune pid=5440)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5440)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5440)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 134.00it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.050, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=5561)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=5561)\u001b[0m Seed set to 3\n","\u001b[36m(_train_tune pid=5561)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=5561)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=5561)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=5561)\u001b[0m 2025-06-14 19:10:19.759537: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=5561)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=5561)\u001b[0m E0000 00:00:1749928219.785811    5643 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=5561)\u001b[0m E0000 00:00:1749928219.793131    5643 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=5561)\u001b[0m 2025-06-14 19:10:19.817697: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=5561)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=5561)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","\u001b[36m(_train_tune pid=5561)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=5561)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5561)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=5561)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=5561)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=5561)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=5561)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5561)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=5561)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=5561)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=5561)\u001b[0m 10.297    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=5561)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=5561)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=2.320]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.650]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.630]\n","Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 41.39it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.630]\n","Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 40.48it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.630]\n","Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 40.32it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.590]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.590]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.450]\n","Epoch 5: 100%|██████████| 7/7 [00:00<00:00, 45.44it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.450]\n","Epoch 5: 100%|██████████| 7/7 [00:00<00:00, 44.34it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.380]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.380]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.300]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 114.37it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.300, valid_loss=1.540]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=1.190, valid_loss=1.540]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.170, valid_loss=1.540]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.120, valid_loss=1.540]\n","Epoch 10: 100%|██████████| 7/7 [00:00<00:00, 52.54it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=1.100, valid_loss=1.540]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=1.100, valid_loss=1.540]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.090, valid_loss=1.540]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=1.070, valid_loss=1.540]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.050, valid_loss=1.540]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.27it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=1.050, valid_loss=1.390]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.090, valid_loss=1.390]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.070, valid_loss=1.390]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.060, valid_loss=1.390]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.070, valid_loss=1.390]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.060, valid_loss=1.390]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.060, valid_loss=1.390]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.080, valid_loss=1.390]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 126.98it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.816, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.020, valid_loss=1.360]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.040, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 199.82it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.080, valid_loss=1.350]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.070, valid_loss=1.350]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=1.030, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.39it/s]\u001b[A\n","Epoch 35: 100%|██████████| 7/7 [00:00<00:00, 40.01it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.030, valid_loss=1.350]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.070, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 196.99it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 44: 100%|██████████| 7/7 [00:00<00:00, 55.28it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=1.020, valid_loss=1.360]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.865, train_loss_epoch=1.010, valid_loss=1.360]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 48.64it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=1.050, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 204.81it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 36.60it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.030, valid_loss=1.340]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.31it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.070, valid_loss=1.340]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=1.030, valid_loss=1.340]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.07it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=1.020, valid_loss=1.340]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.060, valid_loss=1.340]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=1.060, valid_loss=1.340]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.010, valid_loss=1.340]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.28it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.050, valid_loss=1.340]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 204.70it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=1.000, valid_loss=1.340]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=1.020, valid_loss=1.340]\n","Epoch 82:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.060, valid_loss=1.340]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=1.060, valid_loss=1.340]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=1.030, valid_loss=1.340]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 169.20it/s]\u001b[A\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 87: 100%|██████████| 7/7 [00:00<00:00, 49.95it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 87: 100%|██████████| 7/7 [00:00<00:00, 49.23it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.020, valid_loss=1.340]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.020, valid_loss=1.340]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.070, valid_loss=1.340]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=1.030, valid_loss=1.340]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 121.31it/s]\u001b[A\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 93:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 94:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 95:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 96:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=1.020, valid_loss=1.340]\n","Epoch 97:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.891, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 98:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.060, valid_loss=1.340]\n","Epoch 99:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 99: 100%|██████████| 7/7 [00:00<00:00, 54.38it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.050, valid_loss=1.340]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.32it/s]\u001b[A\n","Epoch 100:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 101:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 102:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 103:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 104:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=1.000, valid_loss=1.340]\n","Epoch 105:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.987, valid_loss=1.340]\n","Epoch 106:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 106: 100%|██████████| 7/7 [00:00<00:00, 54.00it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=1.030, valid_loss=1.340]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 206.87it/s]\u001b[A\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 108:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.020, valid_loss=1.340]\n","Epoch 109:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.020, valid_loss=1.340]\n","Epoch 110:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.080, valid_loss=1.340]\n","Epoch 111:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 112:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=1.050, valid_loss=1.340]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:10:40,370\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=5561)\u001b[0m \rEpoch 112: 100%|██████████| 7/7 [00:00<00:00, 53.75it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=1.050, valid_loss=1.340]\rEpoch 112: 100%|██████████| 7/7 [00:00<00:00, 51.84it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.050, valid_loss=1.340]\rEpoch 112: 100%|██████████| 7/7 [00:00<00:00, 51.64it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.040, valid_loss=1.340]\rEpoch 112:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.040, valid_loss=1.340]        \rEpoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.040, valid_loss=1.340]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \rEpoch 113: 100%|██████████| 7/7 [00:00<00:00, 54.52it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.040, valid_loss=1.340]\rEpoch 113: 100%|██████████| 7/7 [00:00<00:00, 52.52it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=1.040, valid_loss=1.340]\rEpoch 113: 100%|██████████| 7/7 [00:00<00:00, 52.32it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=1.020, valid_loss=1.340]\rEpoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=1.020, valid_loss=1.340]        \rEpoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=1.020, valid_loss=1.340]\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5561)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 194.81it/s]\u001b[A\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=0.981, valid_loss=1.340]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=5749)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=5749)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=5749)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=5749)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=5749)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=5749)\u001b[0m 2025-06-14 19:10:51.850279: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=5749)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=5749)\u001b[0m E0000 00:00:1749928251.873361    5831 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=5749)\u001b[0m E0000 00:00:1749928251.880722    5831 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=5749)\u001b[0m 2025-06-14 19:10:51.904389: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=5749)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=5749)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \n","\u001b[36m(_train_tune pid=5749)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=5749)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5749)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=5749)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=5749)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=5749)\u001b[0m 3 | blocks       | ModuleList    | 2.7 M  | train\n","\u001b[36m(_train_tune pid=5749)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5749)\u001b[0m 2.7 M     Trainable params\n","\u001b[36m(_train_tune pid=5749)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=5749)\u001b[0m 2.7 M     Total params\n","\u001b[36m(_train_tune pid=5749)\u001b[0m 10.840    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=5749)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=5749)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.940, train_loss_epoch=2.670]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.370]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.930]\n","Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 49.14it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=1.680]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=1.680]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.650]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.590]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.530]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 174.49it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.530, valid_loss=1.940]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.500, valid_loss=1.940]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.440, valid_loss=1.940]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.430, valid_loss=1.940]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.290, valid_loss=1.940]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.260, valid_loss=1.940]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.250, valid_loss=1.940]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=1.160, valid_loss=1.940]\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 203.91it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.160, valid_loss=1.480]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.140, valid_loss=1.480]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.130, valid_loss=1.480]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=1.120, valid_loss=1.480]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.120, valid_loss=1.480]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.130, valid_loss=1.480]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=1.120, valid_loss=1.480]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=1.070, valid_loss=1.480]\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.79it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.070, valid_loss=1.390]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=1.060, valid_loss=1.390]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.120, valid_loss=1.390]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=1.100, valid_loss=1.390]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=1.100, valid_loss=1.390]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=1.080, valid_loss=1.390]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=1.090, valid_loss=1.390]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=1.070, valid_loss=1.390]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 189.99it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.070, valid_loss=1.370]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=1.080, valid_loss=1.370]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.060, valid_loss=1.370]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=1.050, valid_loss=1.370]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.83it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.060, valid_loss=1.360]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.080, valid_loss=1.360]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 41: 100%|██████████| 7/7 [00:00<00:00, 39.87it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 41: 100%|██████████| 7/7 [00:00<00:00, 39.15it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.050, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 147.36it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.843, train_loss_epoch=1.010, valid_loss=1.360]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=1.040, valid_loss=1.360]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.050, valid_loss=1.360]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 47: 100%|██████████| 7/7 [00:00<00:00, 42.53it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=1.030, valid_loss=1.360]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.070, valid_loss=1.360]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 41.40it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=1.070, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 154.71it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.050, valid_loss=1.350]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=1.060, valid_loss=1.350]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.763, train_loss_epoch=1.020, valid_loss=1.350]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.080, valid_loss=1.350]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.040, valid_loss=1.350]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.080, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 144.63it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=1.080, valid_loss=1.340]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=1.020, valid_loss=1.340]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.060, valid_loss=1.340]\n","Epoch 63: 100%|██████████| 7/7 [00:00<00:00, 48.23it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=1.080, valid_loss=1.340]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=1.080, valid_loss=1.340]\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.63it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.080, valid_loss=1.340]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.060, valid_loss=1.340]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.070, valid_loss=1.340]\n","Epoch 67: 100%|██████████| 7/7 [00:00<00:00, 48.42it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.050, valid_loss=1.340]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.070, valid_loss=1.340]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=1.040, valid_loss=1.340]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 191.32it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.060, valid_loss=1.340]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.060, valid_loss=1.340]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.030, valid_loss=1.340]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.060, valid_loss=1.340]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.040, valid_loss=1.340]\n","Epoch 76: 100%|██████████| 7/7 [00:00<00:00, 48.39it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=1.010, valid_loss=1.340]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=1.010, valid_loss=1.340]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:11:07,752\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=5749)\u001b[0m \rEpoch 77: 100%|██████████| 7/7 [00:00<00:00, 49.45it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=1.010, valid_loss=1.340]\rEpoch 77: 100%|██████████| 7/7 [00:00<00:00, 47.95it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.010, valid_loss=1.340]\rEpoch 77: 100%|██████████| 7/7 [00:00<00:00, 47.79it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.340]\rEpoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.340]        \rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.340]\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \n","\u001b[36m(_train_tune pid=5749)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.97it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5749)\u001b[0m \r                                                                       \u001b[A\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=1.040, valid_loss=1.340]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=1.040, valid_loss=1.340]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=1.040, valid_loss=1.340]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=5913)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=5913)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=5913)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=5913)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=5913)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=5913)\u001b[0m 2025-06-14 19:11:19.030147: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=5913)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=5913)\u001b[0m E0000 00:00:1749928279.053415    5995 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=5913)\u001b[0m E0000 00:00:1749928279.060595    5995 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=5913)\u001b[0m 2025-06-14 19:11:19.084517: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=5913)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=5913)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","\u001b[36m(_train_tune pid=5913)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=5913)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5913)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=5913)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=5913)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=5913)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=5913)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=5913)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=5913)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=5913)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=5913)\u001b[0m 10.252    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=5913)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=5913)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.7e+7, train_loss_epoch=1.01e+11]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+4, train_loss_epoch=1.31e+4]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.75e+4, train_loss_epoch=4.73e+4]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.54e+6, train_loss_epoch=5.48e+8]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.43e+4, train_loss_epoch=7.16e+4]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.01e+3, train_loss_epoch=5.52e+3]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.53e+3, train_loss_epoch=3.59e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 189.95it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=3.59e+3, valid_loss=1.37e+3]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=838.0, train_loss_epoch=1.35e+3, valid_loss=1.37e+3]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+3, train_loss_epoch=994.0, valid_loss=1.37e+3]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+3, train_loss_epoch=1.27e+3, valid_loss=1.37e+3]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+3, train_loss_epoch=1.21e+3, valid_loss=1.37e+3]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=980.0, train_loss_epoch=870.0, valid_loss=1.37e+3]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=426.0, train_loss_epoch=611.0, valid_loss=1.37e+3]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=232.0, train_loss_epoch=312.0, valid_loss=1.37e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.58it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=388.0, train_loss_epoch=312.0, valid_loss=160.0]  \n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=268.0, train_loss_epoch=248.0, valid_loss=160.0]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=166.0, train_loss_epoch=187.0, valid_loss=160.0]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=151.0, train_loss_epoch=150.0, valid_loss=160.0]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=120.0, train_loss_epoch=108.0, valid_loss=160.0]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=90.80, train_loss_epoch=117.0, valid_loss=160.0]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=93.70, train_loss_epoch=85.90, valid_loss=160.0]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=164.0, train_loss_epoch=91.50, valid_loss=160.0]\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.05it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=191.0, train_loss_epoch=91.50, valid_loss=138.0]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=153.0, train_loss_epoch=174.0, valid_loss=138.0]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=189.0, train_loss_epoch=167.0, valid_loss=138.0]\n","Epoch 23: 100%|██████████| 7/7 [00:00<00:00, 51.69it/s, v_num=0, train_loss_step=189.0, train_loss_epoch=167.0, valid_loss=138.0]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=120.0, train_loss_epoch=155.0, valid_loss=138.0]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=89.90, train_loss_epoch=116.0, valid_loss=138.0]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=93.80, train_loss_epoch=89.50, valid_loss=138.0]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=69.40, train_loss_epoch=88.50, valid_loss=138.0]\n","Epoch 27: 100%|██████████| 7/7 [00:00<00:00, 54.10it/s, v_num=0, train_loss_step=69.40, train_loss_epoch=88.50, valid_loss=138.0]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=56.40, train_loss_epoch=64.40, valid_loss=138.0]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 178.07it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=46.30, train_loss_epoch=64.90, valid_loss=60.30]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=36.20, valid_loss=60.30]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=37.50, valid_loss=60.30]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=27.40, train_loss_epoch=31.50, valid_loss=60.30]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=41.00, train_loss_epoch=38.50, valid_loss=60.30]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=31.70, train_loss_epoch=33.00, valid_loss=60.30]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=32.80, train_loss_epoch=28.60, valid_loss=60.30]\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.15it/s]\u001b[A\n","                                                                       \u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=25.20, train_loss_epoch=28.60, valid_loss=21.90]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=19.40, train_loss_epoch=25.70, valid_loss=21.90]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=46.40, train_loss_epoch=29.60, valid_loss=21.90]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=29.90, valid_loss=21.90]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=21.50, train_loss_epoch=20.40, valid_loss=21.90]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=22.50, train_loss_epoch=21.70, valid_loss=21.90]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=17.60, valid_loss=21.90]\n","Epoch 41: 100%|██████████| 7/7 [00:00<00:00, 50.49it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=17.60, valid_loss=21.90]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=23.50, valid_loss=21.90]\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 154.74it/s]\u001b[A\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=16.00, train_loss_epoch=23.50, valid_loss=15.60]\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=15.90, valid_loss=15.60]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=14.70, valid_loss=15.60]\n","Epoch 44: 100%|██████████| 7/7 [00:00<00:00, 48.59it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=14.70, valid_loss=15.60]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=13.10, valid_loss=15.60]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=18.20, train_loss_epoch=18.00, valid_loss=15.60]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=17.70, valid_loss=15.60]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.30, valid_loss=15.60]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=14.50, valid_loss=15.60]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 43.94it/s, v_num=0, train_loss_step=9.070, train_loss_epoch=14.50, valid_loss=15.60]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 154.01it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.070, train_loss_epoch=12.60, valid_loss=11.90]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.30, valid_loss=11.90]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.290, train_loss_epoch=9.640, valid_loss=11.90]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.870, train_loss_epoch=9.250, valid_loss=11.90]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.960, train_loss_epoch=9.190, valid_loss=11.90]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=10.30, valid_loss=11.90]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.140, train_loss_epoch=8.670, valid_loss=11.90]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=7.570, valid_loss=11.90]\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.07it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.150, train_loss_epoch=7.570, valid_loss=6.180]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.490, train_loss_epoch=6.820, valid_loss=6.180]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.280, train_loss_epoch=7.110, valid_loss=6.180]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.200, train_loss_epoch=7.440, valid_loss=6.180]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.950, train_loss_epoch=6.720, valid_loss=6.180]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.150, train_loss_epoch=8.570, valid_loss=6.180]\n","Epoch 62: 100%|██████████| 7/7 [00:00<00:00, 53.47it/s, v_num=0, train_loss_step=9.150, train_loss_epoch=8.570, valid_loss=6.180]\n","Epoch 62: 100%|██████████| 7/7 [00:00<00:00, 51.22it/s, v_num=0, train_loss_step=8.790, train_loss_epoch=9.510, valid_loss=6.180]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.790, train_loss_epoch=9.510, valid_loss=6.180]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=9.640, valid_loss=6.180]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 139.67it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.070, train_loss_epoch=9.640, valid_loss=6.010]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.100, train_loss_epoch=8.980, valid_loss=6.010]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.620, train_loss_epoch=9.920, valid_loss=6.010]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.670, train_loss_epoch=7.480, valid_loss=6.010]\n","Epoch 67: 100%|██████████| 7/7 [00:00<00:00, 54.27it/s, v_num=0, train_loss_step=8.670, train_loss_epoch=7.480, valid_loss=6.010]\n","Epoch 67: 100%|██████████| 7/7 [00:00<00:00, 52.00it/s, v_num=0, train_loss_step=5.760, train_loss_epoch=6.830, valid_loss=6.010]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.760, train_loss_epoch=6.830, valid_loss=6.010]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=8.170, valid_loss=6.010]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=9.490, valid_loss=6.010]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.730, train_loss_epoch=11.80, valid_loss=6.010]\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 144.26it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.680, train_loss_epoch=11.80, valid_loss=6.890]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.920, train_loss_epoch=9.100, valid_loss=6.890]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=9.820, valid_loss=6.890]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.120, train_loss_epoch=7.000, valid_loss=6.890]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.010, train_loss_epoch=6.110, valid_loss=6.890]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.700, train_loss_epoch=5.700, valid_loss=6.890]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.710, train_loss_epoch=5.380, valid_loss=6.890]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.940, train_loss_epoch=6.120, valid_loss=6.890]\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 170.39it/s]\u001b[A\n","Epoch 78: 100%|██████████| 7/7 [00:00<00:00, 37.94it/s, v_num=0, train_loss_step=4.460, train_loss_epoch=6.120, valid_loss=5.530]\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.710, train_loss_epoch=5.970, valid_loss=5.530]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.310, train_loss_epoch=5.960, valid_loss=5.530]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.980, train_loss_epoch=5.730, valid_loss=5.530]\n","Epoch 82:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.190, train_loss_epoch=5.470, valid_loss=5.530]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.300, train_loss_epoch=6.930, valid_loss=5.530]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.840, train_loss_epoch=7.210, valid_loss=5.530]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.720, train_loss_epoch=6.070, valid_loss=5.530]\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 206.41it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=5.630, valid_loss=4.890]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.640, train_loss_epoch=7.280, valid_loss=4.890]\n","Epoch 87: 100%|██████████| 7/7 [00:00<00:00, 55.45it/s, v_num=0, train_loss_step=6.640, train_loss_epoch=7.280, valid_loss=4.890]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.050, train_loss_epoch=5.630, valid_loss=4.890]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.160, train_loss_epoch=5.200, valid_loss=4.890]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.730, train_loss_epoch=4.290, valid_loss=4.890]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.610, train_loss_epoch=5.060, valid_loss=4.890]\n","Epoch 91: 100%|██████████| 7/7 [00:00<00:00, 54.81it/s, v_num=0, train_loss_step=4.610, train_loss_epoch=5.060, valid_loss=4.890]\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.790, train_loss_epoch=5.850, valid_loss=4.890]\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 204.65it/s]\u001b[A\n","Epoch 93:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.090, train_loss_epoch=6.500, valid_loss=5.310]\n","Epoch 94:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.910, train_loss_epoch=5.210, valid_loss=5.310]\n","Epoch 95:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.650, train_loss_epoch=4.200, valid_loss=5.310]\n","Epoch 96:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=4.960, valid_loss=5.310]\n","Epoch 97:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=3.830, valid_loss=5.310]\n","Epoch 98:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.790, train_loss_epoch=3.820, valid_loss=5.310]\n","Epoch 99:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.200, valid_loss=5.310]\n","Epoch 99: 100%|██████████| 7/7 [00:00<00:00, 53.77it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=3.200, valid_loss=5.310]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 174.33it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Epoch 100:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=3.120, valid_loss=2.810]\n","Epoch 101:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.950, valid_loss=2.810]\n","Epoch 102:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.890, valid_loss=2.810]\n","Epoch 103:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.850, valid_loss=2.810]\n","Epoch 104:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.780, valid_loss=2.810]\n","Epoch 105:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.800, valid_loss=2.810]\n","Epoch 106:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.840, valid_loss=2.810]\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=2.790, valid_loss=2.810]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.80it/s]\u001b[A\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=2.790, valid_loss=2.700]\n","Epoch 108:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=2.820, valid_loss=2.700]\n","Epoch 109:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.730, valid_loss=2.700]\n","Epoch 110:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.680, valid_loss=2.700]\n","Epoch 111:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.630, valid_loss=2.700]\n","Epoch 112:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.620, valid_loss=2.700]\n","Epoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.590, valid_loss=2.700]\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.480, valid_loss=2.700]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 204.35it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Epoch 115:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.590, valid_loss=2.550]\n","Epoch 116:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.450, valid_loss=2.550]\n","Epoch 117:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.410, valid_loss=2.550]\n","Epoch 118:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.540, valid_loss=2.550]\n","Epoch 119:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.540, valid_loss=2.550]\n","Epoch 120:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.700, valid_loss=2.550]\n","Epoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.820, valid_loss=2.550]\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.13it/s]\u001b[A\n","Epoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.820, valid_loss=2.660]\n","Epoch 122:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.540, valid_loss=2.660]\n","Epoch 123:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.620, valid_loss=2.660]\n","Epoch 124:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.260, train_loss_epoch=2.810, valid_loss=2.660]\n","Epoch 125:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.580, train_loss_epoch=4.210, valid_loss=2.660]\n","Epoch 126:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.500, train_loss_epoch=4.210, valid_loss=2.660]\n","Epoch 127:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.060, train_loss_epoch=5.380, valid_loss=2.660]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:11:41,068\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n","2025-06-14 19:11:41,108\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/_train_tune_2025-06-14_19-03-27' in 0.0328s.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=5913)\u001b[0m \rEpoch 127: 100%|██████████| 7/7 [00:00<00:00, 45.75it/s, v_num=0, train_loss_step=6.060, train_loss_epoch=5.380, valid_loss=2.660]\rEpoch 127: 100%|██████████| 7/7 [00:00<00:00, 44.75it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=5.380, valid_loss=2.660]\rEpoch 127: 100%|██████████| 7/7 [00:00<00:00, 44.56it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.760, valid_loss=2.660]\rEpoch 127:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.760, valid_loss=2.660]        \rEpoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.760, valid_loss=2.660]\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \n","\u001b[36m(_train_tune pid=5913)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 145.23it/s]\u001b[A\n","\u001b[36m(_train_tune pid=5913)\u001b[0m \r                                                                       \u001b[A\rEpoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.760, valid_loss=3.260]\rEpoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=2.890, valid_loss=3.260]\rEpoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=2.890, valid_loss=3.260]\n","\n"]},{"output_type":"stream","name":"stderr","text":["INFO:lightning_fabric.utilities.seed:Seed set to 9\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name         | Type          | Params | Mode \n","-------------------------------------------------------\n","0 | loss         | MQLoss        | 5      | eval \n","1 | padder_train | ConstantPad1d | 0      | train\n","2 | scaler       | TemporalNorm  | 0      | train\n","3 | blocks       | ModuleList    | 2.6 M  | train\n","-------------------------------------------------------\n","2.6 M     Trainable params\n","5         Non-trainable params\n","2.6 M     Total params\n","10.252    Total estimated model params size (MB)\n","33        Modules in train mode\n","1         Modules in eval mode\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b4ccd3092164890aca06e0bdc4b8da8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b0e5ceb6e3b4be586e781baa31ea25b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82fe3f59990b48e2bdacb3f2b74ed6d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ae2c87f2e39452085f7b8550d0507be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28d63001996b4cec82ffcadb2e6e7599"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"186dbd8b81ee4be2b8db892502ae2db9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61e177c2c79245a8b7724da265589845"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c6a24ac73be47a480e84e82a8073a79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c692353c7b2d4728ae1a572ecefbfe7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d74790f1150415ba4bc0fcb37391245"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d5e85bd67114980b9f020611f22ef8d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------------------------+\n","| Configuration for experiment     _train_tune_2025-06-14_19-11-57   |\n","+--------------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator                   |\n","| Scheduler                        FIFOScheduler                     |\n","| Number of trials                 20                                |\n","+--------------------------------------------------------------------+\n","\n","View detailed results here: /root/ray_results/_train_tune_2025-06-14_19-11-57\n","To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-14_19-03-27_020465_1199/artifacts/2025-06-14_19-11-57/_train_tune_2025-06-14_19-11-57/driver_artifacts`\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=6178)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=6178)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=6178)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=6178)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=6178)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 2025-06-14 19:12:06.929640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=6178)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=6178)\u001b[0m E0000 00:00:1749928326.954050    6256 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=6178)\u001b[0m E0000 00:00:1749928326.962828    6256 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 2025-06-14 19:12:06.988712: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=6178)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=6178)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=6178)\u001b[0m \n","\u001b[36m(_train_tune pid=6178)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=6178)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=6178)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=6178)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.290]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.440]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.770]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.600]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.470]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.420]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.480]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 173.88it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6178)\u001b[0m \n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.500, valid_loss=1.390]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.490, valid_loss=1.390]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.480, valid_loss=1.390]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.410, valid_loss=1.390]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.440, valid_loss=1.390]\n","Epoch 13: 100%|██████████| 7/7 [00:00<00:00, 82.51it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.390, valid_loss=1.390]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.390, valid_loss=1.390]\n","\u001b[36m(_train_tune pid=6178)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 219.29it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.390, valid_loss=1.360]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.450, valid_loss=1.360]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.430, valid_loss=1.360]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.510, valid_loss=1.360]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.550, valid_loss=1.360]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.600, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6178)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 174.73it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.460, valid_loss=1.360]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.570, valid_loss=1.360]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.500, valid_loss=1.360]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.480, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:12:14,088\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=6178)\u001b[0m \rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 82.58it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.480, valid_loss=1.360]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 81.70it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.480, valid_loss=1.360]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 81.16it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.420, valid_loss=1.360]\rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.420, valid_loss=1.360]        \rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.420, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=6178)\u001b[0m \n","\u001b[36m(_train_tune pid=6178)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6178)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6178)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6178)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 225.00it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6178)\u001b[0m \r                                                                       \u001b[A\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.420, valid_loss=1.390]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.510, valid_loss=1.390]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.510, valid_loss=1.390]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=6295)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=6295)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=6295)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=6295)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=6295)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 2025-06-14 19:12:23.646206: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=6295)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=6295)\u001b[0m E0000 00:00:1749928343.689674    6371 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=6295)\u001b[0m E0000 00:00:1749928343.701244    6371 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 2025-06-14 19:12:23.748018: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=6295)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=6295)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=6295)\u001b[0m \n","\u001b[36m(_train_tune pid=6295)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=6295)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=6295)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=6295)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.240]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.880]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.530]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.570]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.470]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.470]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 215.31it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.470, valid_loss=1.370]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.490, valid_loss=1.370]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.490, valid_loss=1.370]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.480, valid_loss=1.370]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=1.370]\n","Epoch 11: 100%|██████████| 7/7 [00:00<00:00, 80.63it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.420, valid_loss=1.370]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.420, valid_loss=1.370]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.530, valid_loss=1.370]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.380, valid_loss=1.370]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6295)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 178.54it/s]\u001b[A\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.430, valid_loss=1.360]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.540, valid_loss=1.360]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.380, valid_loss=1.360]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.570, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=6295)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 226.89it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.570, valid_loss=1.370]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.390, valid_loss=1.370]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.540, valid_loss=1.370]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.470, valid_loss=1.370]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.490, valid_loss=1.370]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:12:30,209\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=6295)\u001b[0m \rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 84.20it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.490, valid_loss=1.370]\rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 83.36it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.490, valid_loss=1.370]\rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 82.90it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.470, valid_loss=1.370]\rEpoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.470, valid_loss=1.370]        \rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.470, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=6295)\u001b[0m \rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 80.74it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.470, valid_loss=1.370]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 79.91it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.470, valid_loss=1.370]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 79.42it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.390, valid_loss=1.370]\rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.390, valid_loss=1.370]        \rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.390, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=6295)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6295)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6295)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6295)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 213.18it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6295)\u001b[0m \n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.480, valid_loss=1.370]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=6416)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=6416)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=6416)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=6416)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=6416)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 2025-06-14 19:12:41.641717: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=6416)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=6416)\u001b[0m E0000 00:00:1749928361.667764    6498 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=6416)\u001b[0m E0000 00:00:1749928361.675280    6498 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 2025-06-14 19:12:41.699650: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=6416)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=6416)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=6416)\u001b[0m \n","\u001b[36m(_train_tune pid=6416)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=6416)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=6416)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=6416)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.340]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.210]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.710]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.510]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.540]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.470]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6416)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 183.37it/s]\u001b[A\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.500, valid_loss=1.360]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.470, valid_loss=1.360]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.550, valid_loss=1.360]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.510, valid_loss=1.360]\n","Epoch 12: 100%|██████████| 7/7 [00:00<00:00, 75.41it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.620, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=6416)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 228.03it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.620, valid_loss=1.350]\n","Epoch 14: 100%|██████████| 7/7 [00:00<00:00, 53.62it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.620, valid_loss=1.350]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.590, valid_loss=1.350]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.600, valid_loss=1.350]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.530, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=6416)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 231.54it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.530, valid_loss=1.350]\n","Epoch 22: 100%|██████████| 7/7 [00:00<00:00, 80.82it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.450, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.450, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.690, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.700, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.450, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6416)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 203.32it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.410, valid_loss=1.350]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.400, valid_loss=1.350]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.490, valid_loss=1.350]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.400, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:12:48,367\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=6416)\u001b[0m \n","\u001b[36m(_train_tune pid=6416)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6416)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6416)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6416)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 137.81it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6416)\u001b[0m \r                                                                       \u001b[A\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.400, valid_loss=1.360]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.430, valid_loss=1.360]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.430, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=6541)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=6541)\u001b[0m Seed set to 1\n","\u001b[36m(_train_tune pid=6541)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=6541)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=6541)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 2025-06-14 19:12:59.719589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=6541)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=6541)\u001b[0m E0000 00:00:1749928379.742731    6624 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=6541)\u001b[0m E0000 00:00:1749928379.749666    6624 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 2025-06-14 19:12:59.775747: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=6541)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=6541)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \n","\u001b[36m(_train_tune pid=6541)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=6541)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=6541)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=6541)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.400]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.230]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.310]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.360]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=2.170]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.690]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.450]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 147.61it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.450, valid_loss=1.380]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.570, valid_loss=1.380]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.460, valid_loss=1.380]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.430, valid_loss=1.380]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.520, valid_loss=1.380]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.430, valid_loss=1.380]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.450, valid_loss=1.380]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.390, valid_loss=1.380]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 223.25it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.390, valid_loss=1.370]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.470, valid_loss=1.370]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.460, valid_loss=1.370]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.470, valid_loss=1.370]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.500, valid_loss=1.370]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.410, valid_loss=1.370]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.530, valid_loss=1.370]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 179.77it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.570, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.500, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.410, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 213.64it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.510, valid_loss=1.360]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.450, valid_loss=1.360]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.370, valid_loss=1.360]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.590, valid_loss=1.360]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.420, valid_loss=1.360]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.410, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 235.25it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.420, valid_loss=1.350]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.400, valid_loss=1.350]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.460, valid_loss=1.350]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=1.490, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 230.39it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=1.350]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.450, valid_loss=1.350]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.640, valid_loss=1.350]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.420, valid_loss=1.350]\n","Epoch 48: 100%|██████████| 7/7 [00:00<00:00, 82.62it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 82.43it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.510, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 216.29it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.450, valid_loss=1.350]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.550, valid_loss=1.350]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.500, valid_loss=1.350]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=1.350]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.400, valid_loss=1.350]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.530, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 228.69it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.530, valid_loss=1.350]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.580, valid_loss=1.350]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.450, valid_loss=1.350]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.440, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.37it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.530, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:13:10,701\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=6541)\u001b[0m \rEpoch 69: 100%|██████████| 7/7 [00:00<00:00, 76.39it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.530, valid_loss=1.350]\rEpoch 69: 100%|██████████| 7/7 [00:00<00:00, 75.86it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.530, valid_loss=1.350]\rEpoch 69: 100%|██████████| 7/7 [00:00<00:00, 75.41it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.420, valid_loss=1.350]\rEpoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.420, valid_loss=1.350]        \rEpoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.420, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \rEpoch 70: 100%|██████████| 7/7 [00:00<00:00, 77.64it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.420, valid_loss=1.350]\rEpoch 70: 100%|██████████| 7/7 [00:00<00:00, 77.34it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.420, valid_loss=1.350]\rEpoch 70: 100%|██████████| 7/7 [00:00<00:00, 76.81it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.470, valid_loss=1.350]\rEpoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.470, valid_loss=1.350]        \rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.470, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 221.02it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6541)\u001b[0m \r                                                                       \u001b[A\rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.470, valid_loss=1.360]\rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.390, valid_loss=1.360]\rEpoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.390, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=6683)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=6683)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=6683)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=6683)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=6683)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 2025-06-14 19:13:21.020237: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=6683)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=6683)\u001b[0m E0000 00:00:1749928401.043716    6761 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=6683)\u001b[0m E0000 00:00:1749928401.050936    6761 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 2025-06-14 19:13:21.076502: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=6683)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=6683)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=6683)\u001b[0m \n","\u001b[36m(_train_tune pid=6683)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=6683)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=6683)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=6683)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.280]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.320]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.600]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.540]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.470]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.460]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 186.08it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6683)\u001b[0m \n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.470, valid_loss=1.360]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=1.360]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.530, valid_loss=1.360]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.390, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=6683)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6683)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6683)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 196.30it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.390, valid_loss=1.360]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.430, valid_loss=1.360]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.500, valid_loss=1.360]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.540, valid_loss=1.360]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.380, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:13:26,382\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=6683)\u001b[0m \rEpoch 19: 100%|██████████| 7/7 [00:00<00:00, 82.91it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.380, valid_loss=1.360]\rEpoch 19: 100%|██████████| 7/7 [00:00<00:00, 81.98it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.380, valid_loss=1.360]\rEpoch 19: 100%|██████████| 7/7 [00:00<00:00, 81.52it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.380, valid_loss=1.360]\rEpoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.380, valid_loss=1.360]        \rEpoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.380, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=6683)\u001b[0m \rEpoch 20: 100%|██████████| 7/7 [00:00<00:00, 79.44it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.380, valid_loss=1.360]\rEpoch 20: 100%|██████████| 7/7 [00:00<00:00, 79.13it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.380, valid_loss=1.360]\rEpoch 20: 100%|██████████| 7/7 [00:00<00:00, 78.57it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.570, valid_loss=1.360]\rEpoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.570, valid_loss=1.360]        \rEpoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.570, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=6683)\u001b[0m \n","\u001b[36m(_train_tune pid=6683)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6683)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6683)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6683)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 224.05it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6683)\u001b[0m \r                                                                       \u001b[A\rEpoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.570, valid_loss=1.360]\rEpoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.370, valid_loss=1.360]\rEpoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.370, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=6797)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=6797)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=6797)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=6797)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=6797)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 2025-06-14 19:13:37.260945: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=6797)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=6797)\u001b[0m E0000 00:00:1749928417.287098    6880 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=6797)\u001b[0m E0000 00:00:1749928417.294279    6880 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 2025-06-14 19:13:37.318409: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=6797)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=6797)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=6797)\u001b[0m \n","\u001b[36m(_train_tune pid=6797)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=6797)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=6797)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=6797)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.340]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.210]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.690]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.490]\n","Epoch 5: 100%|██████████| 7/7 [00:00<00:00, 78.87it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.540]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.540]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.470]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6797)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 175.15it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.470, valid_loss=1.360]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.540, valid_loss=1.360]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.500, valid_loss=1.360]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.620, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=6797)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 169.01it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.620, valid_loss=1.350]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.600, valid_loss=1.350]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.610, valid_loss=1.350]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.520, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=6797)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 171.97it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.520, valid_loss=1.350]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.680, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.700, valid_loss=1.350]\n","Epoch 27: 100%|██████████| 7/7 [00:00<00:00, 53.05it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.700, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.450, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6797)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 131.02it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=1.350]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.400, valid_loss=1.350]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.490, valid_loss=1.350]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.400, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6797)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.54it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.380, valid_loss=1.360]\n","Epoch 38: 100%|██████████| 7/7 [00:00<00:00, 81.58it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.520, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:13:45,433\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=6797)\u001b[0m \rEpoch 40: 100%|██████████| 7/7 [00:00<00:00, 82.80it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.520, valid_loss=1.360]\rEpoch 40: 100%|██████████| 7/7 [00:00<00:00, 81.97it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.520, valid_loss=1.360]\rEpoch 40: 100%|██████████| 7/7 [00:00<00:00, 81.54it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.480, valid_loss=1.360]\rEpoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.480, valid_loss=1.360]        \rEpoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.480, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=6797)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 220.81it/s]\u001b[A\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.370, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=6927)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=6927)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=6927)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=6927)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=6927)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 2025-06-14 19:13:56.429873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=6927)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=6927)\u001b[0m E0000 00:00:1749928436.476462    7009 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=6927)\u001b[0m E0000 00:00:1749928436.486925    7009 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 2025-06-14 19:13:56.522324: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=6927)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=6927)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=6927)\u001b[0m \n","\u001b[36m(_train_tune pid=6927)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=6927)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=6927)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=6927)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.270]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.830]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.520]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.530]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.520]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.450]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.500]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.46it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.500, valid_loss=1.390]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.560, valid_loss=1.390]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.550, valid_loss=1.390]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.500, valid_loss=1.390]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.520, valid_loss=1.390]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.440, valid_loss=1.390]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.510, valid_loss=1.390]\n","\u001b[36m(_train_tune pid=6927)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 220.64it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.510, valid_loss=1.360]\n","Epoch 14: 100%|██████████| 7/7 [00:00<00:00, 52.09it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.510, valid_loss=1.360]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.570, valid_loss=1.360]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.460, valid_loss=1.360]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.510, valid_loss=1.360]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.440, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=6927)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 214.26it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.390, valid_loss=1.360]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.510, valid_loss=1.360]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.430, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:14:02,974\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=6927)\u001b[0m \rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 83.13it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.430, valid_loss=1.360]\rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 82.37it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.430, valid_loss=1.360]\rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 81.93it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.440, valid_loss=1.360]\rEpoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.440, valid_loss=1.360]        \rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.440, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=6927)\u001b[0m \rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 77.89it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.440, valid_loss=1.360]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 77.24it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.440, valid_loss=1.360]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 76.85it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.470, valid_loss=1.360]\rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.470, valid_loss=1.360]        \rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.470, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=6927)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6927)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=6927)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 208.12it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.460, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=7050)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=7050)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=7050)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=7050)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=7050)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 2025-06-14 19:14:13.163750: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=7050)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=7050)\u001b[0m E0000 00:00:1749928453.187208    7128 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=7050)\u001b[0m E0000 00:00:1749928453.194427    7128 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 2025-06-14 19:14:13.220708: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=7050)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=7050)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \n","\u001b[36m(_train_tune pid=7050)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=7050)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=7050)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=7050)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.360]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.720]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.450]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.500]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.440]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.470]\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 213.62it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.470, valid_loss=1.360]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=1.360]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.530, valid_loss=1.360]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.410, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 225.69it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.540, valid_loss=1.360]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.450, valid_loss=1.360]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=1.520, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 189.20it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.400, valid_loss=1.360]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.540, valid_loss=1.360]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.390, valid_loss=1.360]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.560, valid_loss=1.360]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.430, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 227.05it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.570, valid_loss=1.350]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.430, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 205.17it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.460, valid_loss=1.370]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.450, valid_loss=1.370]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.480, valid_loss=1.370]\n","Epoch 39: 100%|██████████| 7/7 [00:00<00:00, 81.26it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.390, valid_loss=1.370]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.390, valid_loss=1.370]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.420, valid_loss=1.370]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.480, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 218.82it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.410, valid_loss=1.350]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.560, valid_loss=1.350]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.370, valid_loss=1.350]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.390, valid_loss=1.350]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.380, valid_loss=1.350]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.390, valid_loss=1.350]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 67.10it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.390, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 155.84it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.350, valid_loss=1.350]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.450, valid_loss=1.350]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 53: 100%|██████████| 7/7 [00:00<00:00, 65.42it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.400, valid_loss=1.350]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.330, valid_loss=1.350]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.500, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 121.41it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.500, valid_loss=1.320]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.490, valid_loss=1.320]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=1.320]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.460, valid_loss=1.320]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=1.320]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.510, valid_loss=1.320]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.390, valid_loss=1.320]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.370, valid_loss=1.320]\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 149.34it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.370, valid_loss=1.310]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.450, valid_loss=1.310]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.400, valid_loss=1.310]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.360, valid_loss=1.310]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.270, valid_loss=1.310]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.440, valid_loss=1.310]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.330, valid_loss=1.310]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.380, valid_loss=1.310]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 219.70it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.380, valid_loss=1.310]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.300, valid_loss=1.310]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.290, valid_loss=1.310]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.370, valid_loss=1.310]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.390, valid_loss=1.310]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.400, valid_loss=1.310]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:14:24,922\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=7050)\u001b[0m \rEpoch 77: 100%|██████████| 7/7 [00:00<00:00, 78.82it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.400, valid_loss=1.310]\rEpoch 77: 100%|██████████| 7/7 [00:00<00:00, 78.09it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.400, valid_loss=1.310]\rEpoch 77: 100%|██████████| 7/7 [00:00<00:00, 77.69it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.330, valid_loss=1.310]\rEpoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.330, valid_loss=1.310]        \rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.330, valid_loss=1.310]\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \n","\u001b[36m(_train_tune pid=7050)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 220.60it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7050)\u001b[0m \r                                                                       \u001b[A\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.330, valid_loss=1.310]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.230, valid_loss=1.310]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.230, valid_loss=1.310]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=7191)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=7191)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=7191)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=7191)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=7191)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 2025-06-14 19:14:34.112601: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=7191)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=7191)\u001b[0m E0000 00:00:1749928474.159896    7266 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=7191)\u001b[0m E0000 00:00:1749928474.172565    7266 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 2025-06-14 19:14:34.210492: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=7191)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=7191)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=7191)\u001b[0m \n","\u001b[36m(_train_tune pid=7191)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=7191)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=7191)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=7191)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.340]\n","Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 54.44it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.340]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.600]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.420]\n","Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 72.96it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.450]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.450]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.570]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.480]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7191)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.73it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.480, valid_loss=1.370]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.430, valid_loss=1.370]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=1.370]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=1.370]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.540, valid_loss=1.370]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.500, valid_loss=1.370]\n","Epoch 13: 100%|██████████| 7/7 [00:00<00:00, 81.37it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.500, valid_loss=1.370]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.420, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=7191)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 223.76it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.420, valid_loss=1.370]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.440, valid_loss=1.370]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.540, valid_loss=1.370]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.460, valid_loss=1.370]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.440, valid_loss=1.370]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.490, valid_loss=1.370]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=1.520, valid_loss=1.370]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7191)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 176.55it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.540, valid_loss=1.360]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.390, valid_loss=1.360]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.560, valid_loss=1.360]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.380, valid_loss=1.360]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.430, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=7191)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 213.78it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.450, valid_loss=1.360]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.500, valid_loss=1.360]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.460, valid_loss=1.360]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.500, valid_loss=1.360]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.450, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=7191)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 221.21it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.450, valid_loss=1.360]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.430, valid_loss=1.360]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.390, valid_loss=1.360]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.500, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=7191)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 218.80it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.450, valid_loss=1.340]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.400, valid_loss=1.340]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.550, valid_loss=1.340]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.380, valid_loss=1.340]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.390, valid_loss=1.340]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.390, valid_loss=1.340]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 82.22it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.390, valid_loss=1.340]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 216.41it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=1.340]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.450, valid_loss=1.340]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.460, valid_loss=1.340]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.460, valid_loss=1.340]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.420, valid_loss=1.340]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.480, valid_loss=1.340]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.490, valid_loss=1.340]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7191)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 166.97it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.490, valid_loss=1.320]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.420, valid_loss=1.320]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.460, valid_loss=1.320]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.390, valid_loss=1.320]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.510, valid_loss=1.320]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.400, valid_loss=1.320]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.380, valid_loss=1.320]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 217.58it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.380, valid_loss=1.300]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.450, valid_loss=1.300]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.410, valid_loss=1.300]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.260, valid_loss=1.300]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.420, valid_loss=1.300]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.320, valid_loss=1.300]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.380, valid_loss=1.300]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7191)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 203.72it/s]\u001b[A\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.300, valid_loss=1.310]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.290, valid_loss=1.310]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.370, valid_loss=1.310]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.340, valid_loss=1.310]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:14:45,931\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=7191)\u001b[0m \rEpoch 75: 100%|██████████| 7/7 [00:00<00:00, 81.28it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.340, valid_loss=1.310]\rEpoch 75: 100%|██████████| 7/7 [00:00<00:00, 80.48it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=1.310]\rEpoch 75: 100%|██████████| 7/7 [00:00<00:00, 80.03it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.380, valid_loss=1.310]\rEpoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.380, valid_loss=1.310]        \rEpoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.380, valid_loss=1.310]\rEpoch 76: 100%|██████████| 7/7 [00:00<00:00, 83.47it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.380, valid_loss=1.310]\rEpoch 76: 100%|██████████| 7/7 [00:00<00:00, 83.14it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.380, valid_loss=1.310]\rEpoch 76: 100%|██████████| 7/7 [00:00<00:00, 82.50it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.410, valid_loss=1.310]\rEpoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.410, valid_loss=1.310]        \rEpoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.410, valid_loss=1.310]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.340, valid_loss=1.310]\n","\u001b[36m(_train_tune pid=7191)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 224.11it/s]\u001b[A\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.240, valid_loss=1.310]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=7329)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=7329)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=7329)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=7329)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=7329)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 2025-06-14 19:14:56.165317: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=7329)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=7329)\u001b[0m E0000 00:00:1749928496.190615    7407 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=7329)\u001b[0m E0000 00:00:1749928496.198136    7407 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 2025-06-14 19:14:56.222652: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=7329)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=7329)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=7329)\u001b[0m \n","\u001b[36m(_train_tune pid=7329)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=7329)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=7329)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=7329)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.290]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.480]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.960]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.490]        \n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.490]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.410]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.480]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7329)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 187.78it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.480, valid_loss=1.400]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.510, valid_loss=1.400]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.490, valid_loss=1.400]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.470, valid_loss=1.400]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=1.400]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.420, valid_loss=1.400]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.530, valid_loss=1.400]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.390, valid_loss=1.400]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7329)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 116.34it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.390, valid_loss=1.360]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.450, valid_loss=1.360]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.510, valid_loss=1.360]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.560, valid_loss=1.360]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.600, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=7329)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 142.09it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.600, valid_loss=1.350]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.450, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.570, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.490, valid_loss=1.350]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.490, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.410, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=7329)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7329)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 112.93it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.520, valid_loss=1.360]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.510, valid_loss=1.360]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.380, valid_loss=1.360]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.520, valid_loss=1.360]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.350, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:15:03,801\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=7329)\u001b[0m \rEpoch 33: 100%|██████████| 7/7 [00:00<00:00, 80.67it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.350, valid_loss=1.360]\rEpoch 33: 100%|██████████| 7/7 [00:00<00:00, 79.71it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.350, valid_loss=1.360]\rEpoch 33: 100%|██████████| 7/7 [00:00<00:00, 79.26it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.420, valid_loss=1.360]\rEpoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.420, valid_loss=1.360]        \rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.420, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=7329)\u001b[0m \rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 79.65it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.420, valid_loss=1.360]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 78.93it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.420, valid_loss=1.360]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 78.53it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.440, valid_loss=1.360]\rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.440, valid_loss=1.360]        \rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.440, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=7329)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7329)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7329)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 208.68it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.370, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=7452)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=7452)\u001b[0m Seed set to 3\n","\u001b[36m(_train_tune pid=7452)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=7452)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=7452)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 2025-06-14 19:15:14.133971: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=7452)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=7452)\u001b[0m E0000 00:00:1749928514.179134    7533 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=7452)\u001b[0m E0000 00:00:1749928514.191059    7533 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 2025-06-14 19:15:14.233175: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=7452)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=7452)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=7452)\u001b[0m \n","\u001b[36m(_train_tune pid=7452)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=7452)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=7452)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=7452)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=7452)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  6.72it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=2.260]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.200]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.210]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.620]\n","Epoch 5: 100%|██████████| 7/7 [00:00<00:00, 80.49it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.450]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.480]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.550]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7452)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.66it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.550, valid_loss=1.350]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.520, valid_loss=1.350]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.450, valid_loss=1.350]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.510, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.73it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.510, valid_loss=1.360]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.660, valid_loss=1.360]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.540, valid_loss=1.360]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.520, valid_loss=1.360]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.420, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:15:20,294\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=7452)\u001b[0m \rEpoch 20: 100%|██████████| 7/7 [00:00<00:00, 83.77it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.420, valid_loss=1.360]\rEpoch 20: 100%|██████████| 7/7 [00:00<00:00, 82.97it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.420, valid_loss=1.360]\rEpoch 20: 100%|██████████| 7/7 [00:00<00:00, 82.50it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.540, valid_loss=1.360]\rEpoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.540, valid_loss=1.360]        \rEpoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.540, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=7452)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7452)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7452)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7452)\u001b[0m \n","\u001b[36m(_train_tune pid=7452)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 186.29it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7452)\u001b[0m \r                                                                       \u001b[A\rEpoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.540, valid_loss=1.360]\rEpoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.350, valid_loss=1.360]\rEpoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.350, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=7570)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=7570)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=7570)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=7570)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=7570)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 2025-06-14 19:15:31.848099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=7570)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=7570)\u001b[0m E0000 00:00:1749928531.871961    7658 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=7570)\u001b[0m E0000 00:00:1749928531.879142    7658 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 2025-06-14 19:15:31.905635: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=7570)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=7570)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=7570)\u001b[0m \n","\u001b[36m(_train_tune pid=7570)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=7570)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=7570)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=7570)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.270]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.860]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.520]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.510]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.510]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.440]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.500]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 208.11it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7570)\u001b[0m \n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.550, valid_loss=1.370]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.550, valid_loss=1.370]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.510, valid_loss=1.370]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.520, valid_loss=1.370]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=1.370]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.510, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=7570)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 214.80it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.570, valid_loss=1.350]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.490, valid_loss=1.350]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.460, valid_loss=1.350]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.440, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=7570)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 223.18it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.490, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.400, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.470, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7570)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 204.01it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.590, valid_loss=1.360]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=1.630, valid_loss=1.360]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.520, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:15:38,651\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=7570)\u001b[0m \rEpoch 33: 100%|██████████| 7/7 [00:00<00:00, 70.07it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.520, valid_loss=1.360]\rEpoch 33: 100%|██████████| 7/7 [00:00<00:00, 69.57it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=1.360]\rEpoch 33: 100%|██████████| 7/7 [00:00<00:00, 69.24it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.570, valid_loss=1.360]\rEpoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.570, valid_loss=1.360]        \rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.570, valid_loss=1.360]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.540, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=7570)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 218.67it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.480, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=7697)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=7697)\u001b[0m Seed set to 4\n","\u001b[36m(_train_tune pid=7697)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=7697)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=7697)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 2025-06-14 19:15:50.542534: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=7697)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=7697)\u001b[0m E0000 00:00:1749928550.569391    7783 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=7697)\u001b[0m E0000 00:00:1749928550.577868    7783 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 2025-06-14 19:15:50.603500: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=7697)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=7697)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=7697)\u001b[0m \n","\u001b[36m(_train_tune pid=7697)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=7697)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=7697)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=7697)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.340]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=2.140]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.360]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.240]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.170]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=2.060]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.780]\n","\u001b[36m(_train_tune pid=7697)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 159.92it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.780, valid_loss=1.500]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.560, valid_loss=1.500]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.600, valid_loss=1.500]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.530, valid_loss=1.500]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.520, valid_loss=1.500]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.680, valid_loss=1.500]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.510, valid_loss=1.500]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.460, valid_loss=1.500]\n","\u001b[36m(_train_tune pid=7697)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 172.25it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.460, valid_loss=1.350]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.530, valid_loss=1.350]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.430, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7697)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 117.39it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.460, valid_loss=1.350]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.370, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:15:57,400\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=7697)\u001b[0m \n","\u001b[36m(_train_tune pid=7697)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7697)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7697)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7697)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 226.86it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7697)\u001b[0m \r                                                                       \u001b[A\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.370, valid_loss=1.350]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.480, valid_loss=1.350]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.480, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=7825)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=7825)\u001b[0m Seed set to 4\n","\u001b[36m(_train_tune pid=7825)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=7825)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=7825)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 2025-06-14 19:16:07.221367: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=7825)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=7825)\u001b[0m E0000 00:00:1749928567.256814    7905 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=7825)\u001b[0m E0000 00:00:1749928567.268351    7905 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 2025-06-14 19:16:07.308285: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=7825)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=7825)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=7825)\u001b[0m \n","\u001b[36m(_train_tune pid=7825)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=7825)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=7825)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=7825)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.300]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=2.090]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=2.180]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.630]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.520]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.490]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.520]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 220.80it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.520, valid_loss=1.390]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.460, valid_loss=1.390]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.560, valid_loss=1.390]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.520, valid_loss=1.390]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.680, valid_loss=1.390]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.510, valid_loss=1.390]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.470, valid_loss=1.390]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7825)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 188.98it/s]\u001b[A\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.530, valid_loss=1.350]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.430, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=7825)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.36it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.430, valid_loss=1.360]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.460, valid_loss=1.360]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.420, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:16:14,173\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=7825)\u001b[0m \rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 75.09it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.420, valid_loss=1.360]\rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 74.51it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.420, valid_loss=1.360]\rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 74.10it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.530, valid_loss=1.360]\rEpoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.530, valid_loss=1.360]        \rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.530, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=7825)\u001b[0m \rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 77.39it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.530, valid_loss=1.360]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 76.73it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.530, valid_loss=1.360]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 76.32it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.370, valid_loss=1.360]\rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.370, valid_loss=1.360]        \rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.370, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=7825)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7825)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7825)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 222.73it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7825)\u001b[0m \n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.490, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=7942)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=7942)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=7942)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=7942)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=7942)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 2025-06-14 19:16:25.014129: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=7942)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=7942)\u001b[0m E0000 00:00:1749928585.041372    8028 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=7942)\u001b[0m E0000 00:00:1749928585.048947    8028 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 2025-06-14 19:16:25.073301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=7942)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=7942)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \n","\u001b[36m(_train_tune pid=7942)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=7942)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=7942)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=7942)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.320]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.170]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.240]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.940]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.520]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.520]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 186.68it/s]\u001b[A\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.560, valid_loss=1.380]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.550, valid_loss=1.380]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.490, valid_loss=1.380]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.510, valid_loss=1.380]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.390, valid_loss=1.380]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=1.380]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.510, valid_loss=1.380]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 225.18it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.560, valid_loss=1.350]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.490, valid_loss=1.350]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.460, valid_loss=1.350]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.550, valid_loss=1.350]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.430, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 171.09it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.490, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.460, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.400, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.460, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 234.46it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.460, valid_loss=1.350]\n","Epoch 28: 100%|██████████| 7/7 [00:00<00:00, 52.35it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.580, valid_loss=1.350]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=1.620, valid_loss=1.350]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.400, valid_loss=1.350]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.530, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 229.20it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.570, valid_loss=1.350]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.380, valid_loss=1.350]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.420, valid_loss=1.350]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.500, valid_loss=1.350]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.440, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 178.77it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.430, valid_loss=1.360]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.420, valid_loss=1.360]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.420, valid_loss=1.360]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.530, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:16:33,189\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=7942)\u001b[0m \rEpoch 49: 100%|██████████| 7/7 [00:00<00:00, 81.99it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.530, valid_loss=1.360]\rEpoch 49: 100%|██████████| 7/7 [00:00<00:00, 81.22it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.530, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 226.10it/s]\u001b[A\n","\u001b[36m(_train_tune pid=7942)\u001b[0m \r                                                                       \u001b[A\rEpoch 49: 100%|██████████| 7/7 [00:00<00:00, 54.72it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.530, valid_loss=1.360]\rEpoch 49: 100%|██████████| 7/7 [00:00<00:00, 54.42it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.580, valid_loss=1.360]\rEpoch 49: 100%|██████████| 7/7 [00:00<00:00, 54.06it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.580, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=8077)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=8077)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=8077)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=8077)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=8077)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 2025-06-14 19:16:43.780463: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=8077)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=8077)\u001b[0m E0000 00:00:1749928603.806213    8155 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=8077)\u001b[0m E0000 00:00:1749928603.813994    8155 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 2025-06-14 19:16:43.843383: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=8077)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=8077)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=8077)\u001b[0m \n","\u001b[36m(_train_tune pid=8077)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=8077)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=8077)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=8077)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=8077)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  5.18it/s]\n","                                                                           \n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=2.190]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.560]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.420]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.460]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.440]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.550]\n","Epoch 6: 100%|██████████| 7/7 [00:00<00:00, 59.94it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.550]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.470]\n","\u001b[36m(_train_tune pid=8077)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 174.27it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.470, valid_loss=1.370]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.460, valid_loss=1.370]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.420, valid_loss=1.370]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.370, valid_loss=1.370]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=1.370]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.530, valid_loss=1.370]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.490, valid_loss=1.370]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.410, valid_loss=1.370]\n","\u001b[36m(_train_tune pid=8077)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 138.18it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.410, valid_loss=1.370]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.440, valid_loss=1.370]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.480, valid_loss=1.370]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.540, valid_loss=1.370]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.460, valid_loss=1.370]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.440, valid_loss=1.370]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.480, valid_loss=1.370]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=1.520, valid_loss=1.370]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 222.83it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.520, valid_loss=1.360]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.400, valid_loss=1.360]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.530, valid_loss=1.360]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.550, valid_loss=1.360]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.370, valid_loss=1.360]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.410, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=8077)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 220.87it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.420, valid_loss=1.360]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.470, valid_loss=1.360]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.450, valid_loss=1.360]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 33: 100%|██████████| 7/7 [00:00<00:00, 82.01it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.530, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:16:51,494\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=8077)\u001b[0m \rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 81.86it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.530, valid_loss=1.360]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 81.08it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.530, valid_loss=1.360]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 80.50it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.410, valid_loss=1.360]\rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.410, valid_loss=1.360]        \rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.410, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=8077)\u001b[0m \n","\u001b[36m(_train_tune pid=8077)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8077)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8077)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8077)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.56it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8077)\u001b[0m \r                                                                       \u001b[A\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.410, valid_loss=1.360]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.400, valid_loss=1.360]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.400, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=8202)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=8202)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=8202)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=8202)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=8202)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 2025-06-14 19:17:03.152779: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=8202)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=8202)\u001b[0m E0000 00:00:1749928623.179527    8286 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=8202)\u001b[0m E0000 00:00:1749928623.186845    8286 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 2025-06-14 19:17:03.211576: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=8202)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=8202)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=8202)\u001b[0m \n","\u001b[36m(_train_tune pid=8202)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=8202)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=8202)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=8202)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.290]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=2.080]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.680]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.530]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.510]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.440]\n","Epoch 6: 100%|██████████| 7/7 [00:00<00:00, 72.51it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.440]\n","Epoch 6: 100%|██████████| 7/7 [00:00<00:00, 72.25it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.440]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.490]\n","\u001b[36m(_train_tune pid=8202)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 223.71it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.550, valid_loss=1.360]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.500, valid_loss=1.360]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.510, valid_loss=1.360]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.400, valid_loss=1.360]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.450, valid_loss=1.360]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.520, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 219.03it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.520, valid_loss=1.360]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.570, valid_loss=1.360]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.490, valid_loss=1.360]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.460, valid_loss=1.360]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.510, valid_loss=1.360]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.560, valid_loss=1.360]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.430, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8202)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 179.02it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.490, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.460, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.400, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.470, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=8202)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 227.51it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.470, valid_loss=1.360]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.590, valid_loss=1.360]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=1.630, valid_loss=1.360]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.530, valid_loss=1.360]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.580, valid_loss=1.360]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.540, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8202)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 205.23it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.370, valid_loss=1.350]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.380, valid_loss=1.350]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.450, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=8202)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 220.74it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.430, valid_loss=1.360]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.430, valid_loss=1.360]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.450, valid_loss=1.360]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.530, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:17:11,405\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=8202)\u001b[0m \rEpoch 49: 100%|██████████| 7/7 [00:00<00:00, 79.83it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.530, valid_loss=1.360]\rEpoch 49: 100%|██████████| 7/7 [00:00<00:00, 79.15it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.530, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=8202)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8202)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8202)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8202)\u001b[0m \n","\u001b[36m(_train_tune pid=8202)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 126.56it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8202)\u001b[0m \r                                                                       \u001b[A\rEpoch 49: 100%|██████████| 7/7 [00:00<00:00, 44.06it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.530, valid_loss=1.350]\rEpoch 49: 100%|██████████| 7/7 [00:00<00:00, 43.75it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.580, valid_loss=1.350]\rEpoch 49: 100%|██████████| 7/7 [00:00<00:00, 43.51it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.580, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=8337)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=8337)\u001b[0m Seed set to 3\n","\u001b[36m(_train_tune pid=8337)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=8337)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=8337)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 2025-06-14 19:17:23.547371: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=8337)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=8337)\u001b[0m E0000 00:00:1749928643.572405    8422 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=8337)\u001b[0m E0000 00:00:1749928643.579972    8422 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 2025-06-14 19:17:23.608447: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=8337)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=8337)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \n","\u001b[36m(_train_tune pid=8337)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=8337)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=8337)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=8337)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=2.280]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.250]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.410]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.250]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.210]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.230]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.280]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 123.30it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.280, valid_loss=2.080]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.970, valid_loss=2.080]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.710, valid_loss=2.080]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.530, valid_loss=2.080]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.500, valid_loss=2.080]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.450, valid_loss=2.080]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.520, valid_loss=2.080]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.510, valid_loss=2.080]\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 140.79it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.650, valid_loss=1.350]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.540, valid_loss=1.350]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.460, valid_loss=1.350]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.410, valid_loss=1.350]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.530, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 115.04it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.530, valid_loss=1.350]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.490, valid_loss=1.350]\n","Epoch 23: 100%|██████████| 7/7 [00:00<00:00, 76.55it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 24: 100%|██████████| 7/7 [00:00<00:00, 64.53it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.440, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 206.92it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.490, valid_loss=1.350]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.450, valid_loss=1.350]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.550, valid_loss=1.350]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.420, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.70it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.570, valid_loss=1.350]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.520, valid_loss=1.350]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.490, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 219.30it/s]\u001b[A\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.490, valid_loss=1.350]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.460, valid_loss=1.350]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.500, valid_loss=1.350]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.640, valid_loss=1.350]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.570, valid_loss=1.350]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 81.17it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.570, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 167.98it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.530, valid_loss=1.350]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.400, valid_loss=1.350]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.500, valid_loss=1.350]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.430, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:17:33,319\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=8337)\u001b[0m \rEpoch 55: 100%|██████████| 7/7 [00:00<00:00, 81.12it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.430, valid_loss=1.350]\rEpoch 55: 100%|██████████| 7/7 [00:00<00:00, 80.38it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.430, valid_loss=1.350]\rEpoch 55: 100%|██████████| 7/7 [00:00<00:00, 79.95it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.470, valid_loss=1.350]\rEpoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.470, valid_loss=1.350]        \rEpoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.470, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 75.03it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.470, valid_loss=1.350]\rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 74.42it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.470, valid_loss=1.350]\rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 74.02it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.650, valid_loss=1.350]\rEpoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.650, valid_loss=1.350]        \rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.650, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 205.65it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8337)\u001b[0m \r                                                                       \u001b[A\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.350]\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.350]\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.350]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=8479)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=8479)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=8479)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=8479)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=8479)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 2025-06-14 19:17:44.789715: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=8479)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=8479)\u001b[0m E0000 00:00:1749928664.813565    8561 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=8479)\u001b[0m E0000 00:00:1749928664.820940    8561 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 2025-06-14 19:17:44.862191: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=8479)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=8479)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=8479)\u001b[0m \n","\u001b[36m(_train_tune pid=8479)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=8479)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=8479)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=8479)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=2.220]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.110]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.180]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=2.020]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.760]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.490]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 225.85it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.490, valid_loss=1.380]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.460, valid_loss=1.380]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.440, valid_loss=1.380]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.380, valid_loss=1.380]\n","Epoch 11: 100%|██████████| 7/7 [00:00<00:00, 79.43it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.430, valid_loss=1.380]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.520, valid_loss=1.380]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.480, valid_loss=1.380]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.410, valid_loss=1.380]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8479)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 187.74it/s]\u001b[A\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.530, valid_loss=1.350]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.450, valid_loss=1.350]\n","Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 79.93it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=1.520, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=8479)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 219.76it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.520, valid_loss=1.350]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.390, valid_loss=1.350]\n","Epoch 22: 100%|██████████| 7/7 [00:00<00:00, 80.97it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.390, valid_loss=1.350]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.530, valid_loss=1.350]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.380, valid_loss=1.350]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.410, valid_loss=1.350]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.560, valid_loss=1.350]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.380, valid_loss=1.350]\n","Epoch 27: 100%|██████████| 7/7 [00:00<00:00, 79.72it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.430, valid_loss=1.350]\n","\u001b[36m(_train_tune pid=8479)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 225.77it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.500, valid_loss=1.350]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.510, valid_loss=1.350]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.470, valid_loss=1.350]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.570, valid_loss=1.350]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.460, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8479)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.95it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.470, valid_loss=1.360]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.450, valid_loss=1.360]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.410, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:17:52,282\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=8479)\u001b[0m \rEpoch 40: 100%|██████████| 7/7 [00:00<00:00, 83.06it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.410, valid_loss=1.360]\rEpoch 40: 100%|██████████| 7/7 [00:00<00:00, 82.17it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.410, valid_loss=1.360]\rEpoch 40: 100%|██████████| 7/7 [00:00<00:00, 81.70it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.450, valid_loss=1.360]\rEpoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.450, valid_loss=1.360]        \rEpoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.450, valid_loss=1.360]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.510, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=8479)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 231.47it/s]\u001b[A\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.450, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=8608)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=8608)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=8608)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=8608)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=8608)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 2025-06-14 19:18:03.184590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=8608)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=8608)\u001b[0m E0000 00:00:1749928683.211176    8688 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=8608)\u001b[0m E0000 00:00:1749928683.218509    8688 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 2025-06-14 19:18:03.242624: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=8608)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=8608)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=8608)\u001b[0m \n","\u001b[36m(_train_tune pid=8608)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=8608)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=8608)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=8608)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.400]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=2.210]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.090]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.100]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.660]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.570]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.480]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 172.39it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.450, valid_loss=1.360]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.430, valid_loss=1.360]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=1.360]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=1.360]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.520, valid_loss=1.360]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.480, valid_loss=1.360]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.410, valid_loss=1.360]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8608)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 151.69it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.410, valid_loss=1.350]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.430, valid_loss=1.350]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.540, valid_loss=1.350]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.450, valid_loss=1.350]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.440, valid_loss=1.350]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.480, valid_loss=1.350]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=1.520, valid_loss=1.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8608)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 121.98it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.390, valid_loss=1.360]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.530, valid_loss=1.360]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.380, valid_loss=1.360]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.410, valid_loss=1.360]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.560, valid_loss=1.360]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:18:10,040\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n","2025-06-14 19:18:10,065\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/_train_tune_2025-06-14_19-11-57' in 0.0221s.\n","INFO:lightning_fabric.utilities.seed:Seed set to 8\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=8608)\u001b[0m \rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 82.42it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.560, valid_loss=1.360]\rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 81.62it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.560, valid_loss=1.360]\rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 81.13it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.380, valid_loss=1.360]\rEpoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.380, valid_loss=1.360]        \rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.380, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=8608)\u001b[0m \rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 73.25it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.380, valid_loss=1.360]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 72.75it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.380, valid_loss=1.360]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 72.39it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.430, valid_loss=1.360]\rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.430, valid_loss=1.360]        \rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.430, valid_loss=1.360]\n","\u001b[36m(_train_tune pid=8608)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8608)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8608)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8608)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 220.58it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8608)\u001b[0m \r                                                                       \u001b[A\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.430, valid_loss=1.350]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.470, valid_loss=1.350]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.470, valid_loss=1.350]\n","\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name         | Type          | Params | Mode \n","-------------------------------------------------------\n","0 | loss         | MQLoss        | 5      | eval \n","1 | padder_train | ConstantPad1d | 0      | train\n","2 | scaler       | TemporalNorm  | 0      | train\n","3 | hist_encoder | LSTM          | 199 K  | train\n","4 | mlp_decoder  | MLP           | 17.2 K | train\n","-------------------------------------------------------\n","216 K     Trainable params\n","5         Non-trainable params\n","216 K     Total params\n","0.865     Total estimated model params size (MB)\n","9         Modules in train mode\n","1         Modules in eval mode\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b5ae7ecf7ff4d4f9240a6b3cfa63638"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e21582e0be024404a227404224e7369c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c91a2ac5bb574ce59f3a9a7d4cb56306"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"086c137f5ed04b7eb9849ca543a4bfc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68e0e27a676f479f9a335e6d51dd8f78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a1b20f837e64420a06c58544d8ccd23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8a16f0d6eb84c1b8de64a9462771733"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9d8f43e5eb949529a67a4ef0d0bd456"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6cfcb5eb068444a98b093f94c2f3167"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c052c85e1224d7bbb2f6b9e4f3c60c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"826015724d314995a7403ab959033670"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e58fea50b9f436c8a672b9c32dff8ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9d837b626bb491a94a881ee05280ed8"}},"metadata":{}}]},{"cell_type":"code","source":["forecasts = nf.predict()\n","forecasts"],"metadata":{"id":"-NRoKDM_kglq","colab":{"base_uri":"https://localhost:8080/","height":872,"referenced_widgets":["0ddf00daf9be4fc1b8fb452ca74e8c6e","8121b8b907554fa9a743106b7f8b9297","c847fd7ba10846c4b38b64ff75fdc041","3167240a7e71450f9bf0168c03ebab64","63ab9526dbed41569293c18458805acb","6267be6a782d431d84b57f7d63b44248","273ec0404add4daaa4bc26d2d865fbab","2acb3b27088440bc881ed132c97685b3","66322c8b32d042829a8524e6bb8cf7c8","065e88082eb84efcbb8b6c2ef1b2591b","d5a2ae780ee3466fb8ad04da20309907","57e2ab30cac24e45b5caaf72111c7899","ddcbb3361dc84b0eadb4ddd3e8a74987","cd54f1fbf62640f090f825f9a1b8f70e","3103cdc549ef436f823aec4a6d98c235","98f32d9b609a4ccc915f4b0425fb4e43","4a0819053cb34fefb228a3132eee5263","b6517488583e44f7bd5b802337c3a89b","51070bd257904194b326bc4782ed8761","57c4a083be4f4d6bbe7acdf4c112ef3c","c889cd639d62452ba0c483e702ac9eb0","f9a525bec3bc497cb2acbd8d78d56573"]},"executionInfo":{"status":"ok","timestamp":1749928707278,"user_tz":-60,"elapsed":165,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"8af2f276-b779-4e2a-feda-5dd9f9bc8bfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ddf00daf9be4fc1b8fb452ca74e8c6e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57e2ab30cac24e45b5caaf72111c7899"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["             unique_id         ds  AutoNHITS-median  AutoNHITS-lo-90  \\\n","0     FOODS_1_001_CA_4 2016-05-23          0.000570        -0.024114   \n","1     FOODS_1_001_CA_4 2016-05-24          0.000063        -0.025770   \n","2     FOODS_1_001_CA_4 2016-05-25         -0.001265        -0.020379   \n","3     FOODS_1_001_CA_4 2016-05-26          0.013880        -0.028729   \n","4     FOODS_1_001_CA_4 2016-05-27         -0.006201        -0.020895   \n","...                ...        ...               ...              ...   \n","6043  FOODS_1_219_CA_4 2016-06-15          1.211085        -0.023975   \n","6044  FOODS_1_219_CA_4 2016-06-16          1.177512        -0.013824   \n","6045  FOODS_1_219_CA_4 2016-06-17          1.230846        -0.014513   \n","6046  FOODS_1_219_CA_4 2016-06-18          1.113451        -0.046679   \n","6047  FOODS_1_219_CA_4 2016-06-19          1.213272        -0.035925   \n","\n","      AutoNHITS-lo-80  AutoNHITS-hi-80  AutoNHITS-hi-90  AutoLSTM-median  \\\n","0           -0.018656         1.077417         1.394878         0.010484   \n","1           -0.018027         1.090967         1.430549         0.012007   \n","2           -0.014025         1.078234         1.468905         0.010544   \n","3           -0.025139         1.082085         1.465877         0.009736   \n","4           -0.018997         1.090077         1.497873         0.009308   \n","...               ...              ...              ...              ...   \n","6043         0.031670         3.893807         4.958648         0.989542   \n","6044         0.023554         3.787918         4.841720         0.987107   \n","6045         0.002961         3.914200         4.784177         0.986382   \n","6046         0.025457         3.665020         4.744458         1.008689   \n","6047         0.032582         3.783099         4.877792         1.003728   \n","\n","      AutoLSTM-lo-90  AutoLSTM-lo-80  AutoLSTM-hi-80  AutoLSTM-hi-90  \n","0          -0.121673       -0.009859        0.987194        1.425882  \n","1          -0.128183       -0.009449        1.067754        1.540595  \n","2          -0.120248       -0.009076        0.983091        1.420167  \n","3          -0.120215       -0.010623        0.951530        1.378647  \n","4          -0.118908       -0.011124        0.925410        1.343441  \n","...              ...             ...             ...             ...  \n","6043       -0.200393        0.036619        2.734977        3.458234  \n","6044       -0.205285        0.031824        2.693017        3.397021  \n","6045       -0.199190        0.033352        2.670127        3.363125  \n","6046       -0.283940        0.062819        3.399448        4.439619  \n","6047       -0.370898        0.013910        3.258542        4.240428  \n","\n","[6048 rows x 12 columns]"],"text/html":["\n","  <div id=\"df-b743e084-2d52-4eb4-9139-ce7760291ca9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>unique_id</th>\n","      <th>ds</th>\n","      <th>AutoNHITS-median</th>\n","      <th>AutoNHITS-lo-90</th>\n","      <th>AutoNHITS-lo-80</th>\n","      <th>AutoNHITS-hi-80</th>\n","      <th>AutoNHITS-hi-90</th>\n","      <th>AutoLSTM-median</th>\n","      <th>AutoLSTM-lo-90</th>\n","      <th>AutoLSTM-lo-80</th>\n","      <th>AutoLSTM-hi-80</th>\n","      <th>AutoLSTM-hi-90</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2016-05-23</td>\n","      <td>0.000570</td>\n","      <td>-0.024114</td>\n","      <td>-0.018656</td>\n","      <td>1.077417</td>\n","      <td>1.394878</td>\n","      <td>0.010484</td>\n","      <td>-0.121673</td>\n","      <td>-0.009859</td>\n","      <td>0.987194</td>\n","      <td>1.425882</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2016-05-24</td>\n","      <td>0.000063</td>\n","      <td>-0.025770</td>\n","      <td>-0.018027</td>\n","      <td>1.090967</td>\n","      <td>1.430549</td>\n","      <td>0.012007</td>\n","      <td>-0.128183</td>\n","      <td>-0.009449</td>\n","      <td>1.067754</td>\n","      <td>1.540595</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2016-05-25</td>\n","      <td>-0.001265</td>\n","      <td>-0.020379</td>\n","      <td>-0.014025</td>\n","      <td>1.078234</td>\n","      <td>1.468905</td>\n","      <td>0.010544</td>\n","      <td>-0.120248</td>\n","      <td>-0.009076</td>\n","      <td>0.983091</td>\n","      <td>1.420167</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2016-05-26</td>\n","      <td>0.013880</td>\n","      <td>-0.028729</td>\n","      <td>-0.025139</td>\n","      <td>1.082085</td>\n","      <td>1.465877</td>\n","      <td>0.009736</td>\n","      <td>-0.120215</td>\n","      <td>-0.010623</td>\n","      <td>0.951530</td>\n","      <td>1.378647</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FOODS_1_001_CA_4</td>\n","      <td>2016-05-27</td>\n","      <td>-0.006201</td>\n","      <td>-0.020895</td>\n","      <td>-0.018997</td>\n","      <td>1.090077</td>\n","      <td>1.497873</td>\n","      <td>0.009308</td>\n","      <td>-0.118908</td>\n","      <td>-0.011124</td>\n","      <td>0.925410</td>\n","      <td>1.343441</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6043</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-15</td>\n","      <td>1.211085</td>\n","      <td>-0.023975</td>\n","      <td>0.031670</td>\n","      <td>3.893807</td>\n","      <td>4.958648</td>\n","      <td>0.989542</td>\n","      <td>-0.200393</td>\n","      <td>0.036619</td>\n","      <td>2.734977</td>\n","      <td>3.458234</td>\n","    </tr>\n","    <tr>\n","      <th>6044</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-16</td>\n","      <td>1.177512</td>\n","      <td>-0.013824</td>\n","      <td>0.023554</td>\n","      <td>3.787918</td>\n","      <td>4.841720</td>\n","      <td>0.987107</td>\n","      <td>-0.205285</td>\n","      <td>0.031824</td>\n","      <td>2.693017</td>\n","      <td>3.397021</td>\n","    </tr>\n","    <tr>\n","      <th>6045</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-17</td>\n","      <td>1.230846</td>\n","      <td>-0.014513</td>\n","      <td>0.002961</td>\n","      <td>3.914200</td>\n","      <td>4.784177</td>\n","      <td>0.986382</td>\n","      <td>-0.199190</td>\n","      <td>0.033352</td>\n","      <td>2.670127</td>\n","      <td>3.363125</td>\n","    </tr>\n","    <tr>\n","      <th>6046</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-18</td>\n","      <td>1.113451</td>\n","      <td>-0.046679</td>\n","      <td>0.025457</td>\n","      <td>3.665020</td>\n","      <td>4.744458</td>\n","      <td>1.008689</td>\n","      <td>-0.283940</td>\n","      <td>0.062819</td>\n","      <td>3.399448</td>\n","      <td>4.439619</td>\n","    </tr>\n","    <tr>\n","      <th>6047</th>\n","      <td>FOODS_1_219_CA_4</td>\n","      <td>2016-06-19</td>\n","      <td>1.213272</td>\n","      <td>-0.035925</td>\n","      <td>0.032582</td>\n","      <td>3.783099</td>\n","      <td>4.877792</td>\n","      <td>1.003728</td>\n","      <td>-0.370898</td>\n","      <td>0.013910</td>\n","      <td>3.258542</td>\n","      <td>4.240428</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6048 rows × 12 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b743e084-2d52-4eb4-9139-ce7760291ca9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b743e084-2d52-4eb4-9139-ce7760291ca9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b743e084-2d52-4eb4-9139-ce7760291ca9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-5d0685a6-adfa-4061-bebe-2f776955b673\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5d0685a6-adfa-4061-bebe-2f776955b673')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-5d0685a6-adfa-4061-bebe-2f776955b673 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_2ed16685-0057-4037-9d96-878093cf088c\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('forecasts')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_2ed16685-0057-4037-9d96-878093cf088c button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('forecasts');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"forecasts","summary":"{\n  \"name\": \"forecasts\",\n  \"rows\": 6048,\n  \"fields\": [\n    {\n      \"column\": \"unique_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 216,\n        \"samples\": [\n          \"FOODS_1_205_CA_4\",\n          \"FOODS_1_217_CA_4\",\n          \"FOODS_1_141_CA_4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ds\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2016-05-23 00:00:00\",\n        \"max\": \"2016-06-19 00:00:00\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"2016-06-01 00:00:00\",\n          \"2016-06-17 00:00:00\",\n          \"2016-05-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AutoNHITS-median\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6048,\n        \"samples\": [\n          0.2662944793701172,\n          0.010133326053619385,\n          0.8221697807312012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AutoNHITS-lo-90\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6045,\n        \"samples\": [\n          -0.03148293495178223,\n          -0.016918420791625977,\n          -0.021861135959625244\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AutoNHITS-lo-80\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6045,\n        \"samples\": [\n          -0.04177260398864746,\n          -0.017084121704101562,\n          -0.009811341762542725\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AutoNHITS-hi-80\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6046,\n        \"samples\": [\n          3.1523056030273438,\n          1.2533419132232666,\n          1.4944324493408203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AutoNHITS-hi-90\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6047,\n        \"samples\": [\n          3.6348276138305664,\n          1.2862154245376587,\n          1.2645751237869263\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AutoLSTM-median\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6046,\n        \"samples\": [\n          0.037530094385147095,\n          0.008982676081359386,\n          0.01516515389084816\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AutoLSTM-lo-90\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6047,\n        \"samples\": [\n          -0.2120964527130127,\n          -0.20958930253982544,\n          -0.08336617052555084\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AutoLSTM-lo-80\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6048,\n        \"samples\": [\n          -0.04692048206925392,\n          -0.009371411986649036,\n          -0.1529003381729126\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AutoLSTM-hi-80\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6048,\n        \"samples\": [\n          5.756642818450928,\n          0.9403451085090637,\n          3.113443613052368\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AutoLSTM-hi-90\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6048,\n        \"samples\": [\n          8.344362258911133,\n          1.3574947118759155,\n          4.032815456390381\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["cv_nn = nf.cross_validation(train,\n","                            n_windows=1,\n","                            step_size=horizon)"],"metadata":{"id":"Y2NT-qSpl6CE","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9070f3e2bb35405db17d4ad239f0f157","ec3e5eaea8ca4337856b4f0729a1b34e","95e23a20c821441c8b73bb96a7be37c9","9c4e05b0f46b4d6790d66b5323b29594","e27f7ec405e74ce5bd3c801dd334041d","73eba21eec8a4dabad72afd0ff102f1d","b7faae5fce1b4711be82a2483cbf9b19","184be2e83bb849cfaf78443b37b95ef5","602c3a3fcf544712b0c008eb3ef73f92","3a0afc555b5d406a8fa4bef3ca181444","92e7beb37bd04a219eec770e0acd1df1","ab653e2090784bd08aadcd1643125b69","20a25d45ba0547f1aec605d330718a0f","e83b22ca655649fbad253742bc73e1ad","51bbf34dcb374025a279030bc260540f","10e5bbb763d34a8881f39329dc84a89a","9fcba674633a445eb9eeb6988dafe5f2","6c298ed584ae4d338b02ba25b35aa1ce","42c06b741d4449e596d0cd3d2fa94e09","b1ac9fb03d21448c9ddf6bcb08fc3ba1","485e45b552fa4f1b89fe48231612f859","e2b957fcd3fc4032be72501bd6fdd44d","0168e8f930ab4283be0ea80a7c4649a4","351a2cdd427a4463a18e5d77d33e3c47","baa4ea06e35f4cb6b5c5fb530c70ed5c","ac6a3bfc88f54644bc373e896d8e38b1","75c307c1935e442c8deb6b188ff2b918","eb35a1880fa44832b328b3ca8f234b0f","2d9c6f86a16c47a2be9404a5f8c1c8ca","f454957b8dc34966999cd075ce5ea407","c837d20e19a14f28b9a95e2aad156ad2","0f8c0768db2542209bfd5525b085af6a","bc3433f738cf40df8ab55e37580e4725","f0628a4d4837464dae68515c6520b5a9","0140f0fcb51145e9998fb009c74823aa","0b3bfe3a407d4c878fab938b4618b5b8","d9ef017410c34d899b06b3e7f8123de6","12cacbfa26aa4c14acdaf72b09e8c189","9bab729defc1406c9647e832f7b40c86","c87763104ffc4adbaa593a7882c3b246","5d8d595f59ec47c18a9c849c45ed4441","e62a4fcb1df04f4b97a17483c0d822b6","51f55f959f42499b9ca8dc10d0da9a0c","45df5fac704c40ddb803774f10dc91c3","89888f516ea0447d9934b623b3e3a8fc","05a2190005544464823862097e666b30","c3684c83ac3442c2ac2aa1630970cfef","206bce365a30408a8d36914a5ca6b651","b7ae60f48c4045abba21ee53f6ae25e9","54feb72462494b169e52d4c7fa76d9ce","3da04144c79d439cb47c1a6f55fec249","121c5c30b9614903aceee5ce9267d521","6cf8f71d95544dd0b0ca332aa637178d","9af484211a5f483c95bf87553c449aa2","fafdcac4b9c54bf3b20297964252b413","f1b3aaa201614d31af882e5f70a0ef36","da38df7dbd7a4d93a9d4d32f29df8df2","84a0685284b44ae497c3f3b39e4032df","ec6c86d5b8fa4241a413da7089618b04","510e425ac3c74c4d9aff3a59cd6ffd1a","927259a7f4d540b19a58873d411e3732","c9e9c0006f51403eb2f423c49d843261","9a9a23022deb4313835f981e28b8c4a6","6826609626624e9fbd32897316885c6e","f34b146efb4b40a198ba1ae2bc3cae5f","acfdf8dbfc814c8eb2b474535e95251a","fd8fba7745ac48f7afc4a0b23377b0d6","2641b22ea7b441bd8848b027c4066050","691bf393bf2a462bbc69db9d48ba31a9","91d2477fbd6d4e83bfd5b21b7237a13e","aa396bc8f10d4067ab9e1d406d223410","f43c012513824c8d9460ffa2f0e65ddf","a2059be4644649bb9bc6909936067c06","24afc46bd13241f3aea13fbd8e1e3029","5e31eb08aaeb4deabe91c9a33c8f8c40","16a8e3acc7f64ac5b6394bd2dbce9410","3ad0181ac01e43cabf3fffd8c5ed7061","35e24355d05347a2bbd2db21b23eb54c","6a9c01a291a44d6bb5c53e759c550651","3595807ddfc242d197f564e655c6037d","1d7ec36a34fd4cc5b7563d9fd1b458e5","c8af2d4fb81d43a984d8973b245187ac","75d13251e6b44a8eaf7236307d7e06c0","cb1ea16d3f124784b84ff5e594baf319","3528ff66184f413981ccaa19558a314b","06ac04ce0c664a31a248d7b1a5260451","4d478de58bc546d5b7bb739aa864fb48","58a7cc9b5eb644698456f4c3e8fc602b","df15a760b3564853a4ec69ea35d3b762","dcc8571867dc4cde9dae04a03c4af981","fa2ef909e39246dca41f30f399430078","d76cf8cf06c54f3faf27a0b179a62303","76e665cf6d23452e9c14b6b7153b188a","d975d72b90de41f295db3c920e2e59a4","93fc07b1480b42f991177f6f68970d05","0e43dc314a0043ee9899b5d4e886aa31","96a34c95ef8c4ce1b9fc58f7455663ef","c9186895ae6545f39768c6757ada1fa3","3857faa149c94249b78112356e95f66a","e69a7c6eea384c4f9e8d622316064ef3","6087ffff11c841ee8c35552f67ed94d9","9d411f384c624264ba8b1b02cd6bb121","78f98a9249814578a728ceaf4498a558","08e32e69767b4bcabb5864c6b58287ae","e59b45af2540499aa41f682b35a40fe6","0abd3e9365914371b19c43f47df090c7","627bfb18264444e4883a21f4c4769e95","dde0678a614f437a8beb300f6fd128e1","bebe079618e64694b0328236e1e57381","ad32bab9eccf48e7ae2d82de89da9d43","db7f3c2467e64d769204b8be8569483f","7bfd54c125aa43f28cb018d87ad28307","7265c85d59c5471891b4adddbc96a2e1","515d48e6fa2b4718bbb57a2b5e1d1dd6","b77b1b091878409e9b0f9ef4e7cb150a","bfe11d9025f9471fbc0573fe8a64a1cf","63cc09fca880482eb993e5984a480431","ce37a2c0f003405784d643e79ac7ee2c","0436299a39914082a7a39ccb29c2fa24","41d1401be8fe4564bbf38a3ec49937cc","9fa310220fbc40018b44b3959b78d5fc","d28b930d40044e77b470c56a6c321b51","fbe89b07fc7740098781eba8ecb0b592","5b2f17b3c1a54088a0380ea415b969d3","0427a3764fe94533ad1fd287f9365b58","ee8c492ba8744956b880572cf4183f6c","6ac3556b8366491086c274e3e19ae516","05fee127d96f48a0bb81c73df2feb929","5a0df1bc78f0417e8370bbed8e1abd5c","5cee77b01f0c47c699bda9527946082c","3e6488ca1abf4fa8ab3668a3d0f87435","f7d71a18ec7249d6a4cea9087d94e999","6efca17fb83447a591cdc611e6753eab","15cc7e5cca874effb8729df5cfdb841a","32c6cbc9f54440e0be95d418eda8c06a","834c8041099b43eaaa19e4424d6210f4","12328798990144fab29e287d80ad44de","9075bf8a37da4d4da3065f76ff315c6f","88935f1ef51a4b148be24a95a7c5668a","f40cf9577e834098bf1137b82ef50e8c","40c69e05d2064019a508742496edf8cd","1aae5ffd23154146adb09cc20a442e2f","7242b694a5884dd486cfc4b55521d2cc","c2181d5886404a8eb26579e7c10c7d1a","b453d4a142be4154bffa3b8d2acd000b","d085dfa351354e73823eda7fbc20c3e3","ecbf18929b77455bbceccf321e991a5b","217f5a5f2dde457eba9c63a0b5a5a23c","5b08029de6a949afb6b0a51e74a2daa7","616c76edb7eb496e957efc77846e7116","421388e54fa648f28665d378205b47aa","7ca68e11965d402590e4168419ee2337","4c4c4b8d043a4379beda87d23fdfd3c2","453d9f37918348539c2d0a24a8c2f743","db681488593840d6ada54fc0c76617c0","e7655df7ee30412bba68c3c67d9f75e0","779ea11f378b482abdba7474cdc08d84","f417dfff84af4664adc81afa45b76f3d","d758ce2ec201470194cfbd92d9af9128","cd0ca77ffda64078a3214094c6bda709","cf404db9b4be44c9968206342e96e250","585c0b53be0f48ce9b231610bc0ea4ea","7ebb5625904449c1aa394941418279ce","0ab427fcc3814bd18e69c3626b694c1c","00e62b139293425aa1d656a08a0939f8","54d5f56a12354d1c9c5de34449d2c9c8","4db9ac09a39d4275af19230c1e1aa9f5","1f73c26e98004549b27bdce5b6e2098c","33c8d6cf74074b82847a8915d2716664","6f04c64361e94f718250332b5042b632","9a156f3536cc482f905a74d5931db6ed","71cb740fa3e94bb6a9925a4f02d2ffcb","38fc104a45a04382b254d62669f1a90c","4d8b25b92ec540be9243c63519a14fb1","dc738de280444fb29a6d490028878306","0e018d13b32741aeb83583a04ed90018","71decdc5b01d4006ba082ac2479849d4","8c24d9b0cee740948815e9ed0fd68fb9","366060b27401457e8ce7cebfae1aac2d","2a2bf743ea494395883d14af637b895e","17580c1156904f0db53fef2f25aa464b","bb5486fdc3e8457287b4b28e76bd0f67","95e55018b5f24399bacb5e8389cf4061","130892ca49ea4522a4f9b2931e5e5abe","2025e0ee545840d4adc734970e8fa63b","4a2abce31e554c37995cbc701617fefc","0d2106fd3ed14a6398283005f11dc617","056bdfbf47654a56bc2dd24e9e716f82","cd3a7f9f7852420881a694eb8d9068fd","62b8cde6a31e4491bd4e7bc568a01a04","4ef08039cde14b9bbf1b7568777e32b9","18bd7cd331fb45bba05a153f9feca00e","cf2df69129684f2bab1c84a8b1aca3e4","ae591a0bd60243edad58c9470d31a127","7119da71288a4a64826c5d76ae9641df","c61e3242ec6c46b9aab4197fac05f08f","a3b537745299439b8272553fb6f41b2b","af502f81c97b4c90b9f2c0f6d32d7f8b","379aad276713407ca5ef3ce3a1f45113","94198cb801634ece8dce354a781f93af","83ea4c43468b4bfc8247b7d397c21625","953a72feaa7f41abbc83d95e75233242","71e8857016834e7d9f2c9b36f4298336","6d416fbc346b425ab56bc1e34a57ccf5","5579d69fcf464d4884decec5304e43cb","b20b76341c88435e93cfb55be6db267d","908a27bf3a224fc78b16e32f39357077","650d4529abaf499d890920ea1b45e885","c8fc31f73d1b46e09fca2104fdfb4342","09de7cb0447443f1b559f9f4b9b163dd","52bbf05f863f49c188c602e1814bd318","1b9de06794db408a95a7657286350d18","dea2527bbab54a159da687316bb392e1","db39b22d1dec475883807ca832d07c22","e6d487c99ac74d4997c7d33d21cbf0e0","683e190121bd472fb0df27e67182f310","4a11ee6704c349b1b86783b09ae6b421","9c25030b8e5f426e827a6bab74069168","fe6f4246ea014b0da5632f99e3d5b160","0c4788cfc78d44e28e23906d61b633fd","a4c9884ad7a548d3ad460a8548371f5b","5973ac594dd243d8b13b68d45216a6cb","5078acafeb7243f48fa1b7e499527231","0b75c54463a04eb2bc9d08d0185ec397","246eaaa374e143009a679d56c273407d","458023ddb89844b1a24bf1ba2b9ff3cd","61453188eefa4c22beedc198c106d2e6","c1ac05d4bd1a40d5913d6b63f5f3f911","5686130aa56d40cb95a58c3791617665","e1a1b059663a4e9aaf37f217cad6b82e","a08cdd975d554e288c7ff1a6719495dc","6877eaf4fcab4e239e8f43867f1f31bf","54a68a71f7d14d818ef308ff5a82323d","49bc6eccbb0d47998cc96c3986b77a2b","0bd623318a154221aad1964728fae0d4","fd87d09e29e4422db4f608d03164383e","cdeae6bec38249c2b75e4391486323e5","22f4120566204891a06730a408e9e4e7","0eacbb1b358b480996aaaed275e18b1a","a6ca46035f464d54838588600f4ab17f","633ec8eafed348b48702d9c40491172b","3b5658c32f6a4362b4ed12d9ac1e600c","500e493d01674c2dbf7711b0a9df07fc","daf324a40fc64fc58369ef0a9f377d14","c6e1b779df0f4114b97f4fc747cbdfc4","f865e387e19b4aebbb76fac51a496a99","47a0626df85b42e6893a06ce47aa533a","7fb64911dc604cf4af6f6a8298ffe24b","060132e2fb8d4fc4a4f56d1f3651f46e","6495dc51a99747fcad76c3a4af680203","851956fda83c4e148fc32cfd4d431f6b","bbf3a1c63b8f446c828e75ea5a8b2ead","3957f9c3e9dc4afe83efc93dd98a8d65","64b285f7a8c4459ea96682f9bdc76638","8effd8e67f0141d68734241dfcdc32ab","44612bb34c594a4da62ab52ff97865d2","4e21a36da1914e9883de7fcf560140c5","deffbfac9e864783810ee41235e41ace","405c39fb35c643f0a0139f48df77927f","4c8b701a1f3743dbb971db3028db9924","192eeac39fb3464bb2e59b1b6d7f3655","5da94cf5666c4ae9ba1cfa267ff685ff","650013b34c134e208a28da9f46c11134","851d729355214e8c9ae046f98c148b1f","a755bee598644e98bb9efe910c875faa","4b630c4ef5fb4a3dab5183d147c4abbe","fe8deda93a8042beb35496356ee23d9b","5c8d5537771e4f6f85901f37dbe1b141","c4a8caf91bb54542867e63b00e628e15","5254077986644ea7bb99b443681650f6","fcd35ba3f2304654b1a27a8fe55327bc","1dc5b883a47546b08bc7baa5bc06ffaa","839252214fc64cab94b05e164468b62a","d0dba8bc7b4d42648d8300568dfd5858","ff0a19562984485ebc8a84e34d53db58","f17a05eb1255433e9eb8bc5517fbed8b","871d5256f77247cfaf11d336a2af37ee","61b8bc94a6234e868b15d005c5fe141b","abd19ca49d8849af8e5585083eb735f2","706ef279f3f44c2c9c0f88636318ac3f","8dc6ae313ecf496fa73df2077dc5c9ba","1804d66f5c5d4b05b7d710568621ecee","d02fc3cedd22478286bd5a53e5c79bfb","957e4c8a4cc44e4ab753324a59aabb3b","f33efc6d211e4c3eb86f93a5f1d2344f","61dc840f02fc4fa081363f7088454377","40651dea98bc4c16903d233114caff09","fbf96ace8d844be5bbe94c1ae7ddbf23","f26008c6ed434fd3a55bdd553bb081b3","3c11dcda16a443b880a5130064346a06","793369b7a26649248f3f3bf5d30cc8a5","9d38847375c543b2abf864b7cb99757b","0f36d14c9a394c7ab27e5deb595d5ff8","580558092e3845799c4b176b2f2892af","b265fa8a542f4fd3b0776a74653e9bc4","cb44213b76c841449898661ac3332d89","e5107ad75c6541b1808778fe02ada8fc","c78d3be0459e4d31a18184660ddf9d78","f35fa2ceebc14621acece4cad9cd759c","dd09a28442b44ba59aa0597218aebbf8","06552821300b420998ec15a557c951d5","adb0657221124855a53f39d06108fc22","4dd505bc9b2a4f37a54fada45c101b68","b3f63c699ebd470db7d0443d3ae3d877","49bcf16e263c4430a6ebf0a9b9f1748f","28fee7854c224485b5c2344bee656a3d","d993e77f93104968b7642da7399fa833","01507ddf2b514a00ab4457b4a920bb92","1fe93307a89443159be5d46a442d7ce8","e42dc92d498343e0a12dd3786009e1bc","a140681c7c75410bbf5ef08a67208cc3","33faa60f253f4793bdd39ef1c4a4a47b","9cb571cf399149aa874557ffa9de6bc4","ec34afa25d6e4594a8e977243250453a","e285c64d702d48b580cd0464c8011579","7e4d58fca5e344999276f656bebca6cd","a24f6a8b368b44e5a0ba0cad07c9a2ab","bcc2beb2ec7e4d399ebf93910a57737d","f28934c4827f4c629f795208ca8e80ec","4ff89157613b43ab831fd22f59e50055","a0e8b0a9ed8f4f56b5c6d4aa2fa3a9ad","8bb283d10c2e400184dabe235d8bcb9d","96cf79e826ba4870aed1a33ceb32f5a6","43864c38b4ec442e88f9f2628bc9d8af","f81fb0cb81194408a7d82178a8fd4288","169d539f49384e9c80f5354964a870b4","fef03503c1484c53aee0ef96ea9eb72e","747b2eaa675a4e9f8c1946d43e16f33e","91eba61f46b247b7acff989866e5aa25","f584accea784454d921ef41fae9dbba7","907904e733224716a117bd347fb284b2","1957bc9b524b4b29813c810f2a57aa58","6f7bbc3fbea048eda2a072d3deffd1d0","a0c346bff1ff4081b40ed41cba947cf1","0b3f15dd1bcb4080abdbece99109c963","3f72f7a0701d48deb9f27ccfba0f53ff","8730fe3280324a418c032e8afa2a7f6b","591943304a4f41ed88e9bbd0f9c9b2e2","2f2fdf8897b742849b88863d01ab64a6","69d3e434124a441fb498d3cf58bef8e7","a645ddca20fd4d7096884871c6b49d19","9c597b1db6e3474e959405146ed1961a","bcc81e8979f440f1bfd34da9861ec1e6","a5e52ee93afc41fb92b9a3fce470e54d","c2e96a4834b5488d942902c33a59d404","12be426a05ae4e98a91a59efe1e0d075","a0dc1e3abca34d6da926a918cf5fac3f","c3646debe46849c1bc04dbfbcc2e739f","f1aa8c5b421246c0865d26f1f5a519eb","47031139f33c4e75af8dd90d995f5f18","479a1437bc7a427ba6737488a5472ea1","4ff2c246ff684917903a83b5817d1378","e695dbc7f88b4bb1b5a6d2e29738f40c","e94c071565de4a4bbe42d33997f7964d","15dc4916231446a4946db059f5056a31","d55eb2c094ca42479e8f261d18079521","d42dc1e1a8bd4915bf00fbd1ac879b9f","927da39162fa451f85cda7c2cf1b520b","b25039b8134647dfba3247b06428cd09","7326d4fe35e84f41bfd9abd674462d6d","0086dd5cf1aa4777b04f1f661b48e07a","a7335a3b8fa24a4ca0d55e5012696089","3a84b2e779b44bbd86c3946130793e13","2e47670255994deda4d23bb2f77e4975","84e332d47bb44c3484317ae2cb5a9026","3c5f457e07384e778f6fdbc5a999e64d","daef9aa494594912b8ae8a5ebe27bd85","444e9835dcaf4ea696e7029f2b2f0264","c951573c8f344cefb079226b6d75993b","d541be76ed384d6d88cd3e957bb10512","0d875d6c78734686a2663af216f4a2ed","065ae366b2ed41469e3201fc14525234","a22dfdaec5994aae82f91bfef357ca61","4b600b216c3f4cad8040a2d021426b49","3db8f7c27c3941f491ba091d604944de","6f86609bb0d642d986952bb331ce0967","1b5d24537c06477a9bf84a2627ac0f48","acf427477e314e969060af57bbb5c5ae","a1964889e0c743c8b12e48f0f0252da0","1829c7417dd34906975c554ffd0733ab","b394f4f7467d4169bdc2ba39bc09515f","994901efbeaf4f70b1e9eaa324fe0fa2","9d78da13bc7a49aa89cde9a6402bc6a8","ebb4ab1d21d74df9b99dcf8cf2c352dc","d06ab0404e8d494ca0e2b4de0ba66e9f"]},"executionInfo":{"status":"ok","timestamp":1749929667425,"user_tz":-60,"elapsed":960145,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"17f2dd8c-45b2-4935-83ba-1b0b6be98c70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------------------------+\n","| Configuration for experiment     _train_tune_2025-06-14_19-18-22   |\n","+--------------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator                   |\n","| Scheduler                        FIFOScheduler                     |\n","| Number of trials                 20                                |\n","+--------------------------------------------------------------------+\n","\n","View detailed results here: /root/ray_results/_train_tune_2025-06-14_19-18-22\n","To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-14_19-03-27_020465_1199/artifacts/2025-06-14_19-18-22/_train_tune_2025-06-14_19-18-22/driver_artifacts`\n","\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (13 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=8786)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=8786)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=8786)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=8786)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=8786)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=8786)\u001b[0m 2025-06-14 19:18:34.026493: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=8786)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=8786)\u001b[0m E0000 00:00:1749928714.050416    8872 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=8786)\u001b[0m E0000 00:00:1749928714.058921    8872 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=8786)\u001b[0m 2025-06-14 19:18:34.082654: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=8786)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=8786)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=8786)\u001b[0m \n","\u001b[36m(_train_tune pid=8786)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=8786)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8786)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=8786)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=8786)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=8786)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=8786)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8786)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=8786)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=8786)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=8786)\u001b[0m 10.286    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=8786)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=8786)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.210]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=1.580]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.540]\n","Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 53.93it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.540]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.480]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.320]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.250]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.210]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8786)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 187.37it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.210, valid_loss=1.140]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.140, valid_loss=1.140]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.150, valid_loss=1.140]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=1.090, valid_loss=1.140]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=1.070, valid_loss=1.140]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.070, valid_loss=1.140]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.090, valid_loss=1.140]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=1.060, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 196.01it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 15: 100%|██████████| 7/7 [00:00<00:00, 54.73it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 54.20it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=1.050, valid_loss=1.040]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8786)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 187.51it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.725, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.080, valid_loss=1.020]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=1.080, valid_loss=1.020]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=1.050, valid_loss=1.020]\n","\u001b[36m(_train_tune pid=8786)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.88it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.030, valid_loss=1.040]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.030, valid_loss=1.040]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=1.030, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=8786)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 205.25it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8786)\u001b[0m \n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=1.050, valid_loss=1.010]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.040, valid_loss=1.010]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=1.070, valid_loss=1.010]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.020, valid_loss=1.010]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.040, valid_loss=1.010]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=1.060, valid_loss=1.010]\n","Epoch 41: 100%|██████████| 7/7 [00:00<00:00, 53.87it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=1.060, valid_loss=1.010]\n","Epoch 41: 100%|██████████| 7/7 [00:00<00:00, 52.03it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.040, valid_loss=1.010]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.040, valid_loss=1.010]\n","\u001b[36m(_train_tune pid=8786)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 190.94it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 52.13it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=1.060, valid_loss=1.020]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.26it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=1.000, valid_loss=1.010]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.030, valid_loss=1.010]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.060, valid_loss=1.010]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=1.020, valid_loss=1.010]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=1.050, valid_loss=1.010]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.020, valid_loss=1.010]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.050, valid_loss=1.010]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.060, valid_loss=1.010]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8786)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 179.07it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.000, valid_loss=1.020]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=1.020]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=1.040, valid_loss=1.020]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:18:47,170\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=8786)\u001b[0m \n","\u001b[36m(_train_tune pid=8786)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8786)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8786)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8786)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.57it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8786)\u001b[0m \r                                                                       \u001b[A\rEpoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.040, valid_loss=1.010]\rEpoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.040, valid_loss=1.010]\rEpoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.040, valid_loss=1.010]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=8938)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=8938)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=8938)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=8938)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=8938)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=8938)\u001b[0m 2025-06-14 19:18:57.614546: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=8938)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=8938)\u001b[0m E0000 00:00:1749928737.640923    9022 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=8938)\u001b[0m E0000 00:00:1749928737.648427    9022 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=8938)\u001b[0m 2025-06-14 19:18:57.676320: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=8938)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=8938)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \n","\u001b[36m(_train_tune pid=8938)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=8938)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8938)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=8938)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=8938)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=8938)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=8938)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=8938)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=8938)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=8938)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=8938)\u001b[0m 10.286    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=8938)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=8938)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.770]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.440]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.300]\n","Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 52.21it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.300]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.160]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.140]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.110]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.070]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 140.41it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=1.040, valid_loss=1.050]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.080, valid_loss=1.050]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.070, valid_loss=1.050]\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 148.98it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 14: 100%|██████████| 7/7 [00:00<00:00, 31.78it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.080, valid_loss=1.050]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=1.030, valid_loss=1.050]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.030, valid_loss=1.050]\n","Epoch 20: 100%|██████████| 7/7 [00:00<00:00, 44.57it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.050, valid_loss=1.050]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 114.33it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.100, valid_loss=1.040]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.030, valid_loss=1.040]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.060, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 171.87it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.030, valid_loss=1.040]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.030, valid_loss=1.040]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.020, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.49it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=1.020, valid_loss=1.010]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.050, valid_loss=1.010]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=1.020, valid_loss=1.010]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=1.050, valid_loss=1.010]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=1.030, valid_loss=1.010]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=1.030, valid_loss=1.010]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.040, valid_loss=1.010]\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 198.55it/s]\u001b[A\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.040, valid_loss=1.010]\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.030, valid_loss=1.010]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.730, train_loss_epoch=1.040, valid_loss=1.010]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.060, valid_loss=1.010]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.040, valid_loss=1.010]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.080, valid_loss=1.010]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=1.020, valid_loss=1.010]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.020, valid_loss=1.010]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 53.19it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=1.020, valid_loss=1.010]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 187.57it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=1.020, valid_loss=1.020]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.000, valid_loss=1.020]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.020, valid_loss=1.020]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.020, valid_loss=1.020]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:19:09,484\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=8938)\u001b[0m \rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 54.51it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.020, valid_loss=1.020]\rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 52.83it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=1.020, valid_loss=1.020]\rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 52.62it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=1.020, valid_loss=1.020]\rEpoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=1.020, valid_loss=1.020]        \rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=1.020, valid_loss=1.020]\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.03it/s]\u001b[A\n","\u001b[36m(_train_tune pid=8938)\u001b[0m \r                                                                       \u001b[A\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.020, valid_loss=1.020]\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.020]\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.020]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=9087)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=9087)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=9087)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=9087)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=9087)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=9087)\u001b[0m 2025-06-14 19:19:20.673585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=9087)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=9087)\u001b[0m E0000 00:00:1749928760.696731    9171 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=9087)\u001b[0m E0000 00:00:1749928760.703855    9171 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=9087)\u001b[0m 2025-06-14 19:19:20.731257: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=9087)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=9087)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","\u001b[36m(_train_tune pid=9087)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=9087)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=9087)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=9087)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=9087)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=9087)\u001b[0m 3 | blocks       | ModuleList    | 2.7 M  | train\n","\u001b[36m(_train_tune pid=9087)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=9087)\u001b[0m 2.7 M     Trainable params\n","\u001b[36m(_train_tune pid=9087)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=9087)\u001b[0m 2.7 M     Total params\n","\u001b[36m(_train_tune pid=9087)\u001b[0m 10.840    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=9087)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=9087)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.680]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.620]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=2.530]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.450]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.340]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.250]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=2.050]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.68it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=2.050, valid_loss=2.220]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.850, valid_loss=2.220]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.730, valid_loss=2.220]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.610, valid_loss=2.220]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.650, valid_loss=2.220]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=1.600, valid_loss=2.220]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.560, valid_loss=2.220]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.540, valid_loss=2.220]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 183.16it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=1.540, valid_loss=1.630]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.530, valid_loss=1.630]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.470, valid_loss=1.630]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.500, valid_loss=1.630]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.540, valid_loss=1.630]\n","Epoch 18: 100%|██████████| 7/7 [00:00<00:00, 47.72it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.480, valid_loss=1.630]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.480, valid_loss=1.630]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.470, valid_loss=1.630]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.410, valid_loss=1.630]\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.92it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.410, valid_loss=1.470]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.410, valid_loss=1.470]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.390, valid_loss=1.470]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.330, valid_loss=1.470]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.300, valid_loss=1.470]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.240, valid_loss=1.470]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=1.240, valid_loss=1.470]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.210, valid_loss=1.470]\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 150.62it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.210, valid_loss=1.210]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.190, valid_loss=1.210]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.190, valid_loss=1.210]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.160, valid_loss=1.210]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=1.170, valid_loss=1.210]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.160, valid_loss=1.210]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.120, valid_loss=1.210]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.140, valid_loss=1.210]\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 136.55it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.140, valid_loss=1.110]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=1.110]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.140, valid_loss=1.110]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=1.080, valid_loss=1.110]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.100, valid_loss=1.110]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.120, valid_loss=1.110]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.130, valid_loss=1.110]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=1.090, valid_loss=1.110]\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 127.61it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.120, valid_loss=1.070]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=1.100, valid_loss=1.070]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.110, valid_loss=1.070]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.090, valid_loss=1.070]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.100, valid_loss=1.070]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.070, valid_loss=1.070]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=1.100, valid_loss=1.070]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 48.51it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=1.100, valid_loss=1.070]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 205.16it/s]\u001b[A\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=1.090, valid_loss=1.060]        \n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=1.090, valid_loss=1.060]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=1.080, valid_loss=1.060]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.050, valid_loss=1.060]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.090, valid_loss=1.060]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.070, valid_loss=1.060]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 191.36it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.100, valid_loss=1.050]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.080, valid_loss=1.050]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.050]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.29it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=1.080, valid_loss=1.050]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.120, valid_loss=1.050]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.080, valid_loss=1.050]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.050, valid_loss=1.050]\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 193.54it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.080, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.75it/s]\u001b[A\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 82:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=1.050, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 174.42it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.060, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 176.32it/s]\u001b[A\n","Epoch 93:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 94:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 95:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.110, valid_loss=1.040]\n","Epoch 96:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 97:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 98:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 99:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 99: 100%|██████████| 7/7 [00:00<00:00, 48.05it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=1.060, valid_loss=1.040]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.69it/s]\u001b[A\n","Epoch 100:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 101:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 102:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 103:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.100, valid_loss=1.030]\n","Epoch 104:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=1.080, valid_loss=1.030]\n","Epoch 105:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 106:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=1.040, valid_loss=1.030]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 213.32it/s]\u001b[A\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 108:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 109:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 110:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.030, valid_loss=1.030]\n","Epoch 111:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.858, train_loss_epoch=1.080, valid_loss=1.030]\n","Epoch 112:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=1.040, valid_loss=1.030]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 119.27it/s]\u001b[A\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 115:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.120, valid_loss=1.030]\n","Epoch 116:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.080, valid_loss=1.030]\n","Epoch 117:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 118:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 119:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.080, valid_loss=1.030]\n","Epoch 120:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.080, valid_loss=1.030]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:19:43,556\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=9087)\u001b[0m \rEpoch 120: 100%|██████████| 7/7 [00:00<00:00, 37.79it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.080, valid_loss=1.030]\rEpoch 120: 100%|██████████| 7/7 [00:00<00:00, 37.31it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.080, valid_loss=1.030]\rEpoch 120: 100%|██████████| 7/7 [00:00<00:00, 37.16it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.080, valid_loss=1.030]\rEpoch 120:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.080, valid_loss=1.030]        \rEpoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.080, valid_loss=1.030]\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \n","\u001b[36m(_train_tune pid=9087)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 134.91it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9087)\u001b[0m \r                                                                       \u001b[A\rEpoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.080, valid_loss=1.030]\rEpoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.060, valid_loss=1.030]\rEpoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.060, valid_loss=1.030]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=9282)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=9282)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=9282)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=9282)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=9282)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=9282)\u001b[0m 2025-06-14 19:19:54.410351: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=9282)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=9282)\u001b[0m E0000 00:00:1749928794.447478    9361 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=9282)\u001b[0m E0000 00:00:1749928794.458932    9361 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=9282)\u001b[0m 2025-06-14 19:19:54.500874: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=9282)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=9282)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=9282)\u001b[0m \n","\u001b[36m(_train_tune pid=9282)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=9282)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=9282)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=9282)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=9282)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=9282)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=9282)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=9282)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=9282)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=9282)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=9282)\u001b[0m 10.297    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=9282)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=9282)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+3, train_loss_epoch=3.54e+10]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=5.550]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=9.220]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.470, train_loss_epoch=7.100]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.180, train_loss_epoch=3.760]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.790, train_loss_epoch=4.880]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.530, train_loss_epoch=3.120]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9282)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 152.27it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.370, train_loss_epoch=3.120, valid_loss=4.960]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.510, train_loss_epoch=5.990, valid_loss=4.960]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.350, train_loss_epoch=6.240, valid_loss=4.960]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.700, train_loss_epoch=4.630, valid_loss=4.960]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.460, train_loss_epoch=3.890, valid_loss=4.960]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.590, train_loss_epoch=2.840, valid_loss=4.960]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=2.820, valid_loss=4.960]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=2.240, valid_loss=4.960]\n","\u001b[36m(_train_tune pid=9282)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 215.46it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=2.240, valid_loss=1.800]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.820, valid_loss=1.800]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=1.760, valid_loss=1.800]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=1.960, valid_loss=1.800]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.770, valid_loss=1.800]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.710, valid_loss=1.800]\n","Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 53.74it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.710, valid_loss=1.800]\n","Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 52.14it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.710, valid_loss=1.800]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.700, valid_loss=1.800]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.650, valid_loss=1.800]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9282)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 192.48it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.690, valid_loss=1.720]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=1.630, valid_loss=1.720]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.570, valid_loss=1.720]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.620, valid_loss=1.720]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.060, valid_loss=1.720]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.400, train_loss_epoch=4.800, valid_loss=1.720]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=4.660, valid_loss=1.720]\n","\u001b[36m(_train_tune pid=9282)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 214.37it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.110, train_loss_epoch=4.660, valid_loss=2.750]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=3.180, valid_loss=2.750]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=3.220, valid_loss=2.750]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.320, valid_loss=2.750]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=2.120, valid_loss=2.750]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=2.510, valid_loss=2.750]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=2.350, valid_loss=2.750]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:20:03,435\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=9282)\u001b[0m \rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 55.52it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=2.350, valid_loss=2.750]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 53.49it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=2.350, valid_loss=2.750]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 53.30it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=2.240, valid_loss=2.750]\rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=2.240, valid_loss=2.750]        \rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=2.240, valid_loss=2.750]\n","\u001b[36m(_train_tune pid=9282)\u001b[0m \n","\u001b[36m(_train_tune pid=9282)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9282)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9282)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9282)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.98it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9282)\u001b[0m \r                                                                       \u001b[A\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=2.240, valid_loss=1.820]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=2.050, valid_loss=1.820]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=2.050, valid_loss=1.820]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=9416)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=9416)\u001b[0m Seed set to 3\n","\u001b[36m(_train_tune pid=9416)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=9416)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=9416)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=9416)\u001b[0m 2025-06-14 19:20:14.445987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=9416)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=9416)\u001b[0m E0000 00:00:1749928814.472192    9496 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=9416)\u001b[0m E0000 00:00:1749928814.481547    9496 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=9416)\u001b[0m 2025-06-14 19:20:14.509136: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=9416)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=9416)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \n","\u001b[36m(_train_tune pid=9416)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=9416)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=9416)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=9416)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=9416)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=9416)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=9416)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=9416)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=9416)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=9416)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=9416)\u001b[0m 10.286    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=9416)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=9416)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=9416)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","                                                                           \n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=2.460]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.150]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.800]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.590]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.580]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.520]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.550]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 176.51it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.550, valid_loss=1.570]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.470, valid_loss=1.570]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.410, valid_loss=1.570]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.390, valid_loss=1.570]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.350, valid_loss=1.570]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.270, valid_loss=1.570]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=1.230, valid_loss=1.570]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.170, valid_loss=1.570]\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.69it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=1.170, valid_loss=1.160]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.190, valid_loss=1.160]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=1.140, valid_loss=1.160]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.120, valid_loss=1.160]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.110, valid_loss=1.160]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.080, valid_loss=1.160]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.110, valid_loss=1.160]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.100, valid_loss=1.160]\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 144.41it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=1.100, valid_loss=1.060]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.110, valid_loss=1.060]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.100, valid_loss=1.060]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=1.040, valid_loss=1.060]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 26: 100%|██████████| 7/7 [00:00<00:00, 47.10it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.080, valid_loss=1.060]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.070, valid_loss=1.060]\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 160.57it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=1.040, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 113.22it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.080, valid_loss=1.030]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=1.030, valid_loss=1.030]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.070, valid_loss=1.030]\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 182.28it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.020, valid_loss=1.030]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=1.030, valid_loss=1.030]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 53.58it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 52.00it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=1.060, valid_loss=1.030]\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 189.86it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.020, valid_loss=1.020]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=1.020, valid_loss=1.020]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.060, valid_loss=1.020]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.25it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=1.010, valid_loss=1.020]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:20:27,326\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=9416)\u001b[0m \rEpoch 62: 100%|██████████| 7/7 [00:00<00:00, 53.06it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=1.010, valid_loss=1.020]\rEpoch 62: 100%|██████████| 7/7 [00:00<00:00, 52.00it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.010, valid_loss=1.020]\rEpoch 62: 100%|██████████| 7/7 [00:00<00:00, 51.74it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.060, valid_loss=1.020]\rEpoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.060, valid_loss=1.020]        \rEpoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.060, valid_loss=1.020]\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \rEpoch 63: 100%|██████████| 7/7 [00:00<00:00, 53.94it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.060, valid_loss=1.020]\rEpoch 63: 100%|██████████| 7/7 [00:00<00:00, 51.99it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=1.060, valid_loss=1.020]\rEpoch 63: 100%|██████████| 7/7 [00:00<00:00, 51.78it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=1.050, valid_loss=1.020]\rEpoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=1.050, valid_loss=1.020]        \rEpoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=1.050, valid_loss=1.020]\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9416)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 189.26it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.080, valid_loss=1.020]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=9566)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=9566)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=9566)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=9566)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=9566)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=9566)\u001b[0m 2025-06-14 19:20:39.248811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=9566)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=9566)\u001b[0m E0000 00:00:1749928839.272658    9652 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=9566)\u001b[0m E0000 00:00:1749928839.279950    9652 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=9566)\u001b[0m 2025-06-14 19:20:39.307707: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=9566)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=9566)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","\u001b[36m(_train_tune pid=9566)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=9566)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=9566)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=9566)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=9566)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=9566)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=9566)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=9566)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=9566)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=9566)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=9566)\u001b[0m 10.252    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=9566)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=9566)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=9566)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=108.0, train_loss_epoch=7.36e+10]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7e+3, train_loss_epoch=5.28e+3]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.3e+3, train_loss_epoch=1.57e+4]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=6.58e+3]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.49e+3, train_loss_epoch=3.13e+4]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=411.0, train_loss_epoch=1.82e+6]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=181.0, train_loss_epoch=126.0]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.40it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=166.0, train_loss_epoch=126.0, valid_loss=1.03e+4]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=124.0, train_loss_epoch=2.65e+7, valid_loss=1.03e+4]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=523.0, train_loss_epoch=1.75e+4, valid_loss=1.03e+4]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=745.0, train_loss_epoch=1.45e+4, valid_loss=1.03e+4]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=776.0, train_loss_epoch=1.15e+3, valid_loss=1.03e+4]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.45e+3, train_loss_epoch=1.72e+3, valid_loss=1.03e+4]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.65e+4, train_loss_epoch=2.71e+4, valid_loss=1.03e+4]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.45e+3, train_loss_epoch=2.34e+3, valid_loss=1.03e+4]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 167.73it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.69e+4, train_loss_epoch=2.34e+3, valid_loss=6.79e+3]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+4, train_loss_epoch=5.66e+6, valid_loss=6.79e+3]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.58e+3, train_loss_epoch=5.52e+3, valid_loss=6.79e+3]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+3, train_loss_epoch=2.02e+3, valid_loss=6.79e+3]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=334.0, train_loss_epoch=629.0, valid_loss=6.79e+3]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=209.0, train_loss_epoch=268.0, valid_loss=6.79e+3]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=95.90, train_loss_epoch=153.0, valid_loss=6.79e+3]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=99.90, train_loss_epoch=117.0, valid_loss=6.79e+3]\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 184.71it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=100.0, train_loss_epoch=117.0, valid_loss=75.60]  \n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=84.60, valid_loss=75.60]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=65.30, train_loss_epoch=71.20, valid_loss=75.60]\n","Epoch 23: 100%|██████████| 7/7 [00:00<00:00, 51.88it/s, v_num=0, train_loss_step=27.60, train_loss_epoch=71.20, valid_loss=75.60]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=27.60, train_loss_epoch=54.20, valid_loss=75.60]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=42.10, valid_loss=75.60]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=38.60, valid_loss=75.60]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=38.00, valid_loss=75.60]\n","Epoch 27: 100%|██████████| 7/7 [00:00<00:00, 54.81it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=38.00, valid_loss=75.60]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.160, train_loss_epoch=30.70, valid_loss=75.60]\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 163.01it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=31.50, train_loss_epoch=29.60, valid_loss=34.80]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=16.20, train_loss_epoch=25.60, valid_loss=34.80]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=21.10, valid_loss=34.80]\n","Epoch 31: 100%|██████████| 7/7 [00:00<00:00, 43.26it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=21.10, valid_loss=34.80]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=21.50, train_loss_epoch=21.40, valid_loss=34.80]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=19.70, train_loss_epoch=18.50, valid_loss=34.80]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=23.60, train_loss_epoch=19.60, valid_loss=34.80]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=21.80, train_loss_epoch=23.60, valid_loss=34.80]\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 158.73it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=23.60, valid_loss=31.90]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.640, train_loss_epoch=17.10, valid_loss=31.90]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=24.00, valid_loss=31.90]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=22.30, train_loss_epoch=23.90, valid_loss=31.90]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=17.00, valid_loss=31.90]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=20.70, train_loss_epoch=14.30, valid_loss=31.90]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.100, train_loss_epoch=12.50, valid_loss=31.90]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.150, train_loss_epoch=8.950, valid_loss=31.90]\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 99.94it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.950, train_loss_epoch=8.580, valid_loss=9.260]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.950, train_loss_epoch=8.290, valid_loss=9.260]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.530, train_loss_epoch=7.260, valid_loss=9.260]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.640, train_loss_epoch=7.610, valid_loss=9.260]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.680, train_loss_epoch=7.560, valid_loss=9.260]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.000, train_loss_epoch=7.040, valid_loss=9.260]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=7.300, valid_loss=9.260]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 53.18it/s, v_num=0, train_loss_step=4.360, train_loss_epoch=7.300, valid_loss=9.260]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 176.61it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.360, train_loss_epoch=5.690, valid_loss=9.400]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.130, train_loss_epoch=5.860, valid_loss=9.400]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.420, train_loss_epoch=6.270, valid_loss=9.400]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.790, train_loss_epoch=5.430, valid_loss=9.400]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=5.580, valid_loss=9.400]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.300, train_loss_epoch=5.860, valid_loss=9.400]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.870, train_loss_epoch=6.000, valid_loss=9.400]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.610, train_loss_epoch=6.200, valid_loss=9.400]\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 212.09it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.550, train_loss_epoch=6.200, valid_loss=7.740]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.840, train_loss_epoch=5.810, valid_loss=7.740]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.040, train_loss_epoch=6.150, valid_loss=7.740]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=6.110, valid_loss=7.740]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.870, train_loss_epoch=7.870, valid_loss=7.740]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.140, train_loss_epoch=7.200, valid_loss=7.740]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=5.780, valid_loss=7.740]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=5.240, valid_loss=7.740]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 204.68it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.780, train_loss_epoch=5.240, valid_loss=6.350]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=5.210, valid_loss=6.350]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.490, train_loss_epoch=5.330, valid_loss=6.350]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.290, train_loss_epoch=5.810, valid_loss=6.350]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.960, train_loss_epoch=5.700, valid_loss=6.350]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.920, train_loss_epoch=6.760, valid_loss=6.350]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=6.340, valid_loss=6.350]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=5.360, valid_loss=6.350]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 177.94it/s]\u001b[A\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.790, train_loss_epoch=5.350, valid_loss=7.110]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.470, train_loss_epoch=5.460, valid_loss=7.110]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.240, train_loss_epoch=5.300, valid_loss=7.110]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.500, train_loss_epoch=5.380, valid_loss=7.110]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.330, train_loss_epoch=5.180, valid_loss=7.110]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.350, train_loss_epoch=5.610, valid_loss=7.110]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.310, train_loss_epoch=6.290, valid_loss=7.110]\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.23it/s]\u001b[A\n","Epoch 78: 100%|██████████| 7/7 [00:00<00:00, 40.54it/s, v_num=0, train_loss_step=4.150, train_loss_epoch=6.290, valid_loss=6.000]\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.640, train_loss_epoch=6.290, valid_loss=6.000]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.590, valid_loss=6.000]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.100, train_loss_epoch=6.020, valid_loss=6.000]\n","Epoch 82:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.470, train_loss_epoch=6.240, valid_loss=6.000]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=5.050, valid_loss=6.000]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=6.160, valid_loss=6.000]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.570, train_loss_epoch=5.300, valid_loss=6.000]\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 206.10it/s]\u001b[A\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.990, train_loss_epoch=5.300, valid_loss=6.990]\n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.530, train_loss_epoch=5.050, valid_loss=6.990]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.340, train_loss_epoch=5.150, valid_loss=6.990]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=5.500, valid_loss=6.990]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.490, train_loss_epoch=5.500, valid_loss=6.990]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=5.480, valid_loss=6.990]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=4.820, valid_loss=6.990]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:20:56,113\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=9566)\u001b[0m \rEpoch 91: 100%|██████████| 7/7 [00:00<00:00, 55.74it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=4.820, valid_loss=6.990]\rEpoch 91: 100%|██████████| 7/7 [00:00<00:00, 53.61it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=4.820, valid_loss=6.990]\rEpoch 91: 100%|██████████| 7/7 [00:00<00:00, 53.39it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=4.840, valid_loss=6.990]\rEpoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=4.840, valid_loss=6.990]        \rEpoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=4.840, valid_loss=6.990]\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","\u001b[36m(_train_tune pid=9566)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9566)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 185.05it/s]\u001b[A\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.550, train_loss_epoch=4.490, valid_loss=6.450]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=9732)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=9732)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=9732)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=9732)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=9732)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=9732)\u001b[0m 2025-06-14 19:21:06.538549: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=9732)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=9732)\u001b[0m E0000 00:00:1749928866.563274    9817 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=9732)\u001b[0m E0000 00:00:1749928866.570441    9817 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=9732)\u001b[0m 2025-06-14 19:21:06.597993: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=9732)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=9732)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=9732)\u001b[0m \n","\u001b[36m(_train_tune pid=9732)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=9732)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=9732)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=9732)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=9732)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=9732)\u001b[0m 3 | blocks       | ModuleList    | 2.7 M  | train\n","\u001b[36m(_train_tune pid=9732)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=9732)\u001b[0m 2.7 M     Trainable params\n","\u001b[36m(_train_tune pid=9732)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=9732)\u001b[0m 2.7 M     Total params\n","\u001b[36m(_train_tune pid=9732)\u001b[0m 10.840    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=9732)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=9732)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.28e+6, train_loss_epoch=2.25e+8]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=62.90, train_loss_epoch=1.12e+4]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=32.80, train_loss_epoch=43.30]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=23.20]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.020, train_loss_epoch=9.730]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.910, train_loss_epoch=5.570]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=4.300]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9732)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 183.50it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.730, train_loss_epoch=4.300, valid_loss=3.770]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=93.30, train_loss_epoch=16.50, valid_loss=3.770]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=145.0, train_loss_epoch=855.0, valid_loss=3.770]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=120.0, train_loss_epoch=108.0, valid_loss=3.770]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=157.0, train_loss_epoch=138.0, valid_loss=3.770]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=201.0, train_loss_epoch=100.0, valid_loss=3.770]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=86.50, train_loss_epoch=101.0, valid_loss=3.770]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=59.70, train_loss_epoch=82.90, valid_loss=3.770]\n","\u001b[36m(_train_tune pid=9732)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 205.96it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=79.10, train_loss_epoch=82.90, valid_loss=79.20]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=68.70, train_loss_epoch=75.10, valid_loss=79.20]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=47.90, train_loss_epoch=51.90, valid_loss=79.20]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=44.20, valid_loss=79.20]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=32.90, train_loss_epoch=40.40, valid_loss=79.20]\n","Epoch 18: 100%|██████████| 7/7 [00:00<00:00, 50.16it/s, v_num=0, train_loss_step=32.90, train_loss_epoch=40.40, valid_loss=79.20]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=37.00, train_loss_epoch=36.60, valid_loss=79.20]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=34.20, train_loss_epoch=38.70, valid_loss=79.20]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=26.10, train_loss_epoch=31.40, valid_loss=79.20]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:21:13,100\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=9732)\u001b[0m \n","\u001b[36m(_train_tune pid=9732)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9732)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9732)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9732)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 184.30it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9732)\u001b[0m \r                                                                       \u001b[A\rEpoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=24.50, train_loss_epoch=31.40, valid_loss=28.30]\rEpoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=24.50, train_loss_epoch=28.20, valid_loss=28.30]\rEpoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=24.50, train_loss_epoch=28.20, valid_loss=28.30]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=9853)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=9853)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=9853)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=9853)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=9853)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=9853)\u001b[0m 2025-06-14 19:21:24.864012: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=9853)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=9853)\u001b[0m E0000 00:00:1749928884.884083    9941 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=9853)\u001b[0m E0000 00:00:1749928884.890194    9941 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=9853)\u001b[0m 2025-06-14 19:21:24.914775: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=9853)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=9853)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \n","\u001b[36m(_train_tune pid=9853)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=9853)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=9853)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=9853)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=9853)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=9853)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=9853)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=9853)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=9853)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=9853)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=9853)\u001b[0m 10.252    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=9853)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=9853)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.890]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.590]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.510]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.380]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.220]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.180]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=1.130]\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 114.96it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=1.130, valid_loss=1.080]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.120, valid_loss=1.080]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.090, valid_loss=1.080]\n","Epoch 9: 100%|██████████| 7/7 [00:00<00:00, 51.45it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.080, valid_loss=1.080]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.080, valid_loss=1.080]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.090, valid_loss=1.080]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.110, valid_loss=1.080]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=1.060, valid_loss=1.080]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.765, train_loss_epoch=1.060, valid_loss=1.080]\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 208.34it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.080, valid_loss=1.050]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.891, train_loss_epoch=1.040, valid_loss=1.050]\n","Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 46.52it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=1.040, valid_loss=1.050]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=1.030, valid_loss=1.050]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 188.84it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.100, valid_loss=1.060]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.080, valid_loss=1.060]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.030, valid_loss=1.060]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.050, valid_loss=1.060]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.050, valid_loss=1.060]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.080, valid_loss=1.060]\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.83it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.080, valid_loss=1.050]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.040, valid_loss=1.050]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=1.040, valid_loss=1.050]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=1.070, valid_loss=1.050]\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 180.82it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.080, valid_loss=1.060]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.100, valid_loss=1.060]\n","Epoch 37: 100%|██████████| 7/7 [00:00<00:00, 48.65it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=1.040, valid_loss=1.060]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.050, valid_loss=1.060]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.060]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=1.040, valid_loss=1.060]\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 205.61it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 43: 100%|██████████| 7/7 [00:00<00:00, 55.15it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 53.39it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=1.030, valid_loss=1.020]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 206.46it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=1.020, valid_loss=1.040]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=1.000, valid_loss=1.040]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.030, valid_loss=1.040]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=1.030, valid_loss=1.040]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=1.020, valid_loss=1.040]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:21:36,851\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=9853)\u001b[0m \rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 55.18it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=1.020, valid_loss=1.040]\rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 53.30it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.020, valid_loss=1.040]\rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 53.10it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.030, valid_loss=1.040]\rEpoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.030, valid_loss=1.040]        \rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.030, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \n","\u001b[36m(_train_tune pid=9853)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 183.41it/s]\u001b[A\n","\u001b[36m(_train_tune pid=9853)\u001b[0m \r                                                                       \u001b[A\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=1.030, valid_loss=1.030]\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=1.030]\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=1.030]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=10005)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=10005)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=10005)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=10005)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=10005)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=10005)\u001b[0m 2025-06-14 19:21:47.588875: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=10005)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=10005)\u001b[0m E0000 00:00:1749928907.615614   10089 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=10005)\u001b[0m E0000 00:00:1749928907.623992   10089 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=10005)\u001b[0m 2025-06-14 19:21:47.650955: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=10005)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=10005)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \n","\u001b[36m(_train_tune pid=10005)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=10005)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=10005)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=10005)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=10005)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=10005)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=10005)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=10005)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=10005)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=10005)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=10005)\u001b[0m 10.297    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=10005)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=10005)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=10005)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=1.940]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.440]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.280]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.180]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.140]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.120]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 183.51it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.110, valid_loss=1.060]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.090, valid_loss=1.060]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=1.050, valid_loss=1.060]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.050, valid_loss=1.060]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=1.040, valid_loss=1.060]\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 206.92it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 20: 100%|██████████| 7/7 [00:00<00:00, 46.49it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=1.030, valid_loss=1.040]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 130.77it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.865, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 26: 100%|██████████| 7/7 [00:00<00:00, 45.55it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=1.040, valid_loss=1.020]\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 147.61it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.030, valid_loss=1.030]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.030, valid_loss=1.030]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=1.030, valid_loss=1.030]\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 123.01it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.010, valid_loss=1.020]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.030, valid_loss=1.020]\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.80it/s]\u001b[A\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 42: 100%|██████████| 7/7 [00:00<00:00, 38.80it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 53.57it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=1.050, valid_loss=1.020]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 180.75it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.997, valid_loss=1.020]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=1.020, valid_loss=1.020]\n","Epoch 53: 100%|██████████| 7/7 [00:00<00:00, 54.67it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=1.020, valid_loss=1.020]\n","Epoch 53: 100%|██████████| 7/7 [00:00<00:00, 53.07it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=1.020, valid_loss=1.020]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.020, valid_loss=1.020]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.050, valid_loss=1.020]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 193.70it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=0.997, valid_loss=1.030]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=1.020, valid_loss=1.030]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.030, valid_loss=1.030]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.010, valid_loss=1.030]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=1.030, valid_loss=1.030]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:22:00,417\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=10005)\u001b[0m \n","\u001b[36m(_train_tune pid=10005)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.69it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10005)\u001b[0m \r                                                                       \u001b[A\rEpoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.030, valid_loss=1.020]\rEpoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.040, valid_loss=1.020]\rEpoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.040, valid_loss=1.020]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=10154)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=10154)\u001b[0m Seed set to 4\n","\u001b[36m(_train_tune pid=10154)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=10154)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=10154)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=10154)\u001b[0m 2025-06-14 19:22:11.604250: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=10154)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=10154)\u001b[0m E0000 00:00:1749928931.630934   10239 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=10154)\u001b[0m E0000 00:00:1749928931.638242   10239 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=10154)\u001b[0m 2025-06-14 19:22:11.662588: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=10154)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=10154)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \n","\u001b[36m(_train_tune pid=10154)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=10154)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=10154)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=10154)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=10154)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=10154)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=10154)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=10154)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=10154)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=10154)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=10154)\u001b[0m 10.262    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=10154)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=10154)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.27e+5, train_loss_epoch=1.83e+12]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.29e+6, train_loss_epoch=2.35e+9]\n","Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 49.71it/s, v_num=0, train_loss_step=2.33e+5, train_loss_epoch=2.4e+6] \n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+5, train_loss_epoch=2.4e+6]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.06e+5, train_loss_epoch=3.47e+5]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.29e+5, train_loss_epoch=3.68e+5]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+5, train_loss_epoch=2.69e+5]\n","Epoch 6: 100%|██████████| 7/7 [00:00<00:00, 51.95it/s, v_num=0, train_loss_step=2.79e+5, train_loss_epoch=2.69e+5]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+5, train_loss_epoch=3.18e+5]\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 188.75it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+5, train_loss_epoch=3.18e+5, valid_loss=2.48e+5]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.04e+4, train_loss_epoch=1.59e+5, valid_loss=2.48e+5]\n","Epoch 8: 100%|██████████| 7/7 [00:00<00:00, 51.66it/s, v_num=0, train_loss_step=5.34e+4, train_loss_epoch=5.57e+4, valid_loss=2.48e+5]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.34e+4, train_loss_epoch=5.57e+4, valid_loss=2.48e+5]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+4, train_loss_epoch=3.35e+4, valid_loss=2.48e+5]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.3e+4, train_loss_epoch=1.79e+4, valid_loss=2.48e+5]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2e+4, train_loss_epoch=1.7e+4, valid_loss=2.48e+5]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.1e+3, train_loss_epoch=1.11e+4, valid_loss=2.48e+5]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.91e+3, train_loss_epoch=7.58e+3, valid_loss=2.48e+5]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 183.87it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+4, train_loss_epoch=7.58e+3, valid_loss=1.14e+4]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.61e+3, train_loss_epoch=1.03e+4, valid_loss=1.14e+4]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.34e+3, train_loss_epoch=7.02e+3, valid_loss=1.14e+4]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.3e+3, train_loss_epoch=6.84e+3, valid_loss=1.14e+4]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.62e+3, train_loss_epoch=4.18e+3, valid_loss=1.14e+4]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.33e+3, train_loss_epoch=5.63e+3, valid_loss=1.14e+4]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.5e+3, train_loss_epoch=7.9e+3, valid_loss=1.14e+4]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=9.71e+3, train_loss_epoch=1.1e+4, valid_loss=1.14e+4]\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 202.13it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.67e+4, train_loss_epoch=1.1e+4, valid_loss=1.38e+4]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.52e+4, train_loss_epoch=1.74e+4, valid_loss=1.38e+4]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.95e+3, train_loss_epoch=8.63e+3, valid_loss=1.38e+4]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.16e+3, train_loss_epoch=5.95e+3, valid_loss=1.38e+4]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.19e+3, train_loss_epoch=5.37e+3, valid_loss=1.38e+4]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.04e+3, train_loss_epoch=4.08e+3, valid_loss=1.38e+4]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.95e+3, train_loss_epoch=5.56e+3, valid_loss=1.38e+4]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.83e+3, train_loss_epoch=4.88e+3, valid_loss=1.38e+4]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 174.38it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.8e+3, train_loss_epoch=4.66e+3, valid_loss=4.93e+3]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=5.1e+3, valid_loss=4.93e+3]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.62e+3, train_loss_epoch=6.31e+3, valid_loss=4.93e+3]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.36e+3, train_loss_epoch=5.63e+3, valid_loss=4.93e+3]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.28e+3, train_loss_epoch=4.26e+3, valid_loss=4.93e+3]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+3, train_loss_epoch=3.06e+3, valid_loss=4.93e+3]\n","Epoch 34: 100%|██████████| 7/7 [00:00<00:00, 43.29it/s, v_num=0, train_loss_step=3.07e+3, train_loss_epoch=3.06e+3, valid_loss=4.93e+3]\n","Epoch 34: 100%|██████████| 7/7 [00:00<00:00, 41.49it/s, v_num=0, train_loss_step=3.15e+3, train_loss_epoch=3.06e+3, valid_loss=4.93e+3]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.15e+3, train_loss_epoch=3.17e+3, valid_loss=4.93e+3]\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 149.43it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.04e+3, train_loss_epoch=3.17e+3, valid_loss=4.43e+3]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=3.19e+3, valid_loss=4.43e+3]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.54e+3, train_loss_epoch=4.32e+3, valid_loss=4.43e+3]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+3, train_loss_epoch=5.86e+3, valid_loss=4.43e+3]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=3.95e+3, valid_loss=4.43e+3]\n","Epoch 39: 100%|██████████| 7/7 [00:00<00:00, 45.48it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=3.95e+3, valid_loss=4.43e+3]\n","Epoch 39: 100%|██████████| 7/7 [00:00<00:00, 43.01it/s, v_num=0, train_loss_step=4.64e+3, train_loss_epoch=3.95e+3, valid_loss=4.43e+3]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.64e+3, train_loss_epoch=3.81e+3, valid_loss=4.43e+3]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.66e+3, train_loss_epoch=6.01e+3, valid_loss=4.43e+3]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.1e+3, train_loss_epoch=4.63e+3, valid_loss=4.43e+3]\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 153.14it/s]\u001b[A\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.83e+3, train_loss_epoch=4.63e+3, valid_loss=2.6e+3]\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.23e+3, train_loss_epoch=3.77e+3, valid_loss=2.6e+3]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.88e+3, valid_loss=2.6e+3]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.63e+3, train_loss_epoch=3.13e+3, valid_loss=2.6e+3]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.87e+3, train_loss_epoch=4.7e+3, valid_loss=2.6e+3]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.93e+3, train_loss_epoch=4.21e+3, valid_loss=2.6e+3]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.06e+3, train_loss_epoch=3.7e+3, valid_loss=2.6e+3]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.45e+3, train_loss_epoch=3.08e+3, valid_loss=2.6e+3]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 42.21it/s, v_num=0, train_loss_step=1.92e+3, train_loss_epoch=3.08e+3, valid_loss=2.6e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 119.51it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.92e+3, train_loss_epoch=2.28e+3, valid_loss=2.23e+3]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+3, train_loss_epoch=1.66e+3, valid_loss=2.23e+3]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.83e+3, train_loss_epoch=1.56e+3, valid_loss=2.23e+3]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.18e+3, train_loss_epoch=1.68e+3, valid_loss=2.23e+3]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.38e+3, train_loss_epoch=1.52e+3, valid_loss=2.23e+3]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+3, train_loss_epoch=1.46e+3, valid_loss=2.23e+3]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.6e+3, train_loss_epoch=1.8e+3, valid_loss=2.23e+3]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.9e+3, train_loss_epoch=1.63e+3, valid_loss=2.23e+3]\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 196.57it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.19e+3, train_loss_epoch=1.63e+3, valid_loss=1.88e+3]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.83e+3, train_loss_epoch=1.9e+3, valid_loss=1.88e+3]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=764.0, train_loss_epoch=1.43e+3, valid_loss=1.88e+3]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=930.0, train_loss_epoch=907.0, valid_loss=1.88e+3]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=864.0, train_loss_epoch=704.0, valid_loss=1.88e+3]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=765.0, train_loss_epoch=811.0, valid_loss=1.88e+3]\n","Epoch 62: 100%|██████████| 7/7 [00:00<00:00, 50.67it/s, v_num=0, train_loss_step=370.0, train_loss_epoch=714.0, valid_loss=1.88e+3]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=370.0, train_loss_epoch=714.0, valid_loss=1.88e+3]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=402.0, train_loss_epoch=701.0, valid_loss=1.88e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 203.95it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \n","                                                                       \u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+3, train_loss_epoch=701.0, valid_loss=321.0]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=612.0, train_loss_epoch=610.0, valid_loss=321.0]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+3, train_loss_epoch=834.0, valid_loss=321.0]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+3, train_loss_epoch=1.1e+3, valid_loss=321.0]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+3, train_loss_epoch=1.31e+3, valid_loss=321.0]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.87e+3, train_loss_epoch=1.44e+3, valid_loss=321.0]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.19e+3, train_loss_epoch=1.74e+3, valid_loss=321.0]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.38e+3, train_loss_epoch=1.64e+3, valid_loss=321.0]\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 191.59it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+3, train_loss_epoch=1.64e+3, valid_loss=3.19e+3]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.14e+3, valid_loss=3.19e+3]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=3.19e+3]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=857.0, train_loss_epoch=1.83e+3, valid_loss=3.19e+3]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.96e+3, train_loss_epoch=1.94e+3, valid_loss=3.19e+3]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.33e+3, train_loss_epoch=2.09e+3, valid_loss=3.19e+3]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.86e+3, train_loss_epoch=1.85e+3, valid_loss=3.19e+3]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:22:26,759\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=10154)\u001b[0m \rEpoch 77: 100%|██████████| 7/7 [00:00<00:00, 54.12it/s, v_num=0, train_loss_step=1.86e+3, train_loss_epoch=1.85e+3, valid_loss=3.19e+3]\rEpoch 77: 100%|██████████| 7/7 [00:00<00:00, 52.49it/s, v_num=0, train_loss_step=1.39e+3, train_loss_epoch=1.85e+3, valid_loss=3.19e+3]\rEpoch 77: 100%|██████████| 7/7 [00:00<00:00, 52.30it/s, v_num=0, train_loss_step=1.39e+3, train_loss_epoch=1.64e+3, valid_loss=3.19e+3]\rEpoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.39e+3, train_loss_epoch=1.64e+3, valid_loss=3.19e+3]        \rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.39e+3, train_loss_epoch=1.64e+3, valid_loss=3.19e+3]\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \n","\u001b[36m(_train_tune pid=10154)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 198.62it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10154)\u001b[0m \r                                                                       \u001b[A\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=433.0, train_loss_epoch=1.64e+3, valid_loss=1.38e+3]  \rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=433.0, train_loss_epoch=780.0, valid_loss=1.38e+3]  \rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=433.0, train_loss_epoch=780.0, valid_loss=1.38e+3]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=10315)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=10315)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=10315)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=10315)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=10315)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=10315)\u001b[0m 2025-06-14 19:22:37.652882: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=10315)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=10315)\u001b[0m E0000 00:00:1749928957.676395   10401 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=10315)\u001b[0m E0000 00:00:1749928957.683654   10401 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=10315)\u001b[0m 2025-06-14 19:22:37.710836: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=10315)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=10315)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","\u001b[36m(_train_tune pid=10315)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=10315)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=10315)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=10315)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=10315)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=10315)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=10315)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=10315)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=10315)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=10315)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=10315)\u001b[0m 10.286    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=10315)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=10315)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=10315)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=3.78e+4]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.760]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=3.050]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.670]\n","Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 54.82it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.670]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.280]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.820]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=1.670]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 179.72it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.670, valid_loss=1.920]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.660, valid_loss=1.920]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.670, valid_loss=1.920]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.650, valid_loss=1.920]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.660, valid_loss=1.920]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.670, valid_loss=1.920]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.600, valid_loss=1.920]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.630, valid_loss=1.920]\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 203.49it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.630, valid_loss=1.700]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.640, valid_loss=1.700]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.590, valid_loss=1.700]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.590, valid_loss=1.700]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=1.660, valid_loss=1.700]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.610, valid_loss=1.700]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.590, valid_loss=1.700]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.600, valid_loss=1.700]\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 144.33it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.600, valid_loss=1.710]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.620, valid_loss=1.710]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=1.670, valid_loss=1.710]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.600, valid_loss=1.710]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.590, valid_loss=1.710]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=1.610, valid_loss=1.710]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.570, valid_loss=1.710]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.590, valid_loss=1.710]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 155.69it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.560, valid_loss=1.660]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.540, valid_loss=1.660]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.510, valid_loss=1.660]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.500, valid_loss=1.660]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.420, valid_loss=1.660]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.400, valid_loss=1.660]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.360, valid_loss=1.660]\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 94.54it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.250, valid_loss=1.240]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.280, valid_loss=1.240]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.200, valid_loss=1.240]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=1.200, valid_loss=1.240]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.180, valid_loss=1.240]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.160, valid_loss=1.240]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.160, valid_loss=1.240]\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 160.78it/s]\u001b[A\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.160, valid_loss=1.110]\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.140, valid_loss=1.110]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=1.230, valid_loss=1.110]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.210, valid_loss=1.110]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.170, valid_loss=1.110]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.190, valid_loss=1.110]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.150, valid_loss=1.110]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.130, valid_loss=1.110]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 47.22it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.130, valid_loss=1.110]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 138.97it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.150, valid_loss=1.090]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.120, valid_loss=1.090]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=1.150, valid_loss=1.090]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.100, valid_loss=1.090]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.130, valid_loss=1.090]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=1.150, valid_loss=1.090]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.120, valid_loss=1.090]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.130, valid_loss=1.090]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 170.75it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.130, valid_loss=1.100]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.140, valid_loss=1.100]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.140, valid_loss=1.100]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.140, valid_loss=1.100]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.110, valid_loss=1.100]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.120, valid_loss=1.100]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.140, valid_loss=1.100]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=1.070, valid_loss=1.100]\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.66it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=1.070, valid_loss=1.070]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.110, valid_loss=1.070]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.090, valid_loss=1.070]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.140, valid_loss=1.070]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=1.090, valid_loss=1.070]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.130, valid_loss=1.070]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=1.120, valid_loss=1.070]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.130, valid_loss=1.070]\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 206.75it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=1.130, valid_loss=1.080]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.150, valid_loss=1.080]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.150, valid_loss=1.080]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.180, valid_loss=1.080]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=1.100, valid_loss=1.080]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=1.130, valid_loss=1.080]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.150, valid_loss=1.080]\n","Epoch 77: 100%|██████████| 7/7 [00:00<00:00, 47.54it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.150, valid_loss=1.080]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.130, valid_loss=1.080]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:22:52,517\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=10315)\u001b[0m \n","\u001b[36m(_train_tune pid=10315)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \n","\u001b[36m(_train_tune pid=10315)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 169.91it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10315)\u001b[0m \r                                                                       \u001b[A\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.130, valid_loss=1.070]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.160, valid_loss=1.070]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.160, valid_loss=1.070]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=10474)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=10474)\u001b[0m Seed set to 3\n","\u001b[36m(_train_tune pid=10474)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=10474)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=10474)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=10474)\u001b[0m 2025-06-14 19:23:04.490946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=10474)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=10474)\u001b[0m E0000 00:00:1749928984.515162   10564 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=10474)\u001b[0m E0000 00:00:1749928984.526546   10564 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=10474)\u001b[0m 2025-06-14 19:23:04.550344: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=10474)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=10474)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","\u001b[36m(_train_tune pid=10474)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=10474)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=10474)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=10474)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=10474)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=10474)\u001b[0m 3 | blocks       | ModuleList    | 2.7 M  | train\n","\u001b[36m(_train_tune pid=10474)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=10474)\u001b[0m 2.7 M     Trainable params\n","\u001b[36m(_train_tune pid=10474)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=10474)\u001b[0m 2.7 M     Total params\n","\u001b[36m(_train_tune pid=10474)\u001b[0m 10.806    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=10474)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=10474)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 19.43it/s]\n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.35e+4]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.790]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.610]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.490]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.390]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.220]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.260]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 194.01it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.260, valid_loss=1.160]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=1.150, valid_loss=1.160]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=1.130, valid_loss=1.160]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.140, valid_loss=1.160]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.160, valid_loss=1.160]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.130, valid_loss=1.160]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=1.120, valid_loss=1.160]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.100, valid_loss=1.160]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.60it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=1.100, valid_loss=1.090]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.130, valid_loss=1.090]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=1.120, valid_loss=1.090]\n","Epoch 16: 100%|██████████| 7/7 [00:00<00:00, 50.73it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=1.120, valid_loss=1.090]\n","Epoch 16: 100%|██████████| 7/7 [00:00<00:00, 49.17it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.100, valid_loss=1.090]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.100, valid_loss=1.090]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.090, valid_loss=1.090]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.060, valid_loss=1.090]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.090, valid_loss=1.090]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.080, valid_loss=1.090]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 190.21it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=1.080, valid_loss=1.170]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.170, valid_loss=1.170]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.130, valid_loss=1.170]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=1.080, valid_loss=1.170]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=1.120, valid_loss=1.170]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.090, valid_loss=1.170]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.100, valid_loss=1.170]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.090, valid_loss=1.170]\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 144.44it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.090, valid_loss=1.080]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.100, valid_loss=1.080]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.090, valid_loss=1.080]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.100, valid_loss=1.080]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.090, valid_loss=1.080]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=1.080]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=1.080, valid_loss=1.080]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=1.070, valid_loss=1.080]\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 156.36it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.100, valid_loss=1.060]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.090, valid_loss=1.060]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=1.050, valid_loss=1.060]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.090, valid_loss=1.060]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.100, valid_loss=1.060]\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 93.60it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.100, valid_loss=1.100]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=1.130, valid_loss=1.100]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.120, valid_loss=1.100]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.060, valid_loss=1.100]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=1.100, valid_loss=1.100]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=1.070, valid_loss=1.100]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.090, valid_loss=1.100]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 49.00it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=1.090, valid_loss=1.100]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 186.48it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=1.090, valid_loss=1.050]\n","Epoch 51: 100%|██████████| 7/7 [00:00<00:00, 49.92it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=1.090, valid_loss=1.050]\n","Epoch 51: 100%|██████████| 7/7 [00:00<00:00, 48.46it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.030, valid_loss=1.050]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=1.030, valid_loss=1.050]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.070, valid_loss=1.050]\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 186.45it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 61: 100%|██████████| 7/7 [00:00<00:00, 47.50it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=1.020, valid_loss=1.050]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=1.020, valid_loss=1.050]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=1.060, valid_loss=1.050]\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 212.34it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=1.080, valid_loss=1.030]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.060, valid_loss=1.030]\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 206.18it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=1.030, valid_loss=1.040]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.040, valid_loss=1.040]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:23:20,251\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=10474)\u001b[0m \n","\u001b[36m(_train_tune pid=10474)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 220.00it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10474)\u001b[0m \r                                                                       \u001b[A\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.040, valid_loss=1.040]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.030, valid_loss=1.040]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.030, valid_loss=1.040]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=10640)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=10640)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=10640)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=10640)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=10640)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=10640)\u001b[0m 2025-06-14 19:23:30.658567: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=10640)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=10640)\u001b[0m E0000 00:00:1749929010.704949   10720 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=10640)\u001b[0m E0000 00:00:1749929010.716587   10720 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=10640)\u001b[0m 2025-06-14 19:23:30.752568: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=10640)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=10640)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","\u001b[36m(_train_tune pid=10640)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=10640)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=10640)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=10640)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=10640)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=10640)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=10640)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=10640)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=10640)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=10640)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=10640)\u001b[0m 10.262    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=10640)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=10640)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.610]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.370]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.220]\n","Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 52.65it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.220]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=2.010]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.870]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=1.730]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.610]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 134.63it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.610, valid_loss=1.740]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.600, valid_loss=1.740]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.560, valid_loss=1.740]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.540, valid_loss=1.740]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.540, valid_loss=1.740]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.590, valid_loss=1.740]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.490, valid_loss=1.740]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.520, valid_loss=1.740]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 168.52it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.520, valid_loss=1.640]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.520, valid_loss=1.640]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.500, valid_loss=1.640]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.510, valid_loss=1.640]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.500, valid_loss=1.640]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.460, valid_loss=1.640]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.490, valid_loss=1.640]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.450, valid_loss=1.640]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 188.24it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.500, valid_loss=1.580]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.450, valid_loss=1.580]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.390, valid_loss=1.580]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.420, valid_loss=1.580]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.400, valid_loss=1.580]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.340, valid_loss=1.580]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.350, valid_loss=1.580]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.85it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.350, valid_loss=1.380]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.310, valid_loss=1.380]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.260, valid_loss=1.380]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.220, valid_loss=1.380]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.210, valid_loss=1.380]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.200, valid_loss=1.380]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.180, valid_loss=1.380]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=1.180, valid_loss=1.380]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 124.30it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.180, valid_loss=1.170]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.190, valid_loss=1.170]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.210, valid_loss=1.170]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.170, valid_loss=1.170]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.130, valid_loss=1.170]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.130, valid_loss=1.170]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=1.170]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.110, valid_loss=1.170]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 135.96it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.100, valid_loss=1.100]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=1.110, valid_loss=1.100]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=1.100]\n","Epoch 45: 100%|██████████| 7/7 [00:00<00:00, 41.87it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.120, valid_loss=1.100]\n","Epoch 45: 100%|██████████| 7/7 [00:00<00:00, 40.68it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.080, valid_loss=1.100]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.080, valid_loss=1.100]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.080, valid_loss=1.100]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.100, valid_loss=1.100]\n","Epoch 48: 100%|██████████| 7/7 [00:00<00:00, 36.98it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.100, valid_loss=1.100]\n","Epoch 48: 100%|██████████| 7/7 [00:00<00:00, 35.77it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.090, valid_loss=1.100]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.090, valid_loss=1.100]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 43.09it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.090, valid_loss=1.100]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 153.03it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.100, valid_loss=1.080]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=1.070, valid_loss=1.080]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=1.050, valid_loss=1.080]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.100, valid_loss=1.080]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.080, valid_loss=1.080]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=1.080, valid_loss=1.080]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=1.070, valid_loss=1.080]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.080, valid_loss=1.080]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 191.59it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=1.080, valid_loss=1.070]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=1.080, valid_loss=1.070]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=1.070, valid_loss=1.070]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.100, valid_loss=1.070]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=1.060, valid_loss=1.070]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.090, valid_loss=1.070]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.070, valid_loss=1.070]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.090, valid_loss=1.070]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.39it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.090, valid_loss=1.060]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.090, valid_loss=1.060]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=1.030, valid_loss=1.060]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=1.070, valid_loss=1.060]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 198.91it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.080, valid_loss=1.050]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=1.080, valid_loss=1.050]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 194.32it/s]\u001b[A\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 82:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.080, valid_loss=1.050]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.110, valid_loss=1.050]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=1.060, valid_loss=1.050]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.88it/s]\u001b[A\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.060, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 179.71it/s]\u001b[A\n","Epoch 93:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 94:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=1.020, valid_loss=1.040]\n","Epoch 95:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 96:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 97:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 98:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 99:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 99: 100%|██████████| 7/7 [00:00<00:00, 47.87it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=1.070, valid_loss=1.040]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 208.84it/s]\u001b[A\n","Epoch 100:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 101:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 102:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 103:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 104:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 105:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 106:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.070, valid_loss=1.030]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 157.01it/s]\u001b[A\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 108:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 109:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 110:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 111:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 112:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.100, valid_loss=1.030]\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.080, valid_loss=1.030]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 187.82it/s]\u001b[A\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.080, valid_loss=1.030]\n","Epoch 115:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 116:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 117:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 118:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=1.080, valid_loss=1.030]\n","Epoch 119:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 120:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.050, valid_loss=1.030]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 151.96it/s]\u001b[A\n","Epoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 122:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 123:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 124:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.080, valid_loss=1.030]\n","Epoch 125:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 126:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 127:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.060, valid_loss=1.030]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 123.25it/s]\u001b[A\n","Epoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 129:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 130:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 131:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 132:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=1.090, valid_loss=1.030]\n","Epoch 133:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.030, valid_loss=1.030]\n","Epoch 134:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=1.030, valid_loss=1.030]\n","Epoch 135:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.070, valid_loss=1.030]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 133.65it/s]\u001b[A\n","Epoch 135:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 136:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 137:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 138:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 139:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 140:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=1.080, valid_loss=1.030]\n","Epoch 141:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=1.050, valid_loss=1.030]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:23:55,617\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=10640)\u001b[0m \rEpoch 141: 100%|██████████| 7/7 [00:00<00:00, 55.79it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=1.050, valid_loss=1.030]\rEpoch 141: 100%|██████████| 7/7 [00:00<00:00, 53.75it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.050, valid_loss=1.030]\rEpoch 141: 100%|██████████| 7/7 [00:00<00:00, 53.53it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.070, valid_loss=1.030]\rEpoch 141:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.070, valid_loss=1.030]        \rEpoch 142:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.070, valid_loss=1.030]\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","\u001b[36m(_train_tune pid=10640)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10640)\u001b[0m \n","\u001b[36m(_train_tune pid=10640)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 189.84it/s]\u001b[A\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=10640)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=10640)\u001b[0m \n","\u001b[36m(_train_tune pid=10640)\u001b[0m \r                                                                       \u001b[A\rEpoch 142:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=1.070, valid_loss=1.030]\rEpoch 142:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=1.040, valid_loss=1.030]\rEpoch 142:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=1.040, valid_loss=1.030]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=10843)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=10843)\u001b[0m Seed set to 2\n","\u001b[36m(_train_tune pid=10843)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=10843)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=10843)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=10843)\u001b[0m 2025-06-14 19:24:07.288141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=10843)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=10843)\u001b[0m E0000 00:00:1749929047.328754   10929 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=10843)\u001b[0m E0000 00:00:1749929047.342799   10929 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=10843)\u001b[0m 2025-06-14 19:24:07.382523: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=10843)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=10843)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \n","\u001b[36m(_train_tune pid=10843)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=10843)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=10843)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=10843)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=10843)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=10843)\u001b[0m 3 | blocks       | ModuleList    | 2.7 M  | train\n","\u001b[36m(_train_tune pid=10843)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=10843)\u001b[0m 2.7 M     Trainable params\n","\u001b[36m(_train_tune pid=10843)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=10843)\u001b[0m 2.7 M     Total params\n","\u001b[36m(_train_tune pid=10843)\u001b[0m 10.806    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=10843)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=10843)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=10843)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=3.27e+4]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=2.010]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.600]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.540]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.450]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.220]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.210]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.24it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=1.210, valid_loss=1.130]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.190, valid_loss=1.130]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.150, valid_loss=1.130]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.160, valid_loss=1.130]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.130, valid_loss=1.130]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=1.110, valid_loss=1.130]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.110, valid_loss=1.130]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=1.090, valid_loss=1.130]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 187.04it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.090, valid_loss=1.100]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.130, valid_loss=1.100]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.140, valid_loss=1.100]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.130, valid_loss=1.100]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=1.120, valid_loss=1.100]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.110, valid_loss=1.100]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=1.110, valid_loss=1.100]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=1.080, valid_loss=1.100]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 183.69it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.080, valid_loss=1.070]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.100, valid_loss=1.070]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.090, valid_loss=1.070]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.130, valid_loss=1.070]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.140, valid_loss=1.070]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=1.100, valid_loss=1.070]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=1.110, valid_loss=1.070]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.140, valid_loss=1.070]\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 203.81it/s]\u001b[A\n","Epoch 28: 100%|██████████| 7/7 [00:00<00:00, 37.48it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=1.140, valid_loss=1.110]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.100, valid_loss=1.110]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.110]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.080, valid_loss=1.110]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=1.080, valid_loss=1.110]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.080, valid_loss=1.110]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=1.090, valid_loss=1.110]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.110, valid_loss=1.110]\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 183.96it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=1.070, valid_loss=1.070]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.110, valid_loss=1.070]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.090, valid_loss=1.070]\n","Epoch 38: 100%|██████████| 7/7 [00:00<00:00, 49.01it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=1.100, valid_loss=1.070]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=1.100, valid_loss=1.070]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=1.090, valid_loss=1.070]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=1.090, valid_loss=1.070]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.110, valid_loss=1.070]\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.64it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.050, valid_loss=1.060]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=1.110, valid_loss=1.060]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=1.040, valid_loss=1.060]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.050, valid_loss=1.060]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=1.050, valid_loss=1.060]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 42.53it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.050, valid_loss=1.060]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 129.30it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.090, valid_loss=1.040]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=1.060, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 148.54it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=1.050, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 102.70it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=1.040, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 177.83it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.090, valid_loss=1.040]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.030, valid_loss=1.040]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.060, valid_loss=1.040]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:24:23,372\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=10843)\u001b[0m \n","\u001b[36m(_train_tune pid=10843)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 200.22it/s]\u001b[A\n","\u001b[36m(_train_tune pid=10843)\u001b[0m \r                                                                       \u001b[A\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.060, valid_loss=1.050]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.040, valid_loss=1.050]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.040, valid_loss=1.050]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=11008)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=11008)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=11008)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=11008)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=11008)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=11008)\u001b[0m 2025-06-14 19:24:34.728194: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=11008)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=11008)\u001b[0m E0000 00:00:1749929074.752208   11094 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=11008)\u001b[0m E0000 00:00:1749929074.759790   11094 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=11008)\u001b[0m 2025-06-14 19:24:34.799863: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=11008)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=11008)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=11008)\u001b[0m \n","\u001b[36m(_train_tune pid=11008)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=11008)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11008)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=11008)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=11008)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=11008)\u001b[0m 3 | blocks       | ModuleList    | 2.7 M  | train\n","\u001b[36m(_train_tune pid=11008)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11008)\u001b[0m 2.7 M     Trainable params\n","\u001b[36m(_train_tune pid=11008)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=11008)\u001b[0m 2.7 M     Total params\n","\u001b[36m(_train_tune pid=11008)\u001b[0m 10.840    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=11008)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=11008)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=289.0]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.620]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.540]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.360]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.320]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.320]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.400]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 205.77it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11008)\u001b[0m \n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.400, valid_loss=1.180]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.190, valid_loss=1.180]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.190, valid_loss=1.180]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=1.130, valid_loss=1.180]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=1.110, valid_loss=1.180]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.120, valid_loss=1.180]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.120, valid_loss=1.180]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=1.100, valid_loss=1.180]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11008)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 164.68it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.100, valid_loss=1.060]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.100, valid_loss=1.060]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.090, valid_loss=1.060]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=1.080, valid_loss=1.060]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=1.050, valid_loss=1.060]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11008)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 160.04it/s]\u001b[A\n","Epoch 21: 100%|██████████| 7/7 [00:00<00:00, 35.17it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.090, valid_loss=1.030]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=1.080, valid_loss=1.030]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=1.050, valid_loss=1.030]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11008)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 191.26it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.070, valid_loss=1.050]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.775, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.060, valid_loss=1.050]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=1.060, valid_loss=1.050]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:24:43,449\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=11008)\u001b[0m \rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 49.22it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=1.060, valid_loss=1.050]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 47.65it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=1.060, valid_loss=1.050]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 47.47it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=1.050, valid_loss=1.050]\rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=1.050, valid_loss=1.050]        \rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=1.050, valid_loss=1.050]\n","\u001b[36m(_train_tune pid=11008)\u001b[0m \n","\u001b[36m(_train_tune pid=11008)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11008)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11008)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11008)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 192.14it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11008)\u001b[0m \r                                                                       \u001b[A\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.050, valid_loss=1.030]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.090, valid_loss=1.030]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.090, valid_loss=1.030]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=11143)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=11143)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=11143)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=11143)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=11143)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=11143)\u001b[0m 2025-06-14 19:24:55.833148: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=11143)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=11143)\u001b[0m E0000 00:00:1749929095.856081   11231 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=11143)\u001b[0m E0000 00:00:1749929095.863072   11231 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=11143)\u001b[0m 2025-06-14 19:24:55.891223: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=11143)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=11143)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=11143)\u001b[0m \n","\u001b[36m(_train_tune pid=11143)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=11143)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11143)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=11143)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=11143)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=11143)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=11143)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11143)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=11143)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=11143)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=11143)\u001b[0m 10.262    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=11143)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=11143)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=11143)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.950]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.540]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.320]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.190]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=1.130]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.110]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.757, train_loss_epoch=1.060]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11143)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 111.90it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.100, valid_loss=1.060]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.070, valid_loss=1.060]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.060, valid_loss=1.060]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.060]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11143)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 112.70it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=1.020, valid_loss=1.040]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.090, valid_loss=1.040]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=1.040, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=11143)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 203.38it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.820, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=1.040, valid_loss=1.030]\n","\u001b[36m(_train_tune pid=11143)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.08it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.040, valid_loss=1.050]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=1.040, valid_loss=1.050]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.040, valid_loss=1.050]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=1.030, valid_loss=1.050]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.050, valid_loss=1.050]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.030, valid_loss=1.050]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:25:04,757\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=11143)\u001b[0m \rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 54.62it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.030, valid_loss=1.050]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 52.68it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.030, valid_loss=1.050]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 52.48it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.050, valid_loss=1.050]\rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.050, valid_loss=1.050]        \rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.050, valid_loss=1.050]\n","\u001b[36m(_train_tune pid=11143)\u001b[0m \n","\u001b[36m(_train_tune pid=11143)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11143)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11143)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11143)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 203.37it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11143)\u001b[0m \r                                                                       \u001b[A\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.050, valid_loss=1.040]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.040]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.040]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=11282)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=11282)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=11282)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=11282)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=11282)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=11282)\u001b[0m 2025-06-14 19:25:15.582072: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=11282)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=11282)\u001b[0m E0000 00:00:1749929115.621483   11365 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=11282)\u001b[0m E0000 00:00:1749929115.633222   11365 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=11282)\u001b[0m 2025-06-14 19:25:15.659937: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=11282)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=11282)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=11282)\u001b[0m \n","\u001b[36m(_train_tune pid=11282)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=11282)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11282)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=11282)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=11282)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=11282)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=11282)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11282)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=11282)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=11282)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=11282)\u001b[0m 10.297    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=11282)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=11282)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 18.20it/s, v_num=0, train_loss_step=2.400]\n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=5.450]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.750]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.370]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.230]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.140]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.140]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=1.070]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11282)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 176.14it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.070, valid_loss=1.070]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=1.070, valid_loss=1.070]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.100, valid_loss=1.070]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=1.130, valid_loss=1.070]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.130, valid_loss=1.070]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.150, valid_loss=1.070]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.100, valid_loss=1.070]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.080, valid_loss=1.070]\n","\u001b[36m(_train_tune pid=11282)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 194.86it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.090, valid_loss=1.040]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.090, valid_loss=1.040]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=1.050, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=11282)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 176.79it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11282)\u001b[0m \n","                                                                       \u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.843, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=1.050, valid_loss=1.020]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11282)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 126.95it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.030, valid_loss=1.040]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.050, valid_loss=1.040]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:25:23,956\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=11282)\u001b[0m \n","\u001b[36m(_train_tune pid=11282)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11282)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11282)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11282)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 148.59it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11282)\u001b[0m \r                                                                       \u001b[A\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.050, valid_loss=1.030]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.030]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.030]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=11410)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=11410)\u001b[0m Seed set to 3\n","\u001b[36m(_train_tune pid=11410)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=11410)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=11410)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=11410)\u001b[0m 2025-06-14 19:25:34.670542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=11410)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=11410)\u001b[0m E0000 00:00:1749929134.700342   11496 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=11410)\u001b[0m E0000 00:00:1749929134.707392   11496 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=11410)\u001b[0m 2025-06-14 19:25:34.732794: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=11410)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=11410)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=11410)\u001b[0m \n","\u001b[36m(_train_tune pid=11410)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=11410)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11410)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=11410)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=11410)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=11410)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=11410)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11410)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=11410)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=11410)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=11410)\u001b[0m 10.297    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=11410)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=11410)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=2.330]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.690]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.520]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.480]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.340]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.300]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11410)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 125.43it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.300, valid_loss=1.250]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.210, valid_loss=1.250]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=1.160, valid_loss=1.250]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.150, valid_loss=1.250]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=1.140, valid_loss=1.250]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.110, valid_loss=1.250]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=1.090, valid_loss=1.250]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.060, valid_loss=1.250]\n","\u001b[36m(_train_tune pid=11410)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 143.58it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.865, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.090, valid_loss=1.040]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 16: 100%|██████████| 7/7 [00:00<00:00, 41.69it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=1.040, valid_loss=1.040]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.060, valid_loss=1.040]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11410)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 148.80it/s]\u001b[A\n","Epoch 21: 100%|██████████| 7/7 [00:00<00:00, 35.61it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.070, valid_loss=1.020]        \n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.080, valid_loss=1.020]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=1.020, valid_loss=1.020]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.060, valid_loss=1.020]\n","\u001b[36m(_train_tune pid=11410)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 213.54it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 28: 100%|██████████| 7/7 [00:00<00:00, 40.14it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=1.040, valid_loss=1.020]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:25:43,461\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=11410)\u001b[0m \rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 54.95it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=1.040, valid_loss=1.020]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 52.88it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=1.040, valid_loss=1.020]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 52.67it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=1.030, valid_loss=1.020]\rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=1.030, valid_loss=1.020]        \rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=1.030, valid_loss=1.020]\n","\u001b[36m(_train_tune pid=11410)\u001b[0m \n","\u001b[36m(_train_tune pid=11410)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11410)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11410)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11410)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 215.56it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11410)\u001b[0m \r                                                                       \u001b[A\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.030, valid_loss=1.030]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.020, valid_loss=1.030]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.020, valid_loss=1.030]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=11545)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=11545)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=11545)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=11545)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=11545)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=11545)\u001b[0m 2025-06-14 19:25:55.262403: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=11545)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=11545)\u001b[0m E0000 00:00:1749929155.288546   11629 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=11545)\u001b[0m E0000 00:00:1749929155.296730   11629 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=11545)\u001b[0m 2025-06-14 19:25:55.338287: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=11545)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=11545)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \n","\u001b[36m(_train_tune pid=11545)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=11545)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11545)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=11545)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=11545)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=11545)\u001b[0m 3 | blocks       | ModuleList    | 2.7 M  | train\n","\u001b[36m(_train_tune pid=11545)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11545)\u001b[0m 2.7 M     Trainable params\n","\u001b[36m(_train_tune pid=11545)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=11545)\u001b[0m 2.7 M     Total params\n","\u001b[36m(_train_tune pid=11545)\u001b[0m 10.840    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=11545)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=11545)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.900, train_loss_epoch=2.660]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.290]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.910]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=1.680]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.600]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.560]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.560]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 184.57it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.560, valid_loss=1.610]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.490, valid_loss=1.610]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.470, valid_loss=1.610]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.380, valid_loss=1.610]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.300, valid_loss=1.610]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.250, valid_loss=1.610]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.240, valid_loss=1.610]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.180, valid_loss=1.610]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 164.81it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.180, valid_loss=1.150]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.160, valid_loss=1.150]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.130, valid_loss=1.150]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=1.100, valid_loss=1.150]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.120, valid_loss=1.150]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.090, valid_loss=1.150]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=1.110, valid_loss=1.150]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=1.070, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 170.36it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=1.050, valid_loss=1.040]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.100, valid_loss=1.040]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=1.080, valid_loss=1.040]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.070, valid_loss=1.040]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=1.060, valid_loss=1.040]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=1.100, valid_loss=1.040]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.750, train_loss_epoch=1.070, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.95it/s]\u001b[A\n","Epoch 28: 100%|██████████| 7/7 [00:00<00:00, 35.81it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.080, valid_loss=1.030]        \n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.080, valid_loss=1.030]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=1.050, valid_loss=1.030]\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 199.81it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=1.090, valid_loss=1.030]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.040, valid_loss=1.030]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.060, valid_loss=1.030]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.050, valid_loss=1.030]\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 157.69it/s]\u001b[A\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.050, valid_loss=1.030]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.070, valid_loss=1.030]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 41.04it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=1.070, valid_loss=1.030]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 157.05it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=1.020, valid_loss=1.020]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.070, valid_loss=1.020]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 151.91it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.020, valid_loss=1.020]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.070, valid_loss=1.020]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=1.050, valid_loss=1.020]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 167.72it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.060, valid_loss=1.020]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=1.030, valid_loss=1.020]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 171.31it/s]\u001b[A\n","Epoch 71: 100%|██████████| 7/7 [00:00<00:00, 36.57it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=1.030, valid_loss=1.020]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.040, valid_loss=1.020]        \n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.040, valid_loss=1.020]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.050, valid_loss=1.020]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=1.030, valid_loss=1.020]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:26:11,218\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=11545)\u001b[0m \rEpoch 77: 100%|██████████| 7/7 [00:00<00:00, 47.33it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=1.030, valid_loss=1.020]\rEpoch 77: 100%|██████████| 7/7 [00:00<00:00, 45.96it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=1.030, valid_loss=1.020]\rEpoch 77: 100%|██████████| 7/7 [00:00<00:00, 45.80it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=1.030, valid_loss=1.020]\rEpoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=1.030, valid_loss=1.020]        \rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=1.030, valid_loss=1.020]\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \n","\u001b[36m(_train_tune pid=11545)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 185.29it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11545)\u001b[0m \r                                                                       \u001b[A\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=1.030, valid_loss=1.020]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=1.050, valid_loss=1.020]\rEpoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=1.050, valid_loss=1.020]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=11709)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=11709)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=11709)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=11709)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=11709)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=11709)\u001b[0m 2025-06-14 19:26:21.516239: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=11709)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=11709)\u001b[0m E0000 00:00:1749929181.540686   11792 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=11709)\u001b[0m E0000 00:00:1749929181.547981   11792 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=11709)\u001b[0m 2025-06-14 19:26:21.576092: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=11709)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=11709)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=11709)\u001b[0m \n","\u001b[36m(_train_tune pid=11709)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=11709)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11709)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=11709)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=11709)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=11709)\u001b[0m 3 | blocks       | ModuleList    | 2.6 M  | train\n","\u001b[36m(_train_tune pid=11709)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11709)\u001b[0m 2.6 M     Trainable params\n","\u001b[36m(_train_tune pid=11709)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=11709)\u001b[0m 2.6 M     Total params\n","\u001b[36m(_train_tune pid=11709)\u001b[0m 10.252    Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=11709)\u001b[0m 34        Modules in train mode\n","\u001b[36m(_train_tune pid=11709)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=11709)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=140.0, train_loss_epoch=9.56e+10]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=7.89e+3]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.59e+3, train_loss_epoch=4.79e+5]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.27e+6, train_loss_epoch=6.23e+5]\n","Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 52.45it/s, v_num=0, train_loss_step=2.17e+4, train_loss_epoch=1.81e+4]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.17e+4, train_loss_epoch=1.81e+4]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.34e+3, train_loss_epoch=1.59e+4]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+4, train_loss_epoch=1.25e+4]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11709)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 193.86it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11709)\u001b[0m \n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+4, train_loss_epoch=1.25e+4, valid_loss=1.41e+4]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.6e+4, train_loss_epoch=1.47e+4, valid_loss=1.41e+4]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.61e+4, train_loss_epoch=1.47e+4, valid_loss=1.41e+4]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.02e+3, train_loss_epoch=1.11e+4, valid_loss=1.41e+4]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.31e+3, train_loss_epoch=8.19e+3, valid_loss=1.41e+4]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+4, train_loss_epoch=9.55e+3, valid_loss=1.41e+4]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.96e+3, train_loss_epoch=7.66e+3, valid_loss=1.41e+4]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=8.55e+3, train_loss_epoch=8.38e+3, valid_loss=1.41e+4]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11709)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 187.47it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.86e+3, train_loss_epoch=8.38e+3, valid_loss=8.57e+3]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.96e+3, train_loss_epoch=8.16e+3, valid_loss=8.57e+3]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.52e+3, train_loss_epoch=6.8e+3, valid_loss=8.57e+3]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.65e+3, train_loss_epoch=5.43e+3, valid_loss=8.57e+3]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.21e+3, train_loss_epoch=6.44e+3, valid_loss=8.57e+3]\n","Epoch 18: 100%|██████████| 7/7 [00:00<00:00, 54.40it/s, v_num=0, train_loss_step=6.21e+3, train_loss_epoch=6.44e+3, valid_loss=8.57e+3]\n","Epoch 18: 100%|██████████| 7/7 [00:00<00:00, 52.51it/s, v_num=0, train_loss_step=6.2e+3, train_loss_epoch=6.34e+3, valid_loss=8.57e+3]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=6.2e+3, train_loss_epoch=6.34e+3, valid_loss=8.57e+3]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.36e+3, train_loss_epoch=6.65e+3, valid_loss=8.57e+3]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.72e+3, train_loss_epoch=6.66e+3, valid_loss=8.57e+3]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11709)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.41it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.1e+3, train_loss_epoch=6.66e+3, valid_loss=4.45e+3] \n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.68e+3, train_loss_epoch=5.33e+3, valid_loss=4.45e+3]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.73e+3, train_loss_epoch=4.31e+3, valid_loss=4.45e+3]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.39e+3, train_loss_epoch=4.57e+3, valid_loss=4.45e+3]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=5.46e+3, train_loss_epoch=5.26e+3, valid_loss=4.45e+3]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+3, train_loss_epoch=5.17e+3, valid_loss=4.45e+3]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.07e+3, train_loss_epoch=2.69e+3, valid_loss=4.45e+3]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.14e+3, train_loss_epoch=3.97e+3, valid_loss=4.45e+3]\n","\u001b[36m(_train_tune pid=11709)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.28it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.69e+3, train_loss_epoch=3.97e+3, valid_loss=3.12e+3]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.69e+3, train_loss_epoch=3.54e+3, valid_loss=3.12e+3]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.82e+3, train_loss_epoch=2.84e+3, valid_loss=3.12e+3]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.6e+3, train_loss_epoch=4.29e+3, valid_loss=3.12e+3]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.51e+3, train_loss_epoch=4.53e+3, valid_loss=3.12e+3]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.78e+3, valid_loss=3.12e+3]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.95e+3, train_loss_epoch=2.39e+3, valid_loss=3.12e+3]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.82e+3, train_loss_epoch=3.01e+3, valid_loss=3.12e+3]\n","\u001b[36m(_train_tune pid=11709)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 190.73it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.98e+3, train_loss_epoch=3.01e+3, valid_loss=6.83e+3]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=4.79e+3, train_loss_epoch=4.37e+3, valid_loss=6.83e+3]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=7.35e+3, train_loss_epoch=5.54e+3, valid_loss=6.83e+3]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3e+3, train_loss_epoch=4.21e+3, valid_loss=6.83e+3]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.46e+3, train_loss_epoch=3.93e+3, valid_loss=6.83e+3]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.65e+3, train_loss_epoch=4.18e+3, valid_loss=6.83e+3]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+3, train_loss_epoch=2.51e+3, valid_loss=6.83e+3]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:26:30,828\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n","2025-06-14 19:26:30,851\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/_train_tune_2025-06-14_19-18-22' in 0.0190s.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=11709)\u001b[0m \rEpoch 41: 100%|██████████| 7/7 [00:00<00:00, 55.41it/s, v_num=0, train_loss_step=1.49e+3, train_loss_epoch=2.51e+3, valid_loss=6.83e+3]\rEpoch 41: 100%|██████████| 7/7 [00:00<00:00, 53.55it/s, v_num=0, train_loss_step=1.68e+3, train_loss_epoch=2.51e+3, valid_loss=6.83e+3]\rEpoch 41: 100%|██████████| 7/7 [00:00<00:00, 53.35it/s, v_num=0, train_loss_step=1.68e+3, train_loss_epoch=1.83e+3, valid_loss=6.83e+3]\rEpoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+3, train_loss_epoch=1.83e+3, valid_loss=6.83e+3]        \rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+3, train_loss_epoch=1.83e+3, valid_loss=6.83e+3]\n","\u001b[36m(_train_tune pid=11709)\u001b[0m \n","\u001b[36m(_train_tune pid=11709)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11709)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11709)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11709)\u001b[0m \n","\u001b[36m(_train_tune pid=11709)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 199.66it/s]\u001b[A\n","\n"]},{"output_type":"stream","name":"stderr","text":["INFO:lightning_fabric.utilities.seed:Seed set to 7\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name         | Type          | Params | Mode \n","-------------------------------------------------------\n","0 | loss         | MQLoss        | 5      | eval \n","1 | padder_train | ConstantPad1d | 0      | train\n","2 | scaler       | TemporalNorm  | 0      | train\n","3 | blocks       | ModuleList    | 2.6 M  | train\n","-------------------------------------------------------\n","2.6 M     Trainable params\n","5         Non-trainable params\n","2.6 M     Total params\n","10.286    Total estimated model params size (MB)\n","33        Modules in train mode\n","1         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=11709)\u001b[0m \n","\u001b[36m(_train_tune pid=11709)\u001b[0m \r                                                                       \u001b[A\rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.4e+3, train_loss_epoch=1.83e+3, valid_loss=3.39e+3] \rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.4e+3, train_loss_epoch=2.87e+3, valid_loss=3.39e+3]\rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=3.4e+3, train_loss_epoch=2.87e+3, valid_loss=3.39e+3]\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9070f3e2bb35405db17d4ad239f0f157"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab653e2090784bd08aadcd1643125b69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0168e8f930ab4283be0ea80a7c4649a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0628a4d4837464dae68515c6520b5a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89888f516ea0447d9934b623b3e3a8fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1b3aaa201614d31af882e5f70a0ef36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd8fba7745ac48f7afc4a0b23377b0d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35e24355d05347a2bbd2db21b23eb54c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df15a760b3564853a4ec69ea35d3b762"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e69a7c6eea384c4f9e8d622316064ef3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db7f3c2467e64d769204b8be8569483f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d28b930d40044e77b470c56a6c321b51"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------------------------+\n","| Configuration for experiment     _train_tune_2025-06-14_19-26-43   |\n","+--------------------------------------------------------------------+\n","| Search algorithm                 SearchGenerator                   |\n","| Scheduler                        FIFOScheduler                     |\n","| Number of trials                 20                                |\n","+--------------------------------------------------------------------+\n","\n","View detailed results here: /root/ray_results/_train_tune_2025-06-14_19-26-43\n","To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-14_19-03-27_020465_1199/artifacts/2025-06-14_19-26-43/_train_tune_2025-06-14_19-26-43/driver_artifacts`\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=11896)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=11896)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=11896)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=11896)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=11896)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 2025-06-14 19:26:53.779103: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=11896)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=11896)\u001b[0m E0000 00:00:1749929213.802836   11980 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=11896)\u001b[0m E0000 00:00:1749929213.810180   11980 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 2025-06-14 19:26:53.835033: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=11896)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=11896)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","\u001b[36m(_train_tune pid=11896)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=11896)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=11896)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=11896)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=11896)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.330]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.260]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.760]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.470]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.450]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.580]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.520]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 184.07it/s]\u001b[A\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.580, valid_loss=1.180]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.530, valid_loss=1.180]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.380, valid_loss=1.180]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.540, valid_loss=1.180]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.470, valid_loss=1.180]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.500, valid_loss=1.180]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 127.53it/s]\u001b[A\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.450, valid_loss=1.150]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.530, valid_loss=1.150]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.450, valid_loss=1.150]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.420, valid_loss=1.150]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.440, valid_loss=1.150]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.530, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 193.85it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.490, valid_loss=1.130]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.450, valid_loss=1.130]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.510, valid_loss=1.130]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.450, valid_loss=1.130]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.440, valid_loss=1.130]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.620, valid_loss=1.130]\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 226.87it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.490, valid_loss=1.120]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.490, valid_loss=1.120]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.450, valid_loss=1.120]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.540, valid_loss=1.120]\n","Epoch 32: 100%|██████████| 7/7 [00:00<00:00, 80.17it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.510, valid_loss=1.120]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.510, valid_loss=1.120]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.390, valid_loss=1.120]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.390, valid_loss=1.120]\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 85.73it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.480, valid_loss=1.110]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.510, valid_loss=1.110]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.530, valid_loss=1.110]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.510, valid_loss=1.110]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.480, valid_loss=1.110]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.510, valid_loss=1.110]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.420, valid_loss=1.110]\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 177.94it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.380, valid_loss=1.100]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.470, valid_loss=1.100]\n","Epoch 45: 100%|██████████| 7/7 [00:00<00:00, 72.46it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.430, valid_loss=1.100]\n","Epoch 45: 100%|██████████| 7/7 [00:00<00:00, 72.00it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.390, valid_loss=1.100]\n","Epoch 46: 100%|██████████| 7/7 [00:00<00:00, 70.59it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.390, valid_loss=1.100]\n","Epoch 46: 100%|██████████| 7/7 [00:00<00:00, 67.08it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.390, valid_loss=1.100]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.390, valid_loss=1.100]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.420, valid_loss=1.100]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 55.65it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.420, valid_loss=1.100]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 173.73it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.450, valid_loss=1.100]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.380, valid_loss=1.100]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.400, valid_loss=1.100]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.430, valid_loss=1.100]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.510, valid_loss=1.100]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.420, valid_loss=1.100]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.420, valid_loss=1.100]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.470, valid_loss=1.100]        \n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.470, valid_loss=1.100]\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 153.29it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.470, valid_loss=1.110]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.430, valid_loss=1.110]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.450, valid_loss=1.110]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.400, valid_loss=1.110]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.410, valid_loss=1.110]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.420, valid_loss=1.110]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.340, valid_loss=1.110]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.470, valid_loss=1.110]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 175.51it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.470, valid_loss=1.090]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.490, valid_loss=1.090]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.290, valid_loss=1.090]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.310, valid_loss=1.090]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.330, valid_loss=1.090]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.350, valid_loss=1.090]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.350, valid_loss=1.090]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 200.45it/s]\u001b[A\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.360, valid_loss=1.050]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=1.360, valid_loss=1.050]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=1.490, valid_loss=1.050]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.460, valid_loss=1.050]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.350, valid_loss=1.050]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.380, valid_loss=1.050]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 198.21it/s]\u001b[A\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.400, valid_loss=1.060]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.280, valid_loss=1.060]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.410, valid_loss=1.060]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.260, valid_loss=1.060]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.250, valid_loss=1.060]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.330, valid_loss=1.060]\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 203.13it/s]\u001b[A\n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.350, valid_loss=1.040]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.250, valid_loss=1.040]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.320, valid_loss=1.040]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.300, valid_loss=1.040]\n","Epoch 89: 100%|██████████| 7/7 [00:00<00:00, 81.70it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.410, valid_loss=1.040]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.410, valid_loss=1.040]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.350, valid_loss=1.040]\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.320, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 220.50it/s]\u001b[A\n","Epoch 93:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.310, valid_loss=1.050]\n","Epoch 94:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.310, valid_loss=1.050]\n","Epoch 95:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.530, valid_loss=1.050]\n","Epoch 96:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.260, valid_loss=1.050]\n","Epoch 98:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.280, valid_loss=1.050]\n","Epoch 99:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.370, valid_loss=1.050]\n","Epoch 99: 100%|██████████| 7/7 [00:00<00:00, 82.32it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.370, valid_loss=1.050]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 227.06it/s]\u001b[A\n","Epoch 100:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.310, valid_loss=1.030]\n","Epoch 101:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.360, valid_loss=1.030]\n","Epoch 102:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.280, valid_loss=1.030]\n","Epoch 103:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.320, valid_loss=1.030]\n","Epoch 105:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.540, valid_loss=1.030]\n","Epoch 106:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.260, valid_loss=1.030]\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.320, valid_loss=1.030]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 174.87it/s]\u001b[A\n","Epoch 108:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.420, valid_loss=1.030]\n","Epoch 109:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.320, valid_loss=1.030]\n","Epoch 110:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.270, valid_loss=1.030]\n","Epoch 111: 100%|██████████| 7/7 [00:00<00:00, 78.59it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.340, valid_loss=1.030]\n","Epoch 112:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.340, valid_loss=1.030]\n","Epoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.340, valid_loss=1.030]\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.370, valid_loss=1.030]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 181.71it/s]\u001b[A\n","Epoch 115:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.410, valid_loss=1.040]\n","Epoch 116:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.320, valid_loss=1.040]\n","Epoch 117:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.260, valid_loss=1.040]\n","Epoch 118:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.360, valid_loss=1.040]\n","Epoch 120:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.330, valid_loss=1.040]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:27:09,417\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=11896)\u001b[0m \rEpoch 120: 100%|██████████| 7/7 [00:00<00:00, 83.81it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.330, valid_loss=1.040]\rEpoch 120: 100%|██████████| 7/7 [00:00<00:00, 82.97it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.330, valid_loss=1.040]\rEpoch 120: 100%|██████████| 7/7 [00:00<00:00, 82.49it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.390, valid_loss=1.040]\rEpoch 120:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.390, valid_loss=1.040]        \rEpoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.390, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","\u001b[36m(_train_tune pid=11896)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \n","\u001b[36m(_train_tune pid=11896)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 208.16it/s]\u001b[A\n","\u001b[36m(_train_tune pid=11896)\u001b[0m \r                                                                       \u001b[A\rEpoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.390, valid_loss=1.040]\rEpoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.370, valid_loss=1.040]\rEpoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.370, valid_loss=1.040]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=12058)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=12058)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=12058)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=12058)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=12058)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 2025-06-14 19:27:20.600356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=12058)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=12058)\u001b[0m E0000 00:00:1749929240.635374   12141 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=12058)\u001b[0m E0000 00:00:1749929240.644038   12141 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 2025-06-14 19:27:20.672378: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=12058)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=12058)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=12058)\u001b[0m \n","\u001b[36m(_train_tune pid=12058)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=12058)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=12058)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=12058)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.280]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.730]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.510]\n","Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 73.38it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.450]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.450]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.580]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.510]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12058)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 161.29it/s]\u001b[A\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.580, valid_loss=1.160]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.540, valid_loss=1.160]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.390, valid_loss=1.160]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.570, valid_loss=1.160]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.470, valid_loss=1.160]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.500, valid_loss=1.160]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12058)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12058)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 192.54it/s]\u001b[A\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.550, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12058)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 218.61it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.550, valid_loss=1.160]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.480, valid_loss=1.160]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.530, valid_loss=1.160]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.470, valid_loss=1.160]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.560, valid_loss=1.160]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:27:26,640\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=12058)\u001b[0m \rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 83.15it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.560, valid_loss=1.160]\rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 82.39it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.560, valid_loss=1.160]\rEpoch 26: 100%|██████████| 7/7 [00:00<00:00, 81.87it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.470, valid_loss=1.160]\rEpoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.470, valid_loss=1.160]        \rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.470, valid_loss=1.160]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 81.46it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.470, valid_loss=1.160]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 81.14it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.470, valid_loss=1.160]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 80.58it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.640, valid_loss=1.160]\rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.640, valid_loss=1.160]        \rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.640, valid_loss=1.160]\n","\u001b[36m(_train_tune pid=12058)\u001b[0m \n","\u001b[36m(_train_tune pid=12058)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12058)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12058)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12058)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 151.96it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12058)\u001b[0m \r                                                                       \u001b[A\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.640, valid_loss=1.160]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.570, valid_loss=1.160]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.570, valid_loss=1.160]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=12178)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=12178)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=12178)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=12178)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=12178)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 2025-06-14 19:27:38.388874: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=12178)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=12178)\u001b[0m E0000 00:00:1749929258.412821   12268 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=12178)\u001b[0m E0000 00:00:1749929258.419992   12268 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 2025-06-14 19:27:38.449127: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=12178)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=12178)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","\u001b[36m(_train_tune pid=12178)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=12178)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=12178)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=12178)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=12178)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.340]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=2.070]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.670]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.540]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.560]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.550]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=1.660]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 123.89it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.660, valid_loss=1.150]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.480, valid_loss=1.150]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.550, valid_loss=1.150]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.510, valid_loss=1.150]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.510, valid_loss=1.150]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.450, valid_loss=1.150]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.28it/s]\u001b[A\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 71.73it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.470, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.60it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.580, valid_loss=1.140]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 26: 100%|██████████| 7/7 [00:00<00:00, 81.54it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.560, valid_loss=1.140]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.560, valid_loss=1.140]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.430, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 223.45it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=1.140]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.560, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 218.88it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.560, valid_loss=1.120]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.420, valid_loss=1.120]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.420, valid_loss=1.120]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.500, valid_loss=1.120]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.440, valid_loss=1.120]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.400, valid_loss=1.120]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.380, valid_loss=1.120]\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 221.37it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.360, valid_loss=1.110]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.450, valid_loss=1.110]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.450, valid_loss=1.110]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.390, valid_loss=1.110]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.430, valid_loss=1.110]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.460, valid_loss=1.110]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 80.50it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.460, valid_loss=1.110]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 234.25it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.360, valid_loss=1.130]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.430, valid_loss=1.130]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.520, valid_loss=1.130]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.380, valid_loss=1.130]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.470, valid_loss=1.130]\n","Epoch 54: 100%|██████████| 7/7 [00:00<00:00, 75.76it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.470, valid_loss=1.130]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.500, valid_loss=1.130]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.430, valid_loss=1.130]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.380, valid_loss=1.130]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 166.27it/s]\u001b[A\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.410, valid_loss=1.100]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.430, valid_loss=1.100]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.470, valid_loss=1.100]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.410, valid_loss=1.100]\n","Epoch 61: 100%|██████████| 7/7 [00:00<00:00, 76.85it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.410, valid_loss=1.100]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.460, valid_loss=1.100]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.370, valid_loss=1.100]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.430, valid_loss=1.100]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 183.34it/s]\u001b[A\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.440, valid_loss=1.100]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.390, valid_loss=1.100]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.360, valid_loss=1.100]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.400, valid_loss=1.100]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.460, valid_loss=1.100]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.500, valid_loss=1.100]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=1.630, valid_loss=1.100]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 199.28it/s]\u001b[A\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=1.100]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.440, valid_loss=1.100]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=1.100]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.370, valid_loss=1.100]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.400, valid_loss=1.100]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.370, valid_loss=1.100]\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 231.30it/s]\u001b[A\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.420, valid_loss=1.080]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.390, valid_loss=1.080]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.370, valid_loss=1.080]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.290, valid_loss=1.080]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.330, valid_loss=1.080]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.370, valid_loss=1.080]\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 226.06it/s]\u001b[A\n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.310, valid_loss=1.060]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.340, valid_loss=1.060]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.430, valid_loss=1.060]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.360, valid_loss=1.060]\n","Epoch 89: 100%|██████████| 7/7 [00:00<00:00, 78.65it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.360, valid_loss=1.060]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.350, valid_loss=1.060]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.310, valid_loss=1.060]\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.420, valid_loss=1.060]\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 212.46it/s]\u001b[A\n","Epoch 93:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.350, valid_loss=1.050]\n","Epoch 94:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.360, valid_loss=1.050]\n","Epoch 95:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.370, valid_loss=1.050]\n","Epoch 96:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.520, valid_loss=1.050]\n","Epoch 97:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.260, valid_loss=1.050]\n","Epoch 98:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.250, valid_loss=1.050]\n","Epoch 99:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.330, valid_loss=1.050]\n","Epoch 99: 100%|██████████| 7/7 [00:00<00:00, 80.87it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.330, valid_loss=1.050]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 226.56it/s]\u001b[A\n","Epoch 100:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.330, valid_loss=1.050]\n","Epoch 101:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.270, valid_loss=1.050]\n","Epoch 102:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.270, valid_loss=1.050]\n","Epoch 103:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.310, valid_loss=1.050]\n","Epoch 105:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.320, valid_loss=1.050]\n","Epoch 106:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.300, valid_loss=1.050]\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.540, valid_loss=1.050]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 220.92it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Epoch 108:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.290, valid_loss=1.040]\n","Epoch 109:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.380, valid_loss=1.040]\n","Epoch 110:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.390, valid_loss=1.040]\n","Epoch 112:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.310, valid_loss=1.040]\n","Epoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.310, valid_loss=1.040]\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.330, valid_loss=1.040]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 144.43it/s]\u001b[A\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.330, valid_loss=1.050]\n","Epoch 115:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.310, valid_loss=1.050]\n","Epoch 116:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.310, valid_loss=1.050]\n","Epoch 117:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.320, valid_loss=1.050]\n","Epoch 118:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.530, valid_loss=1.050]\n","Epoch 119:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.340, valid_loss=1.050]\n","Epoch 120:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.330, valid_loss=1.050]\n","Epoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.260, valid_loss=1.050]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 171.71it/s]\u001b[A\n","Epoch 122:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.500, valid_loss=1.040]\n","Epoch 123:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.340, valid_loss=1.040]\n","Epoch 124:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.310, valid_loss=1.040]\n","Epoch 125:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.350, valid_loss=1.040]\n","Epoch 126:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.330, valid_loss=1.040]\n","Epoch 127:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.330, valid_loss=1.040]\n","Epoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.320, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 137.74it/s]\u001b[A\n","Epoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.320, valid_loss=1.050]\n","Epoch 129:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.360, valid_loss=1.050]\n","Epoch 130:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.340, valid_loss=1.050]\n","Epoch 131:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.410, valid_loss=1.050]\n","Epoch 132:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.330, valid_loss=1.050]\n","Epoch 133:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.330, valid_loss=1.050]\n","Epoch 134:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.250, valid_loss=1.050]\n","Epoch 135:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.330, valid_loss=1.050]\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 145.50it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","Epoch 136:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.330, valid_loss=1.040]\n","Epoch 137:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=1.040]\n","Epoch 138:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.350, valid_loss=1.040]\n","Epoch 139:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.320, valid_loss=1.040]\n","Epoch 140:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.320, valid_loss=1.040]\n","Epoch 142:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.250, valid_loss=1.040]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:27:57,013\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=12178)\u001b[0m \n","\u001b[36m(_train_tune pid=12178)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","\u001b[36m(_train_tune pid=12178)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 186.48it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12178)\u001b[0m \n","\u001b[36m(_train_tune pid=12178)\u001b[0m \r                                                                       \u001b[A\rEpoch 142:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.250, valid_loss=1.040]\rEpoch 142:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.300, valid_loss=1.040]\rEpoch 142:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.300, valid_loss=1.040]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=12178)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n","\u001b[36m(_train_tune pid=12354)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=12354)\u001b[0m Seed set to 1\n","\u001b[36m(_train_tune pid=12354)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=12354)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=12354)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 2025-06-14 19:28:07.867263: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=12354)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=12354)\u001b[0m E0000 00:00:1749929287.900700   12440 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=12354)\u001b[0m E0000 00:00:1749929287.910683   12440 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 2025-06-14 19:28:07.941338: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=12354)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=12354)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=12354)\u001b[0m \n","\u001b[36m(_train_tune pid=12354)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=12354)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=12354)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=12354)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.300]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.320]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.230]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.190]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.270]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.770]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.470]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 214.54it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.580, valid_loss=1.150]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.490, valid_loss=1.150]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.490, valid_loss=1.150]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.410, valid_loss=1.150]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.520, valid_loss=1.150]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.510, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 231.41it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.510, valid_loss=1.150]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.500, valid_loss=1.150]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.420, valid_loss=1.150]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.410, valid_loss=1.150]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.460, valid_loss=1.150]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.460, valid_loss=1.150]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.480, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.80it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.620, valid_loss=1.140]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.510, valid_loss=1.140]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.540, valid_loss=1.140]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.360, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12354)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 157.15it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.490, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12354)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 230.64it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.410, valid_loss=1.140]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.440, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12354)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 214.98it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.410, valid_loss=1.140]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.380, valid_loss=1.140]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 45: 100%|██████████| 7/7 [00:00<00:00, 81.81it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.400, valid_loss=1.140]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 78.92it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.440, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 229.86it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.390, valid_loss=1.140]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.470, valid_loss=1.140]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:28:17,235\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=12354)\u001b[0m \rEpoch 55: 100%|██████████| 7/7 [00:00<00:00, 77.92it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.470, valid_loss=1.140]\rEpoch 55: 100%|██████████| 7/7 [00:00<00:00, 77.26it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.470, valid_loss=1.140]\rEpoch 55: 100%|██████████| 7/7 [00:00<00:00, 76.85it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.500, valid_loss=1.140]\rEpoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.500, valid_loss=1.140]        \rEpoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.500, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12354)\u001b[0m \rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 78.74it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.500, valid_loss=1.140]\rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 78.03it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.500, valid_loss=1.140]\rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 77.62it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.440, valid_loss=1.140]\rEpoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.440, valid_loss=1.140]        \rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.440, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12354)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12354)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12354)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12354)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 224.97it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12354)\u001b[0m \r                                                                       \u001b[A\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.440, valid_loss=1.150]\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=1.150]\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=1.150]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=12489)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=12489)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=12489)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=12489)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=12489)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 2025-06-14 19:28:28.832124: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=12489)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=12489)\u001b[0m E0000 00:00:1749929308.855655   12577 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=12489)\u001b[0m E0000 00:00:1749929308.862746   12577 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 2025-06-14 19:28:28.886148: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=12489)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=12489)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=12489)\u001b[0m \n","\u001b[36m(_train_tune pid=12489)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=12489)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=12489)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=12489)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.320]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=2.130]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.590]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.450]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.590]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.520]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12489)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 158.49it/s]\u001b[A\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.570, valid_loss=1.150]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.530, valid_loss=1.150]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.380, valid_loss=1.150]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.540, valid_loss=1.150]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.490, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12489)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 105.78it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.530, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12489)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 177.29it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.530, valid_loss=1.160]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.500, valid_loss=1.160]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.460, valid_loss=1.160]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.520, valid_loss=1.160]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.460, valid_loss=1.160]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.550, valid_loss=1.160]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.450, valid_loss=1.160]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:28:35,360\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=12489)\u001b[0m \rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 63.23it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.450, valid_loss=1.160]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 63.01it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.450, valid_loss=1.160]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 62.69it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.620, valid_loss=1.160]\rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.620, valid_loss=1.160]        \rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.620, valid_loss=1.160]\n","\u001b[36m(_train_tune pid=12489)\u001b[0m \n","\u001b[36m(_train_tune pid=12489)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12489)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12489)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12489)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 160.42it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12489)\u001b[0m \r                                                                       \u001b[A\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.620, valid_loss=1.150]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.550, valid_loss=1.150]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.550, valid_loss=1.150]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=12620)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=12620)\u001b[0m Seed set to 7\n","\u001b[36m(_train_tune pid=12620)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=12620)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=12620)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 2025-06-14 19:28:45.506690: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=12620)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=12620)\u001b[0m E0000 00:00:1749929325.530470   12700 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=12620)\u001b[0m E0000 00:00:1749929325.537665   12700 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 2025-06-14 19:28:45.567441: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=12620)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=12620)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","\u001b[36m(_train_tune pid=12620)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=12620)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=12620)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=12620)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 31.15it/s, v_num=0, train_loss_step=2.420]\n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.340]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=2.070]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.660]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.560]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.540]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=1.640]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 120.46it/s]\u001b[A\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.540, valid_loss=1.150]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.510, valid_loss=1.150]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.510, valid_loss=1.150]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.450, valid_loss=1.150]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.480, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 198.29it/s]\u001b[A\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.470, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 213.09it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.580, valid_loss=1.140]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.550, valid_loss=1.140]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.430, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 208.08it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=1.140]\n","Epoch 34: 100%|██████████| 7/7 [00:00<00:00, 79.95it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.580, valid_loss=1.140]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.580, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 214.74it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.580, valid_loss=1.140]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.510, valid_loss=1.140]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.400, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 198.51it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.380, valid_loss=1.120]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.460, valid_loss=1.120]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.410, valid_loss=1.120]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.400, valid_loss=1.120]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.440, valid_loss=1.120]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 83.78it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.460, valid_loss=1.120]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.90it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.370, valid_loss=1.140]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.380, valid_loss=1.140]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 56: 100%|██████████| 7/7 [00:00<00:00, 81.92it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.380, valid_loss=1.140]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.380, valid_loss=1.140]        \n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.380, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 225.15it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.380, valid_loss=1.120]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.430, valid_loss=1.120]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.470, valid_loss=1.120]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.410, valid_loss=1.120]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.460, valid_loss=1.120]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.370, valid_loss=1.120]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.420, valid_loss=1.120]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.99it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.420, valid_loss=1.100]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.440, valid_loss=1.100]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.370, valid_loss=1.100]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.400, valid_loss=1.100]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.460, valid_loss=1.100]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.500, valid_loss=1.100]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=1.630, valid_loss=1.100]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 217.58it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.630, valid_loss=1.090]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=1.090]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.430, valid_loss=1.090]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.380, valid_loss=1.090]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.380, valid_loss=1.090]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.410, valid_loss=1.090]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.370, valid_loss=1.090]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 174.16it/s]\u001b[A\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.430, valid_loss=1.100]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.410, valid_loss=1.100]\n","Epoch 82:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.400, valid_loss=1.100]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.330, valid_loss=1.100]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.350, valid_loss=1.100]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.390, valid_loss=1.100]\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.83it/s]\u001b[A\n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.320, valid_loss=1.070]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.350, valid_loss=1.070]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.430, valid_loss=1.070]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.370, valid_loss=1.070]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.350, valid_loss=1.070]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.320, valid_loss=1.070]\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.420, valid_loss=1.070]\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 178.25it/s]\u001b[A\n","Epoch 93:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.350, valid_loss=1.060]\n","Epoch 94:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.350, valid_loss=1.060]\n","Epoch 95:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.380, valid_loss=1.060]\n","Epoch 96:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.530, valid_loss=1.060]\n","Epoch 97:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.260, valid_loss=1.060]\n","Epoch 99:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.350, valid_loss=1.060]\n","Epoch 99: 100%|██████████| 7/7 [00:00<00:00, 77.24it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.350, valid_loss=1.060]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 191.51it/s]\u001b[A\n","Epoch 100:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.340, valid_loss=1.060]\n","Epoch 101:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.280, valid_loss=1.060]\n","Epoch 102:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.280, valid_loss=1.060]\n","Epoch 103:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.320, valid_loss=1.060]\n","Epoch 104:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.450, valid_loss=1.060]\n","Epoch 105:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.330, valid_loss=1.060]\n","Epoch 106:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.310, valid_loss=1.060]\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.550, valid_loss=1.060]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 134.98it/s]\u001b[A\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.550, valid_loss=1.050]\n","Epoch 108:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.300, valid_loss=1.050]\n","Epoch 109:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.390, valid_loss=1.050]\n","Epoch 110:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.390, valid_loss=1.050]\n","Epoch 111:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.420, valid_loss=1.050]\n","Epoch 112:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.320, valid_loss=1.050]\n","Epoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.310, valid_loss=1.050]\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.340, valid_loss=1.050]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 118.54it/s]\u001b[A\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.340, valid_loss=1.060]\n","Epoch 115:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.330, valid_loss=1.060]\n","Epoch 116:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.320, valid_loss=1.060]\n","Epoch 117:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.330, valid_loss=1.060]\n","Epoch 118:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.540, valid_loss=1.060]\n","Epoch 119:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.360, valid_loss=1.060]\n","Epoch 120:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.340, valid_loss=1.060]\n","Epoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.270, valid_loss=1.060]\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 136.77it/s]\u001b[A\n","Epoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.270, valid_loss=1.050]\n","Epoch 122:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.510, valid_loss=1.050]\n","Epoch 123:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.340, valid_loss=1.050]\n","Epoch 124:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.310, valid_loss=1.050]\n","Epoch 125:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.360, valid_loss=1.050]\n","Epoch 126:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.350, valid_loss=1.050]\n","Epoch 127:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.340, valid_loss=1.050]\n","Epoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.340, valid_loss=1.050]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 144.25it/s]\u001b[A\n","Epoch 129:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.370, valid_loss=1.050]\n","Epoch 130:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.350, valid_loss=1.050]\n","Epoch 131:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.410, valid_loss=1.050]\n","Epoch 132:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.330, valid_loss=1.050]\n","Epoch 133:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.330, valid_loss=1.050]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:29:03,790\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=12620)\u001b[0m \rEpoch 133: 100%|██████████| 7/7 [00:00<00:00, 82.48it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.330, valid_loss=1.050]\rEpoch 133: 100%|██████████| 7/7 [00:00<00:00, 81.67it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.330, valid_loss=1.050]\rEpoch 133: 100%|██████████| 7/7 [00:00<00:00, 81.07it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.260, valid_loss=1.050]\rEpoch 133:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.260, valid_loss=1.050]        \rEpoch 134:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.260, valid_loss=1.050]\n","Epoch 135:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.330, valid_loss=1.050]\n","\u001b[36m(_train_tune pid=12620)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 213.22it/s]\u001b[A\n","Epoch 135:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.290, valid_loss=1.060]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=12787)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=12787)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=12787)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=12787)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=12787)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 2025-06-14 19:29:15.508840: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=12787)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=12787)\u001b[0m E0000 00:00:1749929355.560555   12874 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=12787)\u001b[0m E0000 00:00:1749929355.572634   12874 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 2025-06-14 19:29:15.617389: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=12787)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=12787)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=12787)\u001b[0m \n","\u001b[36m(_train_tune pid=12787)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=12787)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=12787)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=12787)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=12787)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","                                                                           \n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.290]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.920]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.490]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.530]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.590]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12787)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 160.13it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.590, valid_loss=1.150]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.480, valid_loss=1.150]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.440, valid_loss=1.150]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.480, valid_loss=1.150]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.480, valid_loss=1.150]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.600, valid_loss=1.150]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.420, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 229.41it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.410, valid_loss=1.140]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=1.140]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.540, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 186.09it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.540, valid_loss=1.160]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.570, valid_loss=1.160]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.460, valid_loss=1.160]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.470, valid_loss=1.160]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.420, valid_loss=1.160]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.550, valid_loss=1.160]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:29:21,738\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=12787)\u001b[0m \rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 81.50it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.550, valid_loss=1.160]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 81.03it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.550, valid_loss=1.160]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 80.58it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.450, valid_loss=1.160]\rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.450, valid_loss=1.160]        \rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.450, valid_loss=1.160]\n","\u001b[36m(_train_tune pid=12787)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12787)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12787)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12787)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.88it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12787)\u001b[0m \r                                                                       \u001b[A\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.450, valid_loss=1.150]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.390, valid_loss=1.150]\n","\u001b[36m(_train_tune pid=12787)\u001b[0m \rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.390, valid_loss=1.150]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=12914)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=12914)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=12914)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=12914)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=12914)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 2025-06-14 19:29:33.422273: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=12914)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=12914)\u001b[0m E0000 00:00:1749929373.450055   12998 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=12914)\u001b[0m E0000 00:00:1749929373.457491   12998 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 2025-06-14 19:29:33.481327: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=12914)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=12914)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \n","\u001b[36m(_train_tune pid=12914)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=12914)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=12914)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=12914)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.180]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.670]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.650]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.480]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.400]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.520]\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 214.30it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.520, valid_loss=1.150]\n","Epoch 8: 100%|██████████| 7/7 [00:00<00:00, 83.40it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.490, valid_loss=1.150]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.510, valid_loss=1.150]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.470, valid_loss=1.150]\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 231.83it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.560, valid_loss=1.140]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.620, valid_loss=1.140]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.510, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 222.99it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.510, valid_loss=1.140]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.570, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 101.27it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.480, valid_loss=1.120]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.510, valid_loss=1.120]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.450, valid_loss=1.120]\n","Epoch 31: 100%|██████████| 7/7 [00:00<00:00, 57.27it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.400, valid_loss=1.120]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.400, valid_loss=1.120]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.470, valid_loss=1.120]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.360, valid_loss=1.120]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.340, valid_loss=1.120]\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 177.92it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.340, valid_loss=1.110]\n","Epoch 36: 100%|██████████| 7/7 [00:00<00:00, 74.15it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=1.110]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.460, valid_loss=1.110]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.430, valid_loss=1.110]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.370, valid_loss=1.110]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.350, valid_loss=1.110]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.430, valid_loss=1.110]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.390, valid_loss=1.110]\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 129.56it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.310, valid_loss=1.120]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.400, valid_loss=1.120]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.410, valid_loss=1.120]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.350, valid_loss=1.120]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.380, valid_loss=1.120]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.420, valid_loss=1.120]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.500, valid_loss=1.120]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 63.08it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.500, valid_loss=1.120]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 134.67it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.430, valid_loss=1.080]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.240, valid_loss=1.080]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.340, valid_loss=1.080]\n","Epoch 53: 100%|██████████| 7/7 [00:00<00:00, 73.34it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.350, valid_loss=1.080]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.350, valid_loss=1.080]        \n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.350, valid_loss=1.080]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.330, valid_loss=1.080]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.290, valid_loss=1.080]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.330, valid_loss=1.080]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 225.66it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.330, valid_loss=1.070]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.440, valid_loss=1.070]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.350, valid_loss=1.070]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.350, valid_loss=1.070]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.360, valid_loss=1.070]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.330, valid_loss=1.070]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.440, valid_loss=1.070]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.300, valid_loss=1.070]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 222.15it/s]\u001b[A\n","                                                                       \u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.300, valid_loss=1.060]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.300, valid_loss=1.060]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.270, valid_loss=1.060]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.470, valid_loss=1.060]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.350, valid_loss=1.060]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.290, valid_loss=1.060]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.270, valid_loss=1.060]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 228.58it/s]\u001b[A\n","                                                                       \u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.270, valid_loss=1.060]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.410, valid_loss=1.060]\n","Epoch 73: 100%|██████████| 7/7 [00:00<00:00, 81.54it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.340, valid_loss=1.060]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.340, valid_loss=1.060]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.260, valid_loss=1.060]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.310, valid_loss=1.060]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.400, valid_loss=1.060]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.360, valid_loss=1.060]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 199.03it/s]\u001b[A\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.290, valid_loss=1.060]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.290, valid_loss=1.060]\n","Epoch 82:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.440, valid_loss=1.060]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.280, valid_loss=1.060]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.360, valid_loss=1.060]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.330, valid_loss=1.060]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.54it/s]\u001b[A\n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.300, valid_loss=1.060]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.370, valid_loss=1.060]\n","Epoch 87: 100%|██████████| 7/7 [00:00<00:00, 82.51it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.370, valid_loss=1.060]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.340, valid_loss=1.060]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.380, valid_loss=1.060]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.400, valid_loss=1.060]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:29:46,450\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=12914)\u001b[0m \rEpoch 90: 100%|██████████| 7/7 [00:00<00:00, 82.16it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.400, valid_loss=1.060]\rEpoch 90: 100%|██████████| 7/7 [00:00<00:00, 81.27it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.400, valid_loss=1.060]\rEpoch 90: 100%|██████████| 7/7 [00:00<00:00, 80.84it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.280, valid_loss=1.060]\rEpoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.280, valid_loss=1.060]        \rEpoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.280, valid_loss=1.060]\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \rEpoch 91: 100%|██████████| 7/7 [00:00<00:00, 79.69it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.280, valid_loss=1.060]\rEpoch 91: 100%|██████████| 7/7 [00:00<00:00, 78.94it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.280, valid_loss=1.060]\rEpoch 91: 100%|██████████| 7/7 [00:00<00:00, 78.53it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.380, valid_loss=1.060]\rEpoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.380, valid_loss=1.060]        \rEpoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.380, valid_loss=1.060]\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=12914)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 193.38it/s]\u001b[A\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.390, valid_loss=1.060]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=13070)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=13070)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=13070)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=13070)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=13070)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 2025-06-14 19:29:57.596611: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=13070)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=13070)\u001b[0m E0000 00:00:1749929397.628707   13150 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=13070)\u001b[0m E0000 00:00:1749929397.636199   13150 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 2025-06-14 19:29:57.659764: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=13070)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=13070)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","\u001b[36m(_train_tune pid=13070)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=13070)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=13070)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=13070)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.160]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.560]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.660]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.480]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.410]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.540]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.520]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 217.21it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.520, valid_loss=1.150]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.490, valid_loss=1.150]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.520, valid_loss=1.150]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.470, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 191.04it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.520, valid_loss=1.150]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.560, valid_loss=1.150]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.450, valid_loss=1.150]\n","Epoch 17: 100%|██████████| 7/7 [00:00<00:00, 77.69it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.540, valid_loss=1.150]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.540, valid_loss=1.150]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.620, valid_loss=1.150]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.440, valid_loss=1.150]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.520, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 183.72it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.540, valid_loss=1.150]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.490, valid_loss=1.150]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.490, valid_loss=1.150]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.500, valid_loss=1.150]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.500, valid_loss=1.150]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.580, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 191.37it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.510, valid_loss=1.140]\n","Epoch 31: 100%|██████████| 7/7 [00:00<00:00, 84.33it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.360, valid_loss=1.140]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.330, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 208.28it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.340, valid_loss=1.120]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.450, valid_loss=1.120]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.430, valid_loss=1.120]\n","Epoch 38: 100%|██████████| 7/7 [00:00<00:00, 74.91it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.430, valid_loss=1.120]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.380, valid_loss=1.120]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.370, valid_loss=1.120]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=1.120]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.390, valid_loss=1.120]\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 219.45it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.310, valid_loss=1.100]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.390, valid_loss=1.100]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.410, valid_loss=1.100]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.360, valid_loss=1.100]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.400, valid_loss=1.100]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.490, valid_loss=1.100]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 70.44it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.490, valid_loss=1.100]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 111.15it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.460, valid_loss=1.090]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.270, valid_loss=1.090]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.350, valid_loss=1.090]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.350, valid_loss=1.090]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.370, valid_loss=1.090]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.330, valid_loss=1.090]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.300, valid_loss=1.090]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.340, valid_loss=1.090]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 105.45it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.340, valid_loss=1.070]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.440, valid_loss=1.070]\n","Epoch 59: 100%|██████████| 7/7 [00:00<00:00, 72.46it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.350, valid_loss=1.070]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.350, valid_loss=1.070]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.350, valid_loss=1.070]\n","Epoch 61: 100%|██████████| 7/7 [00:00<00:00, 65.75it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.350, valid_loss=1.070]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.320, valid_loss=1.070]\n","Epoch 62: 100%|██████████| 7/7 [00:00<00:00, 64.67it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.440, valid_loss=1.070]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.300, valid_loss=1.070]\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 121.76it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.290, valid_loss=1.050]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.260, valid_loss=1.050]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.370, valid_loss=1.050]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.480, valid_loss=1.050]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.360, valid_loss=1.050]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.300, valid_loss=1.050]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.280, valid_loss=1.050]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 107.00it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.280, valid_loss=1.060]\n","Epoch 71: 100%|██████████| 7/7 [00:00<00:00, 35.15it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.410, valid_loss=1.060]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.410, valid_loss=1.060]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.340, valid_loss=1.060]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.340, valid_loss=1.060]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.250, valid_loss=1.060]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.400, valid_loss=1.060]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.360, valid_loss=1.060]\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 228.22it/s]\u001b[A\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.280, valid_loss=1.040]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.280, valid_loss=1.040]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.380, valid_loss=1.040]\n","Epoch 82:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.430, valid_loss=1.040]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.350, valid_loss=1.040]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.320, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 224.64it/s]\u001b[A\n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.280, valid_loss=1.050]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=1.050]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.330, valid_loss=1.050]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.360, valid_loss=1.050]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.380, valid_loss=1.050]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.270, valid_loss=1.050]\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.380, valid_loss=1.050]\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 230.95it/s]\u001b[A\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.380, valid_loss=1.040]\n","Epoch 92: 100%|██████████| 7/7 [00:00<00:00, 49.53it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.380, valid_loss=1.040]\n","Epoch 93:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.400, valid_loss=1.040]\n","Epoch 94:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.250, valid_loss=1.040]\n","Epoch 95:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.450, valid_loss=1.040]\n","Epoch 96:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.320, valid_loss=1.040]\n","Epoch 97:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.250, valid_loss=1.040]\n","Epoch 97:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.310, valid_loss=1.040]        \n","Epoch 98:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.310, valid_loss=1.040]\n","Epoch 99:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.380, valid_loss=1.040]\n","Epoch 99: 100%|██████████| 7/7 [00:00<00:00, 79.28it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.380, valid_loss=1.040]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 222.96it/s]\u001b[A\n","Epoch 100:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.250, valid_loss=1.040]\n","Epoch 101:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.340, valid_loss=1.040]\n","Epoch 102:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.360, valid_loss=1.040]\n","Epoch 103:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.310, valid_loss=1.040]\n","Epoch 104:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.340, valid_loss=1.040]\n","Epoch 106:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.310, valid_loss=1.040]\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.340, valid_loss=1.040]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 200.19it/s]\u001b[A\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.340, valid_loss=1.040]\n","Epoch 109:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.300, valid_loss=1.040]\n","Epoch 110:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.330, valid_loss=1.040]\n","Epoch 111:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.410, valid_loss=1.040]\n","Epoch 112:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.380, valid_loss=1.040]\n","Epoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.290, valid_loss=1.040]\n","Epoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.340, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 200.60it/s]\u001b[A\n","Epoch 115:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.360, valid_loss=1.040]\n","Epoch 116:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.320, valid_loss=1.040]\n","Epoch 117:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.310, valid_loss=1.040]\n","Epoch 118:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.320, valid_loss=1.040]\n","Epoch 119:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.470, valid_loss=1.040]\n","Epoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.280, valid_loss=1.040]\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 216.55it/s]\u001b[A\n","Epoch 121:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.280, valid_loss=1.050]\n","Epoch 123:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.360, valid_loss=1.050]\n","Epoch 124:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.340, valid_loss=1.050]\n","Epoch 125:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.340, valid_loss=1.050]\n","Epoch 126:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.330, valid_loss=1.050]\n","Epoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.300, valid_loss=1.050]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:30:14,177\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=13070)\u001b[0m \n","\u001b[36m(_train_tune pid=13070)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 221.79it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13070)\u001b[0m \r                                                                       \u001b[A\rEpoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.300, valid_loss=1.040]\rEpoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.380, valid_loss=1.040]\rEpoch 128:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.380, valid_loss=1.040]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=13235)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=13235)\u001b[0m Seed set to 9\n","\u001b[36m(_train_tune pid=13235)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=13235)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=13235)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 2025-06-14 19:30:24.589485: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=13235)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=13235)\u001b[0m E0000 00:00:1749929424.615768   13315 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=13235)\u001b[0m E0000 00:00:1749929424.623966   13315 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 2025-06-14 19:30:24.650287: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=13235)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=13235)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=13235)\u001b[0m \n","\u001b[36m(_train_tune pid=13235)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=13235)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=13235)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=13235)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=13235)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.340]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.290]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.960]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.510]\n","\u001b[36m(_train_tune pid=13235)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 212.05it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.510, valid_loss=1.180]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.570, valid_loss=1.180]\n","Epoch 8: 100%|██████████| 7/7 [00:00<00:00, 80.87it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.570, valid_loss=1.180]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.540, valid_loss=1.180]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.380, valid_loss=1.180]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.580, valid_loss=1.180]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.550, valid_loss=1.180]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.500, valid_loss=1.180]\n","\u001b[36m(_train_tune pid=13235)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 193.49it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.520, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 219.57it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.520, valid_loss=1.130]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.490, valid_loss=1.130]\n","Epoch 22: 100%|██████████| 7/7 [00:00<00:00, 79.42it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.490, valid_loss=1.130]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.450, valid_loss=1.130]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.500, valid_loss=1.130]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.440, valid_loss=1.130]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.540, valid_loss=1.130]\n","Epoch 27: 100%|██████████| 7/7 [00:00<00:00, 82.62it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.430, valid_loss=1.130]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.600, valid_loss=1.130]\n","\u001b[36m(_train_tune pid=13235)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.30it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.600, valid_loss=1.140]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 29: 100%|██████████| 7/7 [00:00<00:00, 80.29it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.540, valid_loss=1.140]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.390, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=13235)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 199.80it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.390, valid_loss=1.110]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.510, valid_loss=1.110]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.530, valid_loss=1.110]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.510, valid_loss=1.110]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.480, valid_loss=1.110]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.510, valid_loss=1.110]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.420, valid_loss=1.110]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13235)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 184.53it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.390, valid_loss=1.110]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.470, valid_loss=1.110]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.430, valid_loss=1.110]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.400, valid_loss=1.110]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.390, valid_loss=1.110]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.360, valid_loss=1.110]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.430, valid_loss=1.110]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 63.75it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.430, valid_loss=1.110]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13235)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 109.79it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.450, valid_loss=1.130]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.380, valid_loss=1.130]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.400, valid_loss=1.130]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.430, valid_loss=1.130]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.500, valid_loss=1.130]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.420, valid_loss=1.130]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.420, valid_loss=1.130]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:30:33,873\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=13235)\u001b[0m \rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 64.63it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.420, valid_loss=1.130]\rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 64.41it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.420, valid_loss=1.130]\rEpoch 56: 100%|██████████| 7/7 [00:00<00:00, 63.99it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.480, valid_loss=1.130]\rEpoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.480, valid_loss=1.130]        \rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.480, valid_loss=1.130]\n","\u001b[36m(_train_tune pid=13235)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13235)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13235)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13235)\u001b[0m \n","\u001b[36m(_train_tune pid=13235)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 97.34it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13235)\u001b[0m \r                                                                      \u001b[A\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.480, valid_loss=1.130]\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=1.130]\rEpoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=1.130]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=13362)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=13362)\u001b[0m Seed set to 3\n","\u001b[36m(_train_tune pid=13362)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=13362)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=13362)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 2025-06-14 19:30:44.887425: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=13362)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=13362)\u001b[0m E0000 00:00:1749929444.910205   13448 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=13362)\u001b[0m E0000 00:00:1749929444.917575   13448 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 2025-06-14 19:30:44.940823: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=13362)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=13362)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=13362)\u001b[0m \n","\u001b[36m(_train_tune pid=13362)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=13362)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=13362)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=13362)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=2.380]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.310]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=2.060]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.640]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.550]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.490]\n","Epoch 6: 100%|██████████| 7/7 [00:00<00:00, 80.58it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.540]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.540]\n","\u001b[36m(_train_tune pid=13362)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.14it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.540, valid_loss=1.170]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.460, valid_loss=1.170]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.490, valid_loss=1.170]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.430, valid_loss=1.170]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.480, valid_loss=1.170]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.470, valid_loss=1.170]\n","\u001b[36m(_train_tune pid=13362)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 215.93it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.540, valid_loss=1.140]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 20: 100%|██████████| 7/7 [00:00<00:00, 81.89it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.500, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=13362)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 227.40it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.500, valid_loss=1.150]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.570, valid_loss=1.150]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.450, valid_loss=1.150]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.450, valid_loss=1.150]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.430, valid_loss=1.150]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.480, valid_loss=1.150]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:30:51,938\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=13362)\u001b[0m \rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 82.78it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.480, valid_loss=1.150]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 81.89it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=1.150]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 81.39it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.460, valid_loss=1.150]\rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.460, valid_loss=1.150]        \rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.460, valid_loss=1.150]\n","\u001b[36m(_train_tune pid=13362)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13362)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13362)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13362)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 210.06it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13362)\u001b[0m \r                                                                       \u001b[A\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.460, valid_loss=1.140]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.550, valid_loss=1.140]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.550, valid_loss=1.140]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=13489)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=13489)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=13489)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=13489)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=13489)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 2025-06-14 19:31:02.563087: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=13489)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=13489)\u001b[0m E0000 00:00:1749929462.586484   13573 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=13489)\u001b[0m E0000 00:00:1749929462.593635   13573 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 2025-06-14 19:31:02.626032: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=13489)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=13489)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=13489)\u001b[0m \n","\u001b[36m(_train_tune pid=13489)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=13489)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=13489)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=13489)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.290]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.950]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.490]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.570]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.520]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.570]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 215.29it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.570, valid_loss=1.150]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.460, valid_loss=1.150]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.530, valid_loss=1.150]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.420, valid_loss=1.150]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.480, valid_loss=1.150]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.590, valid_loss=1.150]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.430, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13489)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 177.37it/s]\u001b[A\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=1.140]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.410, valid_loss=1.140]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.540, valid_loss=1.140]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.540, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13489)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 179.54it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.570, valid_loss=1.150]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.580, valid_loss=1.150]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.460, valid_loss=1.150]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.430, valid_loss=1.150]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=1.150]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:31:08,653\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=13489)\u001b[0m \rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 81.99it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=1.150]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 81.21it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.560, valid_loss=1.150]\rEpoch 27: 100%|██████████| 7/7 [00:00<00:00, 80.72it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.460, valid_loss=1.150]\rEpoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.460, valid_loss=1.150]        \rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.460, valid_loss=1.150]\n","\u001b[36m(_train_tune pid=13489)\u001b[0m \n","\u001b[36m(_train_tune pid=13489)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13489)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13489)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13489)\u001b[0m \n","\u001b[36m(_train_tune pid=13489)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 203.43it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13489)\u001b[0m \r                                                                       \u001b[A\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.460, valid_loss=1.150]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.390, valid_loss=1.150]\rEpoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.390, valid_loss=1.150]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=13612)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=13612)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=13612)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=13612)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=13612)\u001b[0m Seed set to 4\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 2025-06-14 19:31:20.410367: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=13612)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=13612)\u001b[0m E0000 00:00:1749929480.434539   13700 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=13612)\u001b[0m E0000 00:00:1749929480.441801   13700 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 2025-06-14 19:31:20.470548: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=13612)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=13612)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","\u001b[36m(_train_tune pid=13612)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=13612)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=13612)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=13612)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=13612)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.460]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.290]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=2.150]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=2.250]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.130]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=2.090]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.740]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 170.48it/s]\u001b[A\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.610, valid_loss=1.200]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.500, valid_loss=1.200]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.430, valid_loss=1.200]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.460, valid_loss=1.200]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.460, valid_loss=1.200]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.430, valid_loss=1.200]\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 146.55it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.430, valid_loss=1.150]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.420, valid_loss=1.150]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.530, valid_loss=1.150]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.460, valid_loss=1.150]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.550, valid_loss=1.150]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.530, valid_loss=1.150]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.450, valid_loss=1.150]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.410, valid_loss=1.150]\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 115.15it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.570, valid_loss=1.140]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.540, valid_loss=1.140]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.450, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 182.00it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.540, valid_loss=1.140]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.510, valid_loss=1.140]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.510, valid_loss=1.140]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.550, valid_loss=1.140]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.380, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 140.73it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.390, valid_loss=1.140]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.440, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 193.93it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 44: 100%|██████████| 7/7 [00:00<00:00, 83.30it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 82.78it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.600, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.48it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.410, valid_loss=1.140]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.550, valid_loss=1.140]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.440, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 196.66it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.550, valid_loss=1.140]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.550, valid_loss=1.140]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.460, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.75it/s]\u001b[A\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.410, valid_loss=1.140]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.470, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 207.22it/s]\u001b[A\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.460, valid_loss=1.130]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.350, valid_loss=1.130]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.480, valid_loss=1.130]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.440, valid_loss=1.130]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.450, valid_loss=1.130]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.430, valid_loss=1.130]\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 204.70it/s]\u001b[A\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.480, valid_loss=1.120]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.460, valid_loss=1.120]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.430, valid_loss=1.120]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.360, valid_loss=1.120]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.420, valid_loss=1.120]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.470, valid_loss=1.120]\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 225.69it/s]\u001b[A\n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.460, valid_loss=1.130]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.430, valid_loss=1.130]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.600, valid_loss=1.130]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.470, valid_loss=1.130]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.460, valid_loss=1.130]\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.460, valid_loss=1.130]\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 219.95it/s]\u001b[A\n","Epoch 93:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.410, valid_loss=1.100]\n","Epoch 94:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.410, valid_loss=1.100]\n","Epoch 95:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.620, valid_loss=1.100]\n","Epoch 97:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.400, valid_loss=1.100]\n","Epoch 98:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.360, valid_loss=1.100]\n","Epoch 99:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.400, valid_loss=1.100]\n","Epoch 99: 100%|██████████| 7/7 [00:00<00:00, 83.37it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=1.400, valid_loss=1.100]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 224.75it/s]\u001b[A\n","Epoch 100:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=1.500, valid_loss=1.100]\n","Epoch 101:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.440, valid_loss=1.100]\n","Epoch 102:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.390, valid_loss=1.100]\n","Epoch 104:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.400, valid_loss=1.100]\n","Epoch 105:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=1.100]\n","Epoch 106:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.510, valid_loss=1.100]\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.480, valid_loss=1.100]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 216.81it/s]\u001b[A\n","Epoch 107:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.480, valid_loss=1.110]\n","Epoch 108:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.460, valid_loss=1.110]\n","Epoch 109:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.480, valid_loss=1.110]\n","Epoch 111:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.500, valid_loss=1.110]\n","Epoch 112:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.400, valid_loss=1.110]\n","Epoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.450, valid_loss=1.110]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:31:35,504\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=13612)\u001b[0m \rEpoch 113: 100%|██████████| 7/7 [00:00<00:00, 79.82it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.450, valid_loss=1.110]\rEpoch 113: 100%|██████████| 7/7 [00:00<00:00, 79.46it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.450, valid_loss=1.110]\rEpoch 113: 100%|██████████| 7/7 [00:00<00:00, 78.88it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.440, valid_loss=1.110]\rEpoch 113:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.440, valid_loss=1.110]        \rEpoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.440, valid_loss=1.110]\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 213.41it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \r                                                                       \u001b[A\rEpoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.440, valid_loss=1.120]\n","\u001b[36m(_train_tune pid=13612)\u001b[0m \rEpoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.410, valid_loss=1.120]\rEpoch 114:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.410, valid_loss=1.120]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=13776)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=13776)\u001b[0m Seed set to 4\n","\u001b[36m(_train_tune pid=13776)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=13776)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=13776)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 2025-06-14 19:31:47.618591: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=13776)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=13776)\u001b[0m E0000 00:00:1749929507.644204   13864 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=13776)\u001b[0m E0000 00:00:1749929507.652320   13864 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 2025-06-14 19:31:47.681324: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=13776)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=13776)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \n","\u001b[36m(_train_tune pid=13776)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=13776)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=13776)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=13776)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.420]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.240]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.970]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.660]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.520]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.510]\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 147.19it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.510, valid_loss=1.180]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.510, valid_loss=1.180]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.480, valid_loss=1.180]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.420, valid_loss=1.180]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.460, valid_loss=1.180]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.480, valid_loss=1.180]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.460, valid_loss=1.180]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.440, valid_loss=1.180]\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 154.59it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.560, valid_loss=1.140]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.410, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 161.96it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.410, valid_loss=1.140]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.570, valid_loss=1.140]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.460, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 105.05it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.550, valid_loss=1.150]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.500, valid_loss=1.150]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.490, valid_loss=1.150]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.510, valid_loss=1.150]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.460, valid_loss=1.150]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:31:55,184\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=13776)\u001b[0m \rEpoch 33: 100%|██████████| 7/7 [00:00<00:00, 80.80it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.460, valid_loss=1.150]\rEpoch 33: 100%|██████████| 7/7 [00:00<00:00, 79.94it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.460, valid_loss=1.150]\rEpoch 33: 100%|██████████| 7/7 [00:00<00:00, 79.49it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.550, valid_loss=1.150]\rEpoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.550, valid_loss=1.150]        \rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.550, valid_loss=1.150]\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 80.38it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.550, valid_loss=1.150]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 80.05it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.550, valid_loss=1.150]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 78.79it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.390, valid_loss=1.150]\rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.390, valid_loss=1.150]        \rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.390, valid_loss=1.150]\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \n","\u001b[36m(_train_tune pid=13776)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 226.24it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13776)\u001b[0m \r                                                                       \u001b[A\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.390, valid_loss=1.140]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.340, valid_loss=1.140]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.340, valid_loss=1.140]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=13904)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=13904)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=13904)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=13904)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=13904)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 2025-06-14 19:32:05.960044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=13904)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=13904)\u001b[0m E0000 00:00:1749929526.012864   13988 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=13904)\u001b[0m E0000 00:00:1749929526.024547   13988 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 2025-06-14 19:32:06.060251: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=13904)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=13904)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=13904)\u001b[0m \n","\u001b[36m(_train_tune pid=13904)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=13904)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=13904)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=13904)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.340]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.290]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.170]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=2.160]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.010]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.630]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.600]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 220.35it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.600, valid_loss=1.160]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.480, valid_loss=1.160]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.430, valid_loss=1.160]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.480, valid_loss=1.160]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.470, valid_loss=1.160]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.590, valid_loss=1.160]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.420, valid_loss=1.160]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 200.72it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.410, valid_loss=1.140]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.400, valid_loss=1.140]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.520, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 224.41it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.560, valid_loss=1.140]\n","Epoch 23: 100%|██████████| 7/7 [00:00<00:00, 78.31it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.550, valid_loss=1.140]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.450, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 170.52it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13904)\u001b[0m \n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.400, valid_loss=1.140]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.410, valid_loss=1.140]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.430, valid_loss=1.140]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:32:13,327\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=13904)\u001b[0m \rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 83.02it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.430, valid_loss=1.140]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 82.23it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.430, valid_loss=1.140]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 81.78it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.470, valid_loss=1.140]\rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.470, valid_loss=1.140]        \rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.470, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=13904)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13904)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13904)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13904)\u001b[0m \n","\u001b[36m(_train_tune pid=13904)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 177.88it/s]\u001b[A\n","\u001b[36m(_train_tune pid=13904)\u001b[0m \r                                                                       \u001b[A\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.470, valid_loss=1.140]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.470, valid_loss=1.140]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.470, valid_loss=1.140]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=14031)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=14031)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=14031)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=14031)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=14031)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 2025-06-14 19:32:24.628343: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=14031)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=14031)\u001b[0m E0000 00:00:1749929544.654208   14119 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=14031)\u001b[0m E0000 00:00:1749929544.662279   14119 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 2025-06-14 19:32:24.686178: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=14031)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=14031)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \n","\u001b[36m(_train_tune pid=14031)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=14031)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=14031)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=14031)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=2.030]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.460]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.650]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.410]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.550]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.530]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 173.24it/s]\u001b[A\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.500, valid_loss=1.160]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.470, valid_loss=1.160]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.500, valid_loss=1.160]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.470, valid_loss=1.160]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.530, valid_loss=1.160]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.490, valid_loss=1.160]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.78it/s]\u001b[A\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=1.160]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.570, valid_loss=1.160]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.450, valid_loss=1.160]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.530, valid_loss=1.160]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.620, valid_loss=1.160]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.440, valid_loss=1.160]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.510, valid_loss=1.160]\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 201.81it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.540, valid_loss=1.150]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.490, valid_loss=1.150]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.440, valid_loss=1.150]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.500, valid_loss=1.150]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.500, valid_loss=1.150]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.580, valid_loss=1.150]\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 215.57it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=1.140]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.400, valid_loss=1.140]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.380, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 139.80it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.390, valid_loss=1.150]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.480, valid_loss=1.150]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.460, valid_loss=1.150]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.390, valid_loss=1.150]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.370, valid_loss=1.150]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.470, valid_loss=1.150]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:32:32,323\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=14031)\u001b[0m \rEpoch 41: 100%|██████████| 7/7 [00:00<00:00, 63.34it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.470, valid_loss=1.150]\rEpoch 41: 100%|██████████| 7/7 [00:00<00:00, 63.11it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.470, valid_loss=1.150]\rEpoch 41: 100%|██████████| 7/7 [00:00<00:00, 62.74it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.440, valid_loss=1.150]\rEpoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.440, valid_loss=1.150]        \rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.440, valid_loss=1.150]\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \n","\u001b[36m(_train_tune pid=14031)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 179.06it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14031)\u001b[0m \r                                                                       \u001b[A\rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.440, valid_loss=1.170]\rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.370, valid_loss=1.170]\rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.370, valid_loss=1.170]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=14160)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=14160)\u001b[0m Seed set to 6\n","\u001b[36m(_train_tune pid=14160)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=14160)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=14160)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 2025-06-14 19:32:42.279516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=14160)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=14160)\u001b[0m E0000 00:00:1749929562.302778   14242 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=14160)\u001b[0m E0000 00:00:1749929562.313414   14242 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 2025-06-14 19:32:42.341241: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=14160)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=14160)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=14160)\u001b[0m \n","\u001b[36m(_train_tune pid=14160)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=14160)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=14160)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=14160)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 25.81it/s, v_num=0, train_loss_step=2.260]\n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.310]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=2.200]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.650]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.490]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.560]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.520]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.580]\n","\u001b[36m(_train_tune pid=14160)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14160)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 148.41it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.580, valid_loss=1.160]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.470, valid_loss=1.160]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.530, valid_loss=1.160]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.410, valid_loss=1.160]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.470, valid_loss=1.160]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.490, valid_loss=1.160]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.600, valid_loss=1.160]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.420, valid_loss=1.160]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 223.35it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.420, valid_loss=1.150]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.410, valid_loss=1.150]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.400, valid_loss=1.150]\n","Epoch 16: 100%|██████████| 7/7 [00:00<00:00, 79.73it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.400, valid_loss=1.150]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.400, valid_loss=1.150]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.460, valid_loss=1.150]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.510, valid_loss=1.150]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.540, valid_loss=1.150]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.530, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 220.41it/s]\u001b[A\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.560, valid_loss=1.140]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.560, valid_loss=1.140]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.460, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 225.54it/s]\u001b[A\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.460, valid_loss=1.150]\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.420, valid_loss=1.150]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=1.150]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.510, valid_loss=1.150]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.420, valid_loss=1.150]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:32:49,984\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=14160)\u001b[0m \rEpoch 33: 100%|██████████| 7/7 [00:00<00:00, 76.88it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.420, valid_loss=1.150]\rEpoch 33: 100%|██████████| 7/7 [00:00<00:00, 76.53it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=1.150]\rEpoch 33: 100%|██████████| 7/7 [00:00<00:00, 75.95it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.440, valid_loss=1.150]\rEpoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.440, valid_loss=1.150]        \rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.440, valid_loss=1.150]\n","\u001b[36m(_train_tune pid=14160)\u001b[0m \rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 75.78it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.440, valid_loss=1.150]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 75.12it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.440, valid_loss=1.150]\rEpoch 34: 100%|██████████| 7/7 [00:00<00:00, 74.75it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.480, valid_loss=1.150]\rEpoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.480, valid_loss=1.150]        \rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.480, valid_loss=1.150]\n","\u001b[36m(_train_tune pid=14160)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14160)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14160)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14160)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 218.45it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14160)\u001b[0m \n","\u001b[36m(_train_tune pid=14160)\u001b[0m \r                                                                       \u001b[A\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.480, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=14160)\u001b[0m \rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.480, valid_loss=1.140]\rEpoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.480, valid_loss=1.140]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=14287)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=14287)\u001b[0m Seed set to 3\n","\u001b[36m(_train_tune pid=14287)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=14287)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=14287)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 2025-06-14 19:33:01.668983: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=14287)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=14287)\u001b[0m E0000 00:00:1749929581.699651   14374 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=14287)\u001b[0m E0000 00:00:1749929581.706995   14374 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 2025-06-14 19:33:01.731517: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=14287)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=14287)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=14287)\u001b[0m \n","\u001b[36m(_train_tune pid=14287)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=14287)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=14287)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=14287)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  6.88it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=2.400]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.360]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.250]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.280]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.310]\n","Epoch 5: 100%|██████████| 7/7 [00:00<00:00, 75.20it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.310]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.180]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.250]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14287)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.16it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=2.250, valid_loss=1.680]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.780, valid_loss=1.680]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.620, valid_loss=1.680]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.550, valid_loss=1.680]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.460, valid_loss=1.680]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.500, valid_loss=1.680]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.470, valid_loss=1.680]\n","\u001b[36m(_train_tune pid=14287)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 219.01it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 17: 100%|██████████| 7/7 [00:00<00:00, 72.99it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.540, valid_loss=1.150]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.540, valid_loss=1.150]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.480, valid_loss=1.150]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.460, valid_loss=1.150]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.490, valid_loss=1.150]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14287)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.54it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.560, valid_loss=1.140]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.460, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14287)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 197.67it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 31: 100%|██████████| 7/7 [00:00<00:00, 78.57it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.490, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14287)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 195.94it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.560, valid_loss=1.140]\n","Epoch 39:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=1.140]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:33:09,254\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=14287)\u001b[0m \rEpoch 40: 100%|██████████| 7/7 [00:00<00:00, 81.19it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=1.140]\rEpoch 40: 100%|██████████| 7/7 [00:00<00:00, 80.48it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.500, valid_loss=1.140]\rEpoch 40: 100%|██████████| 7/7 [00:00<00:00, 80.05it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.520, valid_loss=1.140]\rEpoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.520, valid_loss=1.140]        \rEpoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.520, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=14287)\u001b[0m \rEpoch 41: 100%|██████████| 7/7 [00:00<00:00, 79.81it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.520, valid_loss=1.140]\rEpoch 41: 100%|██████████| 7/7 [00:00<00:00, 79.05it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.520, valid_loss=1.140]\rEpoch 41: 100%|██████████| 7/7 [00:00<00:00, 78.64it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.440, valid_loss=1.140]\rEpoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.440, valid_loss=1.140]        \rEpoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.440, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=14287)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14287)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14287)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 182.18it/s]\u001b[A\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.410, valid_loss=1.140]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=14415)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=14415)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=14415)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=14415)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=14415)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 2025-06-14 19:33:21.225323: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=14415)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=14415)\u001b[0m E0000 00:00:1749929601.252047   14503 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=14415)\u001b[0m E0000 00:00:1749929601.263581   14503 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 2025-06-14 19:33:21.287924: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=14415)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=14415)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \n","\u001b[36m(_train_tune pid=14415)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=14415)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=14415)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=14415)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.220]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=2.170]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.400]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.170]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.990]\n","Epoch 6:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.770]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.550]\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 142.14it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.550, valid_loss=1.160]\n","Epoch 8:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.510, valid_loss=1.160]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.470, valid_loss=1.160]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.500, valid_loss=1.160]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.470, valid_loss=1.160]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.460, valid_loss=1.160]\n","Epoch 13:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.510, valid_loss=1.160]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.460, valid_loss=1.160]\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 178.52it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 15:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.510, valid_loss=1.140]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.550, valid_loss=1.140]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.610, valid_loss=1.140]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 20: 100%|██████████| 7/7 [00:00<00:00, 52.89it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.500, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 144.31it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.530, valid_loss=1.140]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 26:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.510, valid_loss=1.140]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.580, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 196.53it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 32: 100%|██████████| 7/7 [00:00<00:00, 78.64it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.390, valid_loss=1.140]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 212.51it/s]\u001b[A\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.390, valid_loss=1.140]\n","Epoch 37:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.480, valid_loss=1.140]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.400, valid_loss=1.140]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.430, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 228.59it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.360, valid_loss=1.140]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.440, valid_loss=1.140]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.450, valid_loss=1.140]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.420, valid_loss=1.140]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.460, valid_loss=1.140]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.540, valid_loss=1.140]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 78.30it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.540, valid_loss=1.140]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 222.76it/s]\u001b[A\n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.480, valid_loss=1.110]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.300, valid_loss=1.110]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.410, valid_loss=1.110]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.410, valid_loss=1.110]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.420, valid_loss=1.110]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.380, valid_loss=1.110]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.360, valid_loss=1.110]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.400, valid_loss=1.110]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 217.27it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.400, valid_loss=1.110]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.510, valid_loss=1.110]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.410, valid_loss=1.110]\n","Epoch 61:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.430, valid_loss=1.110]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.390, valid_loss=1.110]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.510, valid_loss=1.110]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.360, valid_loss=1.110]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 182.94it/s]\u001b[A\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.360, valid_loss=1.110]\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.360, valid_loss=1.110]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.340, valid_loss=1.110]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.450, valid_loss=1.110]\n","Epoch 68:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.550, valid_loss=1.110]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.430, valid_loss=1.110]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.360, valid_loss=1.110]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.350, valid_loss=1.110]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 227.67it/s]\u001b[A\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.350, valid_loss=1.100]\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.480, valid_loss=1.100]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.420, valid_loss=1.100]\n","Epoch 75:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.330, valid_loss=1.100]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.390, valid_loss=1.100]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.480, valid_loss=1.100]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.420, valid_loss=1.100]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 223.85it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.420, valid_loss=1.100]\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.360, valid_loss=1.100]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.450, valid_loss=1.100]\n","Epoch 82:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.520, valid_loss=1.100]\n","Epoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.370, valid_loss=1.100]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:33:33,683\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=14415)\u001b[0m \rEpoch 83: 100%|██████████| 7/7 [00:00<00:00, 80.59it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.370, valid_loss=1.100]\rEpoch 83: 100%|██████████| 7/7 [00:00<00:00, 79.79it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.370, valid_loss=1.100]\rEpoch 83: 100%|██████████| 7/7 [00:00<00:00, 79.29it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.450, valid_loss=1.100]\rEpoch 83:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.450, valid_loss=1.100]        \rEpoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.450, valid_loss=1.100]\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \rEpoch 84: 100%|██████████| 7/7 [00:00<00:00, 79.12it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.450, valid_loss=1.100]\rEpoch 84: 100%|██████████| 7/7 [00:00<00:00, 78.81it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.450, valid_loss=1.100]\rEpoch 84: 100%|██████████| 7/7 [00:00<00:00, 78.22it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.400, valid_loss=1.100]\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \rEpoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.400, valid_loss=1.100]        \rEpoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.400, valid_loss=1.100]\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \n","\u001b[36m(_train_tune pid=14415)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 148.11it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14415)\u001b[0m \n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.390, valid_loss=1.100]\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_train_tune pid=14570)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n","\u001b[36m(_train_tune pid=14570)\u001b[0m Seed set to 8\n","\u001b[36m(_train_tune pid=14570)\u001b[0m GPU available: True (cuda), used: True\n","\u001b[36m(_train_tune pid=14570)\u001b[0m TPU available: False, using: 0 TPU cores\n","\u001b[36m(_train_tune pid=14570)\u001b[0m HPU available: False, using: 0 HPUs\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 2025-06-14 19:33:44.784677: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(_train_tune pid=14570)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","\u001b[36m(_train_tune pid=14570)\u001b[0m E0000 00:00:1749929624.808352   14656 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(_train_tune pid=14570)\u001b[0m E0000 00:00:1749929624.815301   14656 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 2025-06-14 19:33:44.844141: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","\u001b[36m(_train_tune pid=14570)\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[36m(_train_tune pid=14570)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","\u001b[36m(_train_tune pid=14570)\u001b[0m   | Name         | Type          | Params | Mode \n","\u001b[36m(_train_tune pid=14570)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 0 | loss         | MQLoss        | 5      | train\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 3 | hist_encoder | LSTM          | 199 K  | train\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 4 | mlp_decoder  | MLP           | 17.2 K | train\n","\u001b[36m(_train_tune pid=14570)\u001b[0m -------------------------------------------------------\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 216 K     Trainable params\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 5         Non-trainable params\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 216 K     Total params\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 0.865     Total estimated model params size (MB)\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 10        Modules in train mode\n","\u001b[36m(_train_tune pid=14570)\u001b[0m 0         Modules in eval mode\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=14570)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n","Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n","Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] \n","Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.220]\n","Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=2.160]\n","Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.380]\n","Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=2.090]\n","Epoch 5:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.640]\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.530]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 194.32it/s]\u001b[A\n","Epoch 7:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.530, valid_loss=1.170]\n","Epoch 9:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.460, valid_loss=1.170]\n","Epoch 10:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.500, valid_loss=1.170]\n","Epoch 11:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.460, valid_loss=1.170]\n","Epoch 12:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.460, valid_loss=1.170]\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.470, valid_loss=1.170]\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 213.23it/s]\u001b[A\n","Epoch 14:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.470, valid_loss=1.150]\n","Epoch 16:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.560, valid_loss=1.150]\n","Epoch 17:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.450, valid_loss=1.150]\n","Epoch 18:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.530, valid_loss=1.150]\n","Epoch 19:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.620, valid_loss=1.150]\n","Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 77.95it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.430, valid_loss=1.150]\n","Epoch 20:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.430, valid_loss=1.150]\n","Epoch 21:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.500, valid_loss=1.150]\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 224.75it/s]\u001b[A\n","Epoch 22:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.520, valid_loss=1.140]\n","Epoch 23:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 24:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 25:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 27:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 28:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.580, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 214.50it/s]\u001b[A\n","Epoch 29:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.490, valid_loss=1.140]\n","Epoch 30:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.510, valid_loss=1.140]\n","Epoch 31:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.470, valid_loss=1.140]\n","Epoch 32:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.430, valid_loss=1.140]\n","Epoch 33:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.500, valid_loss=1.140]\n","Epoch 34:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.390, valid_loss=1.140]\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=1.140]\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 145.96it/s]\u001b[A\n","Epoch 35:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.370, valid_loss=1.130]\n","Epoch 35: 100%|██████████| 7/7 [00:00<00:00, 35.38it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.390, valid_loss=1.130]\n","Epoch 36:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.390, valid_loss=1.130]\n","Epoch 36: 100%|██████████| 7/7 [00:00<00:00, 59.95it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.390, valid_loss=1.130]\n","Epoch 37: 100%|██████████| 7/7 [00:00<00:00, 71.48it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.470, valid_loss=1.130]\n","Epoch 38:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.470, valid_loss=1.130]\n","Epoch 40:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=1.130]\n","Epoch 41:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.470, valid_loss=1.130]\n","Epoch 42:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.430, valid_loss=1.130]\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 137.94it/s]\u001b[A\n","Epoch 43:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.360, valid_loss=1.120]\n","Epoch 44:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.430, valid_loss=1.120]\n","Epoch 45:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.450, valid_loss=1.120]\n","Epoch 46:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.400, valid_loss=1.120]\n","Epoch 47:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.410, valid_loss=1.120]\n","Epoch 48:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.450, valid_loss=1.120]\n","Epoch 49:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.530, valid_loss=1.120]\n","Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 57.21it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.530, valid_loss=1.120]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 150.42it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Epoch 50:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.480, valid_loss=1.120]\n","Epoch 51:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.290, valid_loss=1.120]\n","Epoch 52:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.410, valid_loss=1.120]\n","Epoch 53:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.400, valid_loss=1.120]\n","Epoch 54:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.410, valid_loss=1.120]\n","Epoch 55:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.380, valid_loss=1.120]\n","Epoch 56:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.360, valid_loss=1.120]\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.390, valid_loss=1.120]\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 140.34it/s]\u001b[A\n","Epoch 57:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.390, valid_loss=1.110]\n","Epoch 58:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.510, valid_loss=1.110]\n","Epoch 59:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.400, valid_loss=1.110]\n","Epoch 60:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.420, valid_loss=1.110]\n","Epoch 62:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.390, valid_loss=1.110]\n","Epoch 63:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.510, valid_loss=1.110]\n","Epoch 64:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.360, valid_loss=1.110]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 173.24it/s]\u001b[A\n","Epoch 65:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.360, valid_loss=1.100]\n","Epoch 66:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.340, valid_loss=1.100]\n","Epoch 67:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.450, valid_loss=1.100]\n","Epoch 69:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.420, valid_loss=1.100]\n","Epoch 70:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.360, valid_loss=1.100]\n","Epoch 71:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.340, valid_loss=1.100]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 185.96it/s]\u001b[A\n","Epoch 72:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.480, valid_loss=1.110]\n","Epoch 73:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.410, valid_loss=1.110]\n","Epoch 74:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.420, valid_loss=1.110]\n","Epoch 76:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.380, valid_loss=1.110]\n","Epoch 77:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.480, valid_loss=1.110]\n","Epoch 78:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.420, valid_loss=1.110]\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 211.23it/s]\u001b[A\n","Epoch 79:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.360, valid_loss=1.100]\n","Epoch 80:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.350, valid_loss=1.100]\n","Epoch 81:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.450, valid_loss=1.100]\n","Epoch 82:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.520, valid_loss=1.100]\n","Epoch 84:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.440, valid_loss=1.100]\n","Epoch 85:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.400, valid_loss=1.100]\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 205.11it/s]\u001b[A\n","Epoch 86:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.370, valid_loss=1.090]\n","Epoch 87:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.440, valid_loss=1.090]\n","Epoch 88:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.410, valid_loss=1.090]\n","Epoch 89:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.440, valid_loss=1.090]\n","Epoch 90:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.460, valid_loss=1.090]\n","Epoch 91:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.350, valid_loss=1.090]\n","Epoch 92:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.450, valid_loss=1.090]\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 223.47it/s]\u001b[A\n","Epoch 93:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.480, valid_loss=1.100]\n","Epoch 94:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.330, valid_loss=1.100]\n","Epoch 95:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.530, valid_loss=1.100]\n","Epoch 96:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.400, valid_loss=1.100]\n","Epoch 98:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=1.100]\n"]},{"output_type":"stream","name":"stderr","text":["2025-06-14 19:33:58,661\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'valid_loss': ('__ref_ph', '004b9a7a')}\n","2025-06-14 19:33:58,700\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/_train_tune_2025-06-14_19-26-43' in 0.0336s.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_train_tune pid=14570)\u001b[0m \rEpoch 98: 100%|██████████| 7/7 [00:00<00:00, 79.34it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=1.100]\rEpoch 98: 100%|██████████| 7/7 [00:00<00:00, 78.70it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.390, valid_loss=1.100]\rEpoch 98: 100%|██████████| 7/7 [00:00<00:00, 78.28it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.460, valid_loss=1.100]\rEpoch 98:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.460, valid_loss=1.100]        \rEpoch 99:   0%|          | 0/7 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.460, valid_loss=1.100]\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \rEpoch 99: 100%|██████████| 7/7 [00:00<00:00, 74.97it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.460, valid_loss=1.100]\rEpoch 99: 100%|██████████| 7/7 [00:00<00:00, 74.34it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.460, valid_loss=1.100]\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \rValidation:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 209.26it/s]\u001b[A\n","\u001b[36m(_train_tune pid=14570)\u001b[0m \r                                                                       \u001b[A\rEpoch 99: 100%|██████████| 7/7 [00:00<00:00, 50.52it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.460, valid_loss=1.120]\rEpoch 99: 100%|██████████| 7/7 [00:00<00:00, 50.20it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.320, valid_loss=1.120]\rEpoch 99: 100%|██████████| 7/7 [00:00<00:00, 49.87it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.320, valid_loss=1.120]\n","\n"]},{"output_type":"stream","name":"stderr","text":["INFO:lightning_fabric.utilities.seed:Seed set to 7\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name         | Type          | Params | Mode \n","-------------------------------------------------------\n","0 | loss         | MQLoss        | 5      | eval \n","1 | padder_train | ConstantPad1d | 0      | train\n","2 | scaler       | TemporalNorm  | 0      | train\n","3 | hist_encoder | LSTM          | 199 K  | train\n","4 | mlp_decoder  | MLP           | 17.2 K | train\n","-------------------------------------------------------\n","216 K     Trainable params\n","5         Non-trainable params\n","216 K     Total params\n","0.865     Total estimated model params size (MB)\n","9         Modules in train mode\n","1         Modules in eval mode\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6efca17fb83447a591cdc611e6753eab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2181d5886404a8eb26579e7c10c7d1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db681488593840d6ada54fc0c76617c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54d5f56a12354d1c9c5de34449d2c9c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71decdc5b01d4006ba082ac2479849d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"056bdfbf47654a56bc2dd24e9e716f82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"379aad276713407ca5ef3ce3a1f45113"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09de7cb0447443f1b559f9f4b9b163dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4c9884ad7a548d3ad460a8548371f5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6877eaf4fcab4e239e8f43867f1f31bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"500e493d01674c2dbf7711b0a9df07fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64b285f7a8c4459ea96682f9bdc76638"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a755bee598644e98bb9efe910c875faa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f17a05eb1255433e9eb8bc5517fbed8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40651dea98bc4c16903d233114caff09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c78d3be0459e4d31a18184660ddf9d78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fe93307a89443159be5d46a442d7ce8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ff89157613b43ab831fd22f59e50055"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"907904e733224716a117bd347fb284b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c597b1db6e3474e959405146ed1961a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e695dbc7f88b4bb1b5a6d2e29738f40c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e47670255994deda4d23bb2f77e4975"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n","INFO:pytorch_lightning.utilities.rank_zero:Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Predicting: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3db8f7c27c3941f491ba091d604944de"}},"metadata":{}}]},{"cell_type":"markdown","source":["## **5. ANÁLISE DAS MÉTRICAS**"],"metadata":{"id":"wdBp2rfqljXy"}},{"cell_type":"code","source":["def rmsse(y, y_hat, y_train, seasonality):\n","    delta_y = (y - y_hat) ** 2\n","    delta_y = np.average(delta_y)\n","    scale = (y_train[:-seasonality] - y_train[seasonality:]) ** 2\n","    scale = np.average(scale)\n","    rmsse = np.sqrt(delta_y / scale)\n","    return rmsse\n","\n","def mase(y, y_hat, y_train, seasonality):\n","    delta_y = abs(y - y_hat)\n","    delta_y = np.average(delta_y)\n","    scale = abs(y_train[:-seasonality] - y_train[seasonality:])\n","    scale = np.average(scale)\n","    mase = delta_y / scale\n","    return mase\n","\n","def model_evaluation(y_hist, y_true, y_pred, Model, seasonality):\n","\n","    results_row = [{\"Model\": Model,\n","                    \"MSE\": metrics.mean_squared_error(y_true, y_pred),\n","                    \"MAE\": metrics.mean_absolute_error(y_true, y_pred),\n","                    \"RMSE\": np.sqrt(metrics.mean_squared_error(y_true, y_pred)),\n","                    \"RMSSE\": rmsse(y_true.values, y_pred.values, y_hist.values, seasonality=seasonality),\n","                    \"MASE\": mase(y_true.values, y_pred.values, y_hist.values, seasonality=seasonality)\n","                   }]\n","\n","    results = pd.DataFrame.from_records(results_row)\n","    return results"],"metadata":{"id":"OO9Xzy0RllTC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(forecasts.keys())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vkimw2na_LlQ","executionInfo":{"status":"ok","timestamp":1749930524675,"user_tz":-60,"elapsed":61,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"23d51027-ae9f-48f9-b374-08cb03e18253"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['unique_id', 'ds', 'AutoNHITS-median', 'AutoNHITS-lo-90',\n","       'AutoNHITS-lo-80', 'AutoNHITS-hi-80', 'AutoNHITS-hi-90',\n","       'AutoLSTM-median', 'AutoLSTM-lo-90', 'AutoLSTM-lo-80', 'AutoLSTM-hi-80',\n","       'AutoLSTM-hi-90'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["### FAZER DOWNLOAD DO FICHEIRO 'results_PST5.csv' NA ABA FICHEIROS DO COLAB ###\n","\n","new_result = model_evaluation(train[\"y\"], test[\"y_test\"], forecasts[\"AutoNHITS-median\"], \"AutoNHITS\", season_length)\n","Models_results = pd.concat([Models_results, new_result], ignore_index=True)\n","\n","new_result = model_evaluation(train[\"y\"], test[\"y_test\"], forecasts[\"AutoLSTM-median\"], \"AutoLSTM\", season_length)\n","Models_results = pd.concat([Models_results, new_result], ignore_index=True)\n","\n","Models_results.to_csv(\"results_PST5.csv\", index=False)\n","\n","Models_results"],"metadata":{"id":"xizhAjHtvusx","colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"status":"ok","timestamp":1749930607387,"user_tz":-60,"elapsed":55,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"f001eb1a-fc4e-42bf-af89-70b34b98450a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              Model       MSE       MAE      RMSE     RMSSE      MASE\n","0    Seasonal Naive  4.866237  1.268023  2.205955  1.055169  1.228272\n","1  Historic Average  3.181790  1.069713  1.783757  0.853221  1.036179\n","2         AutoARIMA  2.778064  1.043241  1.666753  0.797254  1.010537\n","3           AutoETS  2.722531  1.036994  1.650009  0.789245  1.004485\n","4           XGBoost  3.275633  1.053321  1.809871  0.865711  1.020301\n","5          LightGBM  3.013774  1.134485  1.736022  0.830388  1.098920\n","6         AutoNHITS  2.996018  0.959077  1.730901  0.827938  0.929011\n","7          AutoLSTM  3.290443  0.973242  1.813958  0.867666  0.942733"],"text/html":["\n","  <div id=\"df-b290f874-63ba-4875-845b-75a7169ece8b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>MSE</th>\n","      <th>MAE</th>\n","      <th>RMSE</th>\n","      <th>RMSSE</th>\n","      <th>MASE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Seasonal Naive</td>\n","      <td>4.866237</td>\n","      <td>1.268023</td>\n","      <td>2.205955</td>\n","      <td>1.055169</td>\n","      <td>1.228272</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Historic Average</td>\n","      <td>3.181790</td>\n","      <td>1.069713</td>\n","      <td>1.783757</td>\n","      <td>0.853221</td>\n","      <td>1.036179</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AutoARIMA</td>\n","      <td>2.778064</td>\n","      <td>1.043241</td>\n","      <td>1.666753</td>\n","      <td>0.797254</td>\n","      <td>1.010537</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AutoETS</td>\n","      <td>2.722531</td>\n","      <td>1.036994</td>\n","      <td>1.650009</td>\n","      <td>0.789245</td>\n","      <td>1.004485</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>XGBoost</td>\n","      <td>3.275633</td>\n","      <td>1.053321</td>\n","      <td>1.809871</td>\n","      <td>0.865711</td>\n","      <td>1.020301</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>LightGBM</td>\n","      <td>3.013774</td>\n","      <td>1.134485</td>\n","      <td>1.736022</td>\n","      <td>0.830388</td>\n","      <td>1.098920</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>AutoNHITS</td>\n","      <td>2.996018</td>\n","      <td>0.959077</td>\n","      <td>1.730901</td>\n","      <td>0.827938</td>\n","      <td>0.929011</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>AutoLSTM</td>\n","      <td>3.290443</td>\n","      <td>0.973242</td>\n","      <td>1.813958</td>\n","      <td>0.867666</td>\n","      <td>0.942733</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b290f874-63ba-4875-845b-75a7169ece8b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b290f874-63ba-4875-845b-75a7169ece8b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b290f874-63ba-4875-845b-75a7169ece8b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-3a28067e-30bd-4739-b194-83b99a2d4cde\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a28067e-30bd-4739-b194-83b99a2d4cde')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-3a28067e-30bd-4739-b194-83b99a2d4cde button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_ad8e4407-92c2-46a7-95c7-0b53b3005a71\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('Models_results')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_ad8e4407-92c2-46a7-95c7-0b53b3005a71 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('Models_results');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"Models_results","summary":"{\n  \"name\": \"Models_results\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Historic Average\",\n          \"LightGBM\",\n          \"Seasonal Naive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6801770644950725,\n        \"min\": 2.722530890809451,\n        \"max\": 4.866236686706543,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.181790351867676,\n          3.013773965696412,\n          4.866236686706543\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09787817921716638,\n        \"min\": 0.959076837815773,\n        \"max\": 1.268022537231445,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.0697128772735596,\n          1.1344846839295002,\n          1.268022537231445\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1750405351910057,\n        \"min\": 1.6500093608247957,\n        \"max\": 2.20595482426693,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.7837573691137694,\n          1.7360224554124903,\n          2.20595482426693\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08372674227950296,\n        \"min\": 0.7892451660399364,\n        \"max\": 1.0551693,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.8532206,\n          0.8303876108837279,\n          1.0551693\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MASE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09480987249588073,\n        \"min\": 0.9290111912776784,\n        \"max\": 1.228272,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.036179,\n          1.098920259719666,\n          1.228272\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["O AutoNHITS e o AutoLSTM superam os restantes modelos, especialmente na MASE e na MAE. Isto mostra que os modelos neuronais especializados para séries temporais são eficazes neste problema.\n","\n","O AutoNIHTS obtém um melhor resultado global, sendo o modelo recomendado, pois consegue capturar os padrões complexos da série de forma superior.\n","\n","Se for pretendido simplicidade, AutoETS ainda é uma boa opção, principalmente se o custo computacional for importante."],"metadata":{"id":"7agMvrxoiL3U"}},{"cell_type":"markdown","source":["### Plot das previsões"],"metadata":{"id":"NmNydXZQlnMB"}},{"cell_type":"code","source":["plot_series(\n","    train,\n","    forecasts,\n","    plot_random=False,\n","    models=['AutoNHITS-median'],\n","    max_insample_length=48\n",")"],"metadata":{"id":"YxMjW16ClpiO","colab":{"base_uri":"https://localhost:8080/","height":880},"executionInfo":{"status":"ok","timestamp":1749930663321,"user_tz":-60,"elapsed":3886,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"92b6aa68-dc44-4280-f4f3-411977b4ce2e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 1600x1400 with 8 Axes>"],"image/png":"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\n"},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["plot_series(\n","    train,\n","    forecasts,\n","    plot_random=False,\n","    models=['AutoLSTM-median'],\n","    max_insample_length=48\n",")"],"metadata":{"id":"jJch-6GalymI","colab":{"base_uri":"https://localhost:8080/","height":882},"executionInfo":{"status":"ok","timestamp":1749930666363,"user_tz":-60,"elapsed":1742,"user":{"displayName":"Rui Parada","userId":"16308073451763810536"}},"outputId":"18954db0-2522-4e56-aeb3-79316a664d3f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 1600x1400 with 8 Axes>"],"image/png":"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\n"},"metadata":{},"execution_count":22}]}]}